{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Reading multiple data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DataFrames from multiple files\n",
    "When data is spread among several files, you usually invoke pandas' read_csv() (or a similar data import function) multiple times to load the data into several DataFrames.\n",
    "\n",
    "The data files for this example have been derived from a [list of Olympic medals awarded between 1896 & 2008](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data) compiled by the Guardian.\n",
    "\n",
    "The column labels of each DataFrame are NOC, Country, & Total where NOC is a three-letter code for the name of the country and Total is the number of medals of that type won (bronze, silver, or gold).\n",
    "\n",
    "This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the [Pandas Cheat Sheet](https://datacamp-community-prod.s3.amazonaws.com/9f0f2ae1-8bd8-4302-a67b-e17f3059d9e8) and keep it handy!\n",
    "\n",
    "* Import pandas as pd.\n",
    "* Read the file 'Bronze.csv' into a DataFrame called bronze.\n",
    "* Read the file 'Silver.csv' into a DataFrame called silver.\n",
    "* Read the file 'Gold.csv' into a DataFrame called gold.\n",
    "* Print the first 5 rows of the DataFrame gold. This has been done for you, so hit 'Submit Answer' to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Reading csv files into DataFrames like this should now be second nature to you!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'Bronze.csv' into a DataFrame: bronze\n",
    "bronze = pd.read_csv('datasets/Bronze.csv')\n",
    "\n",
    "# Read 'Silver.csv' into a DataFrame: silver\n",
    "silver = pd.read_csv('datasets/Silver.csv')\n",
    "\n",
    "# Read 'Gold.csv' into a DataFrame: gold\n",
    "gold = pd.read_csv('datasets/Gold.csv')\n",
    "\n",
    "# Print the first five rows of gold\n",
    "print(gold.head())\n",
    "'''Reading csv files into DataFrames like this should now be second nature to you!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DataFrames from multiple files in a loop\n",
    "As you saw in the video, loading data from multiple files into DataFrames is more efficient in a loop or a list comprehension.\n",
    "\n",
    "Notice that this approach is not restricted to working with CSV files. That is, even if your data comes in other formats, as long as pandas has a suitable data import function, you can apply a loop or comprehension to generate a list of DataFrames imported from the source files.\n",
    "\n",
    "Here, you'll continue working with The Guardian's Olympic medal dataset.\n",
    "\n",
    "* Create a list of file names called filenames with three strings 'Gold.csv', 'Silver.csv', & 'Bronze.csv'. This has been done for you.\n",
    "* Use a for loop to create another list called dataframes containing the three DataFrames loaded from filenames:\n",
    "    * Iterate over filenames.\n",
    "    * Read each CSV file in filenames into a DataFrame and append it to dataframes by using pd.read_csv() inside a call to .append().\n",
    "* Print the first 5 rows of the first DataFrame of the list dataframes. This has been done for you, so hit 'Submit Answer' to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'When you are dealing with multiple csv files like this, it is more efficient to read them into DataFrames using a loop.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create the list of file names: filenames\n",
    "filenames = ['datasets/Gold.csv', 'datasets/Silver.csv', 'datasets/Bronze.csv']\n",
    "\n",
    "# Create the list of three DataFrames: dataframes\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))\n",
    "\n",
    "# Print top 5 rows of 1st DataFrame in dataframes\n",
    "print(dataframes[0].head())\n",
    "'''When you are dealing with multiple csv files like this, it is more efficient to read them into DataFrames using a loop.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataFrames from multiple data files\n",
    "In this exercise, you'll combine the three DataFrames from earlier exercises - gold, silver, & bronze - into a single DataFrame called medals. The approach you'll use here is clumsy. Later on in the course, you'll see various powerful methods that are frequently used in practice for concatenating or merging DataFrames.\n",
    "\n",
    "Remember, the column labels of each DataFrame are NOC, Country, and Total, where NOC is a three-letter code for the name of the country and Total is the number of medals of that type won.\n",
    "\n",
    "* Construct a copy of the DataFrame gold called medals using the .copy() method.\n",
    "* Create a list called new_labels with entries 'NOC', 'Country', & 'Gold'. This is the same as the column labels from gold with the column label 'Total' replaced by 'Gold'.\n",
    "* Rename the columns of medals by assigning new_labels to medals.columns.\n",
    "* Create new columns 'Silver' and 'Bronze' in medals using silver['Total'] & bronze['Total'].\n",
    "* Print the top 5 rows of the final DataFrame medals. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country    Gold  Silver  Bronze\n",
      "0  USA   United States  2088.0  1195.0  1052.0\n",
      "1  URS    Soviet Union   838.0   627.0   584.0\n",
      "2  GBR  United Kingdom   498.0   591.0   505.0\n",
      "3  FRA          France   378.0   461.0   475.0\n",
      "4  GER         Germany   407.0   350.0   454.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Later in this course, you'll learn far more powerful tools for combining DataFrames!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Make a copy of gold: medals\n",
    "medals = gold.copy()\n",
    "\n",
    "# Create list of new column labels: new_labels\n",
    "new_labels = ['NOC', 'Country', 'Gold']\n",
    "\n",
    "# Rename the columns of medals using new_labels\n",
    "medals.columns = new_labels\n",
    "\n",
    "# Add columns 'Silver' & 'Bronze' to medals\n",
    "medals['Silver'] = silver['Total']\n",
    "medals['Bronze'] = bronze['Total']\n",
    "\n",
    "# Print the head of medals\n",
    "print(medals.head())\n",
    "'''Later in this course, you'll learn far more powerful tools for combining DataFrames!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Reindexing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting DataFrame with the Index & columns\n",
    "It is often useful to rearrange the sequence of the rows of a DataFrame by sorting. You don't have to implement these yourself; the principal methods for doing this are .sort_index() and .sort_values().\n",
    "\n",
    "In this exercise, you'll use these methods with a DataFrame of temperature values indexed by month names. You'll sort the rows alphabetically using the Index and numerically using a column. Notice, for this data, the original ordering is probably most useful and intuitive: the purpose here is for you to understand what the sorting methods do.\n",
    "\n",
    "* Read 'monthly_max_temp.csv' into a DataFrame called weather1 with 'Month' as the index.\n",
    "* Sort the index of weather1 in alphabetical order using the .sort_index() method and store the result in weather2.\n",
    "* Sort the index of weather1 in reverse alphabetical order by specifying the additional keyword argument ascending=False inside .sort_index().\n",
    "* Use the .sort_values() method to sort weather1 in increasing numerical order according to the values of the column 'Max TemperatureF'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Max TemperatureF\n",
      "Month                  \n",
      "Jan                  68\n",
      "Feb                  60\n",
      "Mar                  68\n",
      "Apr                  84\n",
      "May                  88\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Apr                  84\n",
      "Aug                  86\n",
      "Dec                  68\n",
      "Feb                  60\n",
      "Jan                  68\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Sep                  90\n",
      "Oct                  84\n",
      "Nov                  72\n",
      "May                  88\n",
      "Mar                  68\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Feb                  60\n",
      "Jan                  68\n",
      "Mar                  68\n",
      "Dec                  68\n",
      "Nov                  72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Being able to sort DataFrames is an important skill. When your DataFrames are sorted, it becomes easier to see how you can combine them.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'monthly_max_temp.csv' into a DataFrame: weather1\n",
    "weather1 = pd.read_csv('datasets/monthly_max_temp.csv', index_col='Month')\n",
    "\n",
    "# Print the head of weather1\n",
    "print(weather1.head())\n",
    "\n",
    "# Sort the index of weather1 in alphabetical order: weather2\n",
    "weather2 = weather1.sort_index()\n",
    "\n",
    "# Print the head of weather2\n",
    "print(weather2.head())\n",
    "\n",
    "# Sort the index of weather1 in reverse alphabetical order: weather3\n",
    "weather3 = weather1.sort_index(ascending=False)\n",
    "\n",
    "# Print the head of weather3\n",
    "print(weather3.head())\n",
    "\n",
    "# Sort weather1 numerically using the values of 'Max TemperatureF': weather4\n",
    "weather4 = weather1.sort_values('Max TemperatureF')\n",
    "\n",
    "# Print the head of weather4\n",
    "print(weather4.head())\n",
    "'''Being able to sort DataFrames is an important skill. When your DataFrames are sorted, it becomes easier to see how you can combine them.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing DataFrame from a list\n",
    "Sorting methods are not the only way to change DataFrame Indexes. There is also the .reindex() method.\n",
    "\n",
    "In this exercise, you'll reindex a DataFrame of quarterly-sampled mean temperature values to contain monthly samples (this is an example of upsampling or increasing the rate of samples, which you may recall from the [pandas Foundations course](https://www.datacamp.com/courses/pandas-foundations)).\n",
    "\n",
    "The original data has the first month's abbreviation of the quarter (three-month interval) on the Index, namely Apr, Jan, Jul, and Oct. This data has been loaded into a DataFrame called weather1 and has been printed in its entirety in the IPython Shell. Notice it has only four rows (corresponding to the first month of each quarter) and that the rows are not sorted chronologically.\n",
    "\n",
    "You'll initially use a list of all twelve month abbreviations and subsequently apply the .ffill() method to forward-fill the null entries when upsampling. This list of month abbreviations has been pre-loaded as year.\n",
    "\n",
    "* Reorder the rows of weather1 using the .reindex() method with the list year as the argument, which contains the abbreviations for each month.\n",
    "* Reorder the rows of weather1 just as you did above, this time chaining the .ffill() method to replace the null values with the last preceding non-null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Max TemperatureF\n",
      "Month                  \n",
      "Jan                  68\n",
      "Feb                  60\n",
      "Mar                  68\n",
      "Apr                  84\n",
      "May                  88\n",
      "Jun                  89\n",
      "Jul                  91\n",
      "Aug                  86\n",
      "Sep                  90\n",
      "Oct                  84\n",
      "Nov                  72\n",
      "Dec                  68\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Jan                  68\n",
      "Feb                  60\n",
      "Mar                  68\n",
      "Apr                  84\n",
      "May                  88\n",
      "Jun                  89\n",
      "Jul                  91\n",
      "Aug                  86\n",
      "Sep                  90\n",
      "Oct                  84\n",
      "Nov                  72\n",
      "Dec                  68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Notice that values corresponding to months missing from weather1 are filled with NaN values in weather2. This does not happen in weather3, since you used forward-fill.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "year = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "# Reindex weather1 using the list year: weather2\n",
    "weather2 = weather1.reindex(year)\n",
    "\n",
    "# Print weather2\n",
    "print(weather2)\n",
    "\n",
    "# Reindex weather1 using the list year with forward-fill: weather3\n",
    "weather3 = weather1.reindex(year).ffill()\n",
    "\n",
    "# Print weather3\n",
    "print(weather3)\n",
    "'''Notice that values corresponding to months missing from weather1 are filled with NaN values in weather2. This does not happen in weather3, since you used forward-fill.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reindexing using another DataFrame Index\n",
    "Another common technique is to reindex a DataFrame using the Index of another DataFrame. The DataFrame .reindex() method can accept the Index of a DataFrame or Series as input. You can access the Index of a DataFrame with its .index attribute.\n",
    "\n",
    "The Baby Names Dataset from data.gov summarizes counts of names (with genders) from births registered in the US since 1881. In this exercise, you will start with two baby-names DataFrames names_1981 and names_1881 loaded for you.\n",
    "\n",
    "The DataFrames names_1981 and names_1881 both have a MultiIndex with levels name and gender giving unique labels to counts in each row. If you're interested in seeing how the MultiIndexes were set up, names_1981 and names_1881 were read in using the following commands:\n",
    "\n",
    "```python\n",
    "names_1981 = pd.read_csv('names1981.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "names_1881 = pd.read_csv('names1881.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "```\n",
    "As you can see by looking at their shapes, which have been printed in the IPython Shell, the DataFrame corresponding to 1981 births is much larger, reflecting the greater diversity of names in 1981 as compared to 1881.\n",
    "\n",
    "Your job here is to use the DataFrame .reindex() and .dropna() methods to make a DataFrame common_names counting names from 1881 that were still popular in 1981.\n",
    "\n",
    "* Create a new DataFrame common_names by reindexing names_1981 using the index attribute of the DataFrame names_1881 of older names.\n",
    "* Print the shape of the new common_names DataFrame. This has been done for you. It should be the same as that of names_1881.\n",
    "* Drop the rows of common_names that have null counts using the .dropna() method. These rows correspond to names that fell out of fashion between 1881 & 1981.\n",
    "* Print the shape of the reassigned common_names DataFrame. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1935, 1)\n",
      "(1587, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It looks like 348 names fell out of fashion between 1881 and 1981!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "names_1981 = pd.read_csv('datasets/names1981.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "names_1881 = pd.read_csv('datasets/names1881.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "\n",
    "# Reindex names_1981 with index of names_1881: common_names\n",
    "common_names = names_1981.reindex(names_1881.index)\n",
    "\n",
    "# Print shape of common_names\n",
    "print(common_names.shape)\n",
    "\n",
    "# Drop rows with null counts: common_names\n",
    "common_names = common_names.dropna()\n",
    "\n",
    "# Print shape of new common_names\n",
    "print(common_names.shape)\n",
    "'''It looks like 348 names fell out of fashion between 1881 and 1981!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Arithmetic with Series & DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding unaligned DataFrames\n",
    "The DataFrames january and february, which have been printed in the IPython Shell, represent the sales a company made in the corresponding months.\n",
    "\n",
    "The Indexes in both DataFrames are called Company, identifying which company bought that quantity of units. The column Units is the number of units sold.\n",
    "\n",
    "If you were to add these two DataFrames by executing the command total = january + february, how many rows would the resulting DataFrame have? Try this in the IPython Shell and find out for yourself.\n",
    "\n",
    "Possible Answers\n",
    "* 3 rows.\n",
    "* 4 rows.\n",
    "* 5 rows.\n",
    "* 6 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Units\n",
      "Company                \n",
      "Acme Corporation     19\n",
      "Hooli                17\n",
      "Initech              20\n",
      "Mediacore            10\n",
      "Streeplex            13\n",
      "                  Units\n",
      "Company                \n",
      "Acme Corporation     15\n",
      "Hooli                 3\n",
      "Mediacore            13\n",
      "Vandelay Inc         25\n",
      "                  Units\n",
      "Company                \n",
      "Acme Corporation   34.0\n",
      "Hooli              20.0\n",
      "Initech             NaN\n",
      "Mediacore          23.0\n",
      "Streeplex           NaN\n",
      "Vandelay Inc        NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'january and february both consist of the sales of the Companies Acme Corporation, Hooli, and Mediacore. january has the additional two companies Initech and Streeplex, while february has the additional company Vandelay Inc. Together, they consist of the sales of 6 unique companies, and so total would have 6 rows.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "january = pd.read_csv('datasets/january.csv', index_col = \"Company\")\n",
    "february = pd.read_csv('datasets/february.csv', index_col = \"Company\")\n",
    "\n",
    "print(january)\n",
    "print(february)\n",
    "\n",
    "total = january + february\n",
    "\n",
    "print(total)\n",
    "'''january and february both consist of the sales of the Companies Acme Corporation, Hooli, and Mediacore. january has the additional two companies Initech and Streeplex, while february has the additional company Vandelay Inc. Together, they consist of the sales of 6 unique companies, and so total would have 6 rows.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in arithmetic formulas\n",
    "In this exercise, you'll work with weather data pulled from [wunderground.com](https://www.wunderground.com/). The DataFrame weather has been pre-loaded along with pandas as pd. It has 365 rows (observed each day of the year 2013 in Pittsburgh, PA) and 22 columns reflecting different weather measurements each day.\n",
    "\n",
    "You'll subset a collection of columns related to temperature measurements in degrees Fahrenheit, convert them to degrees Celsius, and relabel the columns of the new DataFrame to reflect the change of units.\n",
    "\n",
    "Remember, ordinary arithmetic operators (like +, -, *, and /) broadcast scalar values to conforming DataFrames when combining scalars & DataFrames in arithmetic expressions. Broadcasting also works with pandas Series and NumPy arrays.\n",
    "\n",
    "* Create a new DataFrame temps_f by extracting the columns 'Min TemperatureF', 'Mean TemperatureF', & 'Max TemperatureF' from weather as a new DataFrame temps_f. To do this, pass the relevant columns as a list to weather[].\n",
    "* Create a new DataFrame temps_c from temps_f using the formula (temps_f - 32) * 5/9.\n",
    "* Rename the columns of temps_c to replace 'F' with 'C' using the .str.replace('F', 'C') method on temps_c.columns.\n",
    "* Print the first 5 rows of DataFrame temps_c. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Min TemperatureC  Mean TemperatureC  Max TemperatureC\n",
      "Date                                                             \n",
      "2013-01-01         -6.111111          -2.222222          0.000000\n",
      "2013-01-02         -8.333333          -6.111111         -3.888889\n",
      "2013-01-03         -8.888889          -4.444444          0.000000\n",
      "2013-01-04         -2.777778          -2.222222         -1.111111\n",
      "2013-01-05         -3.888889          -1.111111          1.111111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' In only three lines of code, you converted the units of 365 data points (over three columns) from degrees Fahrenheit to degrees Celsius.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weather = pd.read_csv('datasets/pittsburgh2013.csv', index_col='Date', \n",
    "                      parse_dates=True)\n",
    "# Extract selected columns from weather as new DataFrame: temps_f\n",
    "temps_f = weather[['Min TemperatureF','Mean TemperatureF','Max TemperatureF']]\n",
    "\n",
    "# Convert temps_f to celsius: temps_c\n",
    "temps_c = (temps_f - 32) * 5/9\n",
    "\n",
    "# Rename 'F' in column names with 'C': temps_c.columns\n",
    "temps_c.columns = temps_c.columns.str.replace('F', 'C')\n",
    "\n",
    "# Print first 5 rows of temps_c\n",
    "print(temps_c.head())\n",
    "''' In only three lines of code, you converted the units of 365 data points (over three columns) from degrees Fahrenheit to degrees Celsius.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing percentage growth of GDP\n",
    "Your job in this exercise is to compute the yearly percent-change of US GDP ([Gross Domestic Product](https://en.wikipedia.org/wiki/Gross_domestic_product)) since 2008.\n",
    "\n",
    "The data has been obtained from the [Federal Reserve Bank of St. Louis](https://fred.stlouisfed.org/series/GDP) and is available in the file GDP.csv, which contains quarterly data; you will resample it to annual sampling and then compute the annual growth of GDP. For a refresher on resampling, check out the relevant material from [pandas Foundations](https://campus.datacamp.com/courses/pandas-foundations/time-series-in-pandas?ex=7).\n",
    "\n",
    "* Read the file 'GDP.csv' into a DataFrame called gdp, using parse_dates=True and index_col='DATE'.\n",
    "* Create a DataFrame post2008 by slicing gdp such that it comprises all rows from 2008 onward.\n",
    "* Print the last 8 rows of the slice post2008. This has been done for you. This data has quarterly frequency so the indices are separated by three-month intervals.\n",
    "* Create the DataFrame yearly by resampling the slice post2008 by year. Remember, you need to chain .resample() (using the alias 'A' for annual frequency) with some kind of aggregation; you will use the aggregation method .last() to select the last element when resampling.\n",
    "* Compute the percentage growth of the resampled DataFrame yearly with .pct_change() * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE\n",
      "DATE               \n",
      "2014-07-01  17569.4\n",
      "2014-10-01  17692.2\n",
      "2015-01-01  17783.6\n",
      "2015-04-01  17998.3\n",
      "2015-07-01  18141.9\n",
      "2015-10-01  18222.8\n",
      "2016-01-01  18281.6\n",
      "2016-04-01  18436.5\n",
      "              VALUE\n",
      "DATE               \n",
      "2008-12-31  14549.9\n",
      "2009-12-31  14566.5\n",
      "2010-12-31  15230.2\n",
      "2011-12-31  15785.3\n",
      "2012-12-31  16297.3\n",
      "2013-12-31  16999.9\n",
      "2014-12-31  17692.2\n",
      "2015-12-31  18222.8\n",
      "2016-12-31  18436.5\n",
      "              VALUE    growth\n",
      "DATE                         \n",
      "2008-12-31  14549.9       NaN\n",
      "2009-12-31  14566.5  0.114090\n",
      "2010-12-31  15230.2  4.556345\n",
      "2011-12-31  15785.3  3.644732\n",
      "2012-12-31  16297.3  3.243524\n",
      "2013-12-31  16999.9  4.311144\n",
      "2014-12-31  17692.2  4.072377\n",
      "2015-12-31  18222.8  2.999062\n",
      "2016-12-31  18436.5  1.172707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Note that the first column of the 'growth' column is NaN because there is no data for the year 2007.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'GDP.csv' into a DataFrame: gdp\n",
    "#gdp = pd.read_csv('GDP.csv', index_col='DATE', parse_dates=True)\n",
    "gdp = pd.read_csv('datasets/gdp_usa.csv', index_col='DATE', parse_dates=True)\n",
    "\n",
    "# Slice all the gdp data from 2008 onward: post2008\n",
    "post2008 = gdp.loc['2008':]\n",
    "\n",
    "# Print the last 8 rows of post2008\n",
    "print(post2008.tail(8))\n",
    "\n",
    "# Resample post2008 by year, keeping last(): yearly\n",
    "yearly = post2008.resample('A').last()\n",
    "\n",
    "# Print yearly\n",
    "print(yearly)\n",
    "\n",
    "# Compute percentage growth of yearly: yearly['growth']\n",
    "yearly['growth'] = yearly.pct_change() * 100\n",
    "\n",
    "# Print yearly again\n",
    "print(yearly)\n",
    "'''Note that the first column of the 'growth' column is NaN because there is no data for the year 2007.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting currency of stocks\n",
    "In this exercise, stock prices in US Dollars for the S&P 500 in 2015 have been obtained from [Yahoo Finance](https://finance.yahoo.com/). The files sp500.csv for sp500 and exchange.csv for the exchange rates are both provided to you.\n",
    "\n",
    "Using the daily exchange rate to Pounds Sterling, your task is to convert both the Open and Close column prices.\n",
    "\n",
    "* Read the DataFrames sp500 & exchange from the files 'sp500.csv' & 'exchange.csv' respectively..\n",
    "* Use parse_dates=True and index_col='Date'.\n",
    "* Extract the columns 'Open' & 'Close' from the DataFrame sp500 as a new DataFrame dollars and print the first 5 rows.\n",
    "* Construct a new DataFrame pounds by converting US dollars to British pounds. You'll use the .multiply() method of dollars with exchange['GBP/USD'] and axis='rows'\n",
    "* Print the first 5 rows of the new DataFrame pounds. This has been done for you, so hit 'Submit Answer' to see the results!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  2058.899902  2058.199951\n",
      "2015-01-05  2054.439941  2020.579956\n",
      "2015-01-06  2022.150024  2002.609985\n",
      "2015-01-07  2005.550049  2025.900024\n",
      "2015-01-08  2030.609985  2062.139893\n",
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  1340.364425  1339.908750\n",
      "2015-01-05  1348.616555  1326.389506\n",
      "2015-01-06  1332.515980  1319.639876\n",
      "2015-01-07  1330.562125  1344.063112\n",
      "2015-01-08  1343.268811  1364.126161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Now that you've become familiar with how to share information between DataFrames, you'll learn about concatenating DataFrames in the next chapter.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'sp500.csv' into a DataFrame: sp500\n",
    "sp500 = pd.read_csv('datasets/sp500.csv',parse_dates=True,index_col='Date')\n",
    "\n",
    "# Read 'exchange.csv' into a DataFrame: exchange\n",
    "exchange = pd.read_csv('datasets/exchange.csv',parse_dates=True,index_col='Date')\n",
    "\n",
    "# Subset 'Open' & 'Close' columns from sp500: dollars\n",
    "dollars = sp500[['Open','Close']]\n",
    "\n",
    "# Print the head of dollars\n",
    "print(dollars.head())\n",
    "\n",
    "# Convert dollars to pounds: pounds\n",
    "pounds = dollars.multiply(exchange['GBP/USD'],axis='rows')\n",
    "\n",
    "# Print the head of pounds\n",
    "print(pounds.head())\n",
    "'''Now that you've become familiar with how to share information between DataFrames, you'll learn about concatenating DataFrames in the next chapter.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
