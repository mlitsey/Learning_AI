{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data in Python Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing flat files from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you import web data?\n",
    "#### You can: go to URL and click to download files\n",
    "#### BUT: not reproducible, not scalable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lean how to ...\n",
    "* Import and locally save datasets from the web\n",
    "* Load datasets into pandas DataFrames directly from the web\n",
    "* Make HTTP requests (GET requests)\n",
    "* Scrape web data such as HTML\n",
    "* Parse HTML into useful data (BeautifulSoup)\n",
    "* Use the urllib and requests packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Urllib package\n",
    "* Provides interface for fetching data across the web\n",
    "* urlopen() - accepts URLs instead of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('winequality-white.csv', <http.client.HTTPMessage at 0x715beef0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to automate file download in Python\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "\n",
    "urlretrieve(url, 'winequality-white.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing flat files from the web: your turn!\n",
    "#### You are about to import your first file from the web! The flat file you will import will be 'winequality-red.csv' from the University of California, Irvine's Machine Learning repository. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.\n",
    "#### The URL of the file is\n",
    "'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "#### After you import it, you'll check your working directory to confirm that it is there and then you'll load it into a pandas DataFrame.\n",
    "\n",
    "* Import the function urlretrieve from the subpackage urllib.request.\n",
    "* Assign the URL of the file to the variable url.\n",
    "* Use the function urlretrieve() to save the file locally as 'winequality-red.csv'.\n",
    "* Execute the remaining code to load 'winequality-red.csv' in a pandas DataFrame and to print its head to the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "#url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/snakes.json'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'winequality-red.csv')\n",
    "#urlretrieve(url, 'snakes.json')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and reading flat files from the web\n",
    "#### You have just imported a file from the web, saved it locally and loaded it into a DataFrame. If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can do that easily using pandas. In particular, you can use the function pd.read_csv() with the URL as the first argument and the separator sep as the second argument.\n",
    "#### The URL of the file, once again, is\n",
    "'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "* Assign the URL of the file to the variable url.\n",
    "* Read file into a DataFrame df using pd.read_csv(), recalling that the separator in the file is ';'.\n",
    "* Print the head of the DataFrame df.\n",
    "* Execute the rest of the code to plot histogram of the first feature in the DataFrame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep = ';')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Plot first column of df\n",
    "pd.DataFrame.hist(df.ix[:, 0:1])\n",
    "plt.xlabel('fixed acidity (g(tartaric acid)/dm$^3$)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing non-flat files from the web\n",
    "#### Congrats! You've just loaded a flat file from the web into a DataFrame without first saving it locally using the pandas function pd.read_csv(). This function is super cool because it has close relatives that allow you to load all types of files, not only flat ones. In this interactive exercise, you'll use pd.read_excel() to import an Excel spreadsheet.\n",
    "#### The URL of the spreadsheet is\n",
    "'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "#### Your job is to use pd.read_excel() to read in all of its sheets, print the sheet names and then print the head of the first sheet using its name, not its index.\n",
    "#### Note that the output of pd.read_excel() is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values.\n",
    "\n",
    "* Assign the URL of the file to the variable url.\n",
    "* Read the file in url into a dictionary xl using pd.read_excel() recalling that, in order to import all sheets you need to pass None to the argument sheetname.\n",
    "* Print the names of the sheets in the Excel spreadsheet; these will be the keys of the dictionary xl.\n",
    "* Print the head of the first sheet using the sheet name, not the index of the sheet! The sheet name is '1700'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['1700', '1900'])\n",
      "                 country       1700\n",
      "0            Afghanistan  34.565000\n",
      "1  Akrotiri and Dhekelia  34.616667\n",
      "2                Albania  41.312000\n",
      "3                Algeria  36.720000\n",
      "4         American Samoa -14.307000\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "#xl = pd.read_excel(url, sheetname = None)\n",
    "xl = pd.read_excel(url, sheet_name = None)\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print(xl.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xl['1700'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP requests to import files from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL\n",
    "* Uniform/Universal Resource Locator\n",
    "* References to web resources\n",
    "* Focus: web addresses\n",
    "* Ingredients:\n",
    "    * Protocol identifier - http: or https:\n",
    "    * Resource name - datacamp.com\n",
    "* These specify web addresses uniquely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP\n",
    "* HyperText Transfer Protocol\n",
    "* Foundation of data communication for the web\n",
    "* HTTPS - more secure form of HTTP \n",
    "* Going to a website = sending HTTP request\n",
    "    * GET request\n",
    "* urlretrieve() performs a GET request and stores it locally\n",
    "* HTML - HyperText Markup Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET requests using urllib\n",
    "\n",
    "from urllib.request import urlopen, Request \n",
    "\n",
    "url = \"https://www.wikipedia.org/\"\n",
    "\n",
    "request = Request(url)\n",
    "\n",
    "response = urlopen(request)\n",
    "\n",
    "html = response.read()\n",
    "\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET requests using Requests\n",
    "## One of the most downloaded Python packages\n",
    "\n",
    "import requests\n",
    "url = \"https://www.wikipedia.org/\"\n",
    "r = requests.get(url)\n",
    "text = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing HTTP requests in Python using urllib\n",
    "#### Now that you know the basics behind HTTP GET requests, it's time to perform some of your own. In this interactive exercise, you will ping our very own DataCamp servers to perform a GET request to extract information from our teach page, \"http://www.datacamp.com/teach/documentation\".\n",
    "#### In the next exercise, you'll extract the HTML itself. Right now, however, you are going to package and send the request and then catch the response.\n",
    "\n",
    "* Import the functions urlopen and Request from the subpackage urllib.request.\n",
    "* Package the request to the url \"http://www.datacamp.com/teach/documentation\" using the function Request() and assign it to request.\n",
    "* Send the request and catch the response in the variable response with the function urlopen().\n",
    "* Run the rest of the code to see the datatype of response and to close the connection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# This packages the request: request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Print the datatype of response\n",
    "print(type(response))\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing HTTP request results in Python using urllib\n",
    "#### You have just packaged and sent a GET request to \"http://www.datacamp.com/teach/documentation\" and then caught the response. You saw that such a response is a http.client.HTTPResponse object. The question remains: what can you do with this response?\n",
    "#### Well, as it came from an HTML page, you could read it to extract the HTML and, in fact, such a http.client.HTTPResponse object has an associated read() method. In this exercise, you'll build on your previous great work to extract the response and print the HTML.\n",
    "\n",
    "* Send the request and catch the response in the variable response with the function urlopen(), as in the previous exercise.\n",
    "* Extract the response using the read() method and store the result in the variable html.\n",
    "* Print the string html.\n",
    "* Hit submit to perform all of the above and to close the response: be tidy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<html lang=\"en\" data-direction=\"ltr\">\\n  <head>\\n    <link href=\"https://fonts.intercomcdn.com\" rel=\"preconnect\" crossorigin>\\n      <script src=\"https://www.googletagmanager.com/gtag/js?id=UA-39297847-9\" async=\"async\" nonce=\"iBhG1aBK559vFuuIJC/jx2zCoI0f+e1mnOuF73KIJ/s=\"></script>\\n      <script nonce=\"iBhG1aBK559vFuuIJC/jx2zCoI0f+e1mnOuF73KIJ/s=\">\\n        window.dataLayer = window.dataLayer || [];\\n        function gtag(){dataLayer.push(arguments);}\\n        gtag(\\'js\\', new Date());\\n        gtag(\\'config\\', \\'UA-39297847-9\\');\\n</script>\\n    <meta charset=\"utf-8\">\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n    <title>DataCamp Help Center</title>\\n    <meta name=\"description\" content=\"\">\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n      <meta name=\"intercom:trackingEvent\" content=\"{&quot;name&quot;:&quot;Viewed Help Center&quot;,&quot;metadata&quot;:{&quot;action&quot;:&quot;viewed&quot;,&quot;object&quot;:&quot;educate_home&quot;,&quot;place&quot;:&quot;help_center&quot;,&quot;owner&quot;:&quot;educate&quot;}}\" />\\n\\n    <link rel=\"stylesheet\" media=\"all\" href=\"https://intercom.help/_assets/application-cf96f613358ad1f77fb9ea03098706a52f28f50d9c46df57184f74e53e1941ba.css\" />\\n    <link rel=\"canonical\" href=\"http://instructor-support.datacamp.com/\"/>\\n\\n        <link href=\"https://static.intercomassets.com/assets/educate/educate-favicon-64x64-at-2x-52016a3500a250d0b118c0a04ddd13b1a7364a27759483536dd1940bccdefc20.png\" rel=\"shortcut icon\" type=\"image/png\" />\\n      <style>\\n        .header, .avatar__image-extra { background-color: #263e63; }\\n        .article a, .c__primary { color: #263e63; }\\n        .avatar__fallback { background-color: #263e63; }\\n        article a.intercom-h2b-button { background-color: #263e63; border: 0; }\\n      </style>\\n\\n      <meta property=\"og:title\" content=\"DataCamp Help Center\" />\\n  <meta name=\"twitter:title\" content=\"DataCamp Help Center\" />\\n\\n\\n<meta property=\"og:type\" content=\"website\" />\\n<meta property=\"og:image\" content=\"\" />\\n\\n<meta name=\"twitter:image\" content=\"\" />\\n\\n  </head>\\n  <body class=\"\">\\n    <header class=\"header\">\\n  <div class=\"container header__container o__ltr\" dir=\"ltr\">\\n    <div class=\"content\">\\n      <div class=\"mo o__centered o__reversed header__meta_wrapper\">\\n        <div class=\"mo__body\">\\n          <div class=\"header__logo\">\\n            <a href=\"/\">\\n                <img alt=\"DataCamp Help Center\" src=\"https://downloads.intercomcdn.com/i/o/81221/856b63d438031754b681746b/4ea2737e4266936fb423911d9c587812.png\" />\\n            </a>\\n          </div>\\n        </div>\\n        <div class=\"mo__aside\">\\n          <div class=\"header__home__url\">\\n              <a target=\"_blank\" rel=\\'noopener\\' href=\"http://www.datacamp.com/teach\"><svg width=\"14\" height=\"14\" viewBox=\"0 0 14 14\" xmlns=\"http://www.w3.org/2000/svg\"><title>Group 65</title><g stroke=\"#FFF\" fill=\"none\" fill-rule=\"evenodd\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M11.5 6.73v6.77H.5v-11h7.615M4.5 9.5l7-7M13.5 5.5v-5h-5\"/></g></svg><span>Go to DataCamp</span></a>\\n          </div>\\n        </div>\\n      </div>\\n          <h1 class=\"header__headline\">Advice and answers from the DataCamp Team</h1>\\n        <form action=\"/\" autocomplete=\"off\" class=\"header__form search\">\\n          <input type=\"text\" autocomplete=\"off\" class=\"search__input js__search-input o__ltr\" placeholder=\"Search for answers...\" tabindex=\"1\" name=\"q\" value=\"\">\\n          <div class=\"search_icons\">\\n            <button type=\"submit\" class=\"search__submit o__ltr\"></button>\\n            <a class=\"search__clear-text__icon\">\\n              <svg class=\"interface-icon\" xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 16 16\">\\n                <path d=\"M8.018 6.643L5.375 4 4 5.375l2.643 2.643L4 10.643 5.375 12l2.643-2.625L10.625 12 12 10.643 9.357 8.018 12 5.375 10.643 4z\" />\\n              </svg>\\n            </a>\\n        </form>\\n      </div>\\n    </div>\\n  </div>\\n</header>\\n\\n    <div class=\"container\">\\n      <div class=\"content educate_content\"><section class=\"section\">\\n    <div class=\"g__space\">\\n      <a href=\"/getting-started\" class=\"paper \">\\n        <div class=\"collection o__ltr\">\\n          <div class=\"collection__photo\">\\n            <svg role=\\'img\\' viewBox=\\'0 0 48 48\\'><g id=\"chat-star\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linejoin=\"round\"><path d=\"M20 34.942c-2.083-.12-4.292-.42-6-.942L3 39l4-9c-3.858-3.086-6-7.246-6-12C1 8.61 10.328 1 21.835 1 33.343 1 43 8.61 43 18c0 1.044-.117 2.065-.342 3.057\"></path><path d=\"M36.016 25L40 33h7l-6 5 3 9-8-5.494L28 47l3-9-6-5h7l4.016-8z\"></path></g></svg>\\n          </div>\\n          <div class=\"collection_meta\" dir=\"ltr\">\\n            <h2 class=\"t__h3 c__primary\">Getting Started</h2>\\n            <p class=\"paper__preview\">Everything you need to know to begin your DataCamp journey!</p>\\n            <div class=\"avatar\">\\n  <div class=\"avatar__photo avatars__images o__ltr\">\\n        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2678519/square_128/pic2-1539176502.JPG?1539176502\" alt=\"Jen Bricker avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2637958/square_128/YR_Headshot-1539175806.JPG?1539175806\" alt=\"Yashas Roy avatar\" class=\"avatar__image\">\\n\\n      <span class=\"avatar__image avatar__fallback\">+2</span>\\n  </div>\\n  <div class=\"avatar__info\">\\n    <div>\\n      <span class=\"c__darker\">\\n        11 articles in this collection\\n      </span>\\n      <br>\\n      Written by <span class=\\'c__darker\\'> Becca Robins,</span> <span class=\\'c__darker\\'> Jen Bricker,</span> <span class=\\'c__darker\\'> Yashas Roy</span> and 2 others\\n    </div>\\n  </div>\\n</div>\\n\\n          </div>\\n        </div>\\n      </a>\\n    </div>\\n    <div class=\"g__space\">\\n      <a href=\"/courses\" class=\"paper \">\\n        <div class=\"collection o__ltr\">\\n          <div class=\"collection__photo\">\\n            <svg role=\\'img\\' viewBox=\\'0 0 48 48\\'><g id=\"devices-laptop\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linecap=\"round\"><path d=\"M41 31H7V11h34v20z\"></path><path d=\"M3 35V10a3 3 0 0 1 3-3h36a3 3 0 0 1 3 3v25m-16 0v2H19v-2H1v4a2 2 0 0 0 2 2h42a2 2 0 0 0 2-2v-4H29z\" stroke-linejoin=\"round\"></path></g></svg>\\n          </div>\\n          <div class=\"collection_meta\" dir=\"ltr\">\\n            <h2 class=\"t__h3 c__primary\">Courses</h2>\\n            <p class=\"paper__preview\">Everything you need to know about creating DataCamp courses.</p>\\n            <div class=\"avatar\">\\n  <div class=\"avatar__photo avatars__images o__ltr\">\\n        <img src=\"https://static.intercomassets.com/avatars/2637958/square_128/YR_Headshot-1539175806.JPG?1539175806\" alt=\"Yashas Roy avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2247397/square_128/IMG_2763_final_square_small-1532522734.jpg?1532522734\" alt=\"Nick Carchedi avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2298587/square_128/about_pic-1539247923.jpg?1539247923\" alt=\"Vincent Vankrunkelsven avatar\" class=\"avatar__image\">\\n\\n      <span class=\"avatar__image avatar__fallback\">+6</span>\\n  </div>\\n  <div class=\"avatar__info\">\\n    <div>\\n      <span class=\"c__darker\">\\n        73 articles in this collection\\n      </span>\\n      <br>\\n      Written by <span class=\\'c__darker\\'> Yashas Roy,</span> <span class=\\'c__darker\\'> Nick Carchedi,</span> <span class=\\'c__darker\\'> Vincent Vankrunkelsven</span> and 6 others\\n    </div>\\n  </div>\\n</div>\\n\\n          </div>\\n        </div>\\n      </a>\\n    </div>\\n    <div class=\"g__space\">\\n      <a href=\"/projects\" class=\"paper \">\\n        <div class=\"collection o__ltr\">\\n          <div class=\"collection__photo\">\\n            <svg role=\\'img\\' viewBox=\\'0 0 48 48\\'><g id=\"book-opened2\"><path d=\"M24 11c0-3.866 10.297-7 23-7v33c-12.703 0-23 3.134-23 7 0-3.866-10.3-7-23-7V4c12.7 0 23 3.134 23 7zm0 0v32m-5-27.52c-3.22-1.232-7.773-2.128-13-2.48m13 8.48c-3.22-1.232-7.773-2.128-13-2.48m13 8.48c-3.22-1.232-7.773-2.128-13-2.48m13 8.48c-3.22-1.23-7.773-2.127-13-2.48m23-15.52c3.223-1.232 7.773-2.128 13-2.48m-13 8.48c3.223-1.232 7.773-2.128 13-2.48m-13 8.48c3.223-1.232 7.773-2.128 13-2.48m-13 8.48c3.223-1.23 7.773-2.127 13-2.48\" stroke-width=\"2\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path></g></svg>\\n          </div>\\n          <div class=\"collection_meta\" dir=\"ltr\">\\n            <h2 class=\"t__h3 c__primary\">Projects</h2>\\n            <p class=\"paper__preview\">Everything you need to know about creating DataCamp projects.</p>\\n            <div class=\"avatar\">\\n  <div class=\"avatar__photo avatars__images o__ltr\">\\n        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2360843/square_128/20170928_DavidV_ByBBImagery-022-1380-1537479799.jpg?1537479799\" alt=\"David Venturi avatar\" class=\"avatar__image\">\\n\\n  </div>\\n  <div class=\"avatar__info\">\\n    <div>\\n      <span class=\"c__darker\">\\n        15 articles in this collection\\n      </span>\\n      <br>\\n      Written by <span class=\\'c__darker\\'> Becca Robins</span> and <span class=\\'c__darker\\'> David Venturi</span>\\n    </div>\\n  </div>\\n</div>\\n\\n          </div>\\n        </div>\\n      </a>\\n    </div>\\n    <div class=\"g__space\">\\n      <a href=\"/course-editor-basics\" class=\"paper \">\\n        <div class=\"collection o__ltr\">\\n          <div class=\"collection__photo\">\\n            <svg role=\\'img\\' viewBox=\\'0 0 48 48\\'><g id=\"book-bookmark\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linecap=\"round\"><path d=\"M35 31l-6-6-6 6V7h12v24z\"></path><path d=\"M35 9h6v38H11a4 4 0 0 1-4-4V5\" stroke-linejoin=\"round\"></path><path d=\"M39 9V1H11a4 4 0 0 0 0 8h12\" stroke-linejoin=\"round\"></path></g></svg>\\n          </div>\\n          <div class=\"collection_meta\" dir=\"ltr\">\\n            <h2 class=\"t__h3 c__primary\">Course Editor Basics</h2>\\n            <p class=\"paper__preview\">Everything you need to know to get going with our online course editor.</p>\\n            <div class=\"avatar\">\\n  <div class=\"avatar__photo avatars__images o__ltr\">\\n        <img src=\"https://static.intercomassets.com/avatars/2247397/square_128/IMG_2763_final_square_small-1532522734.jpg?1532522734\" alt=\"Nick Carchedi avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\\n\\n  </div>\\n  <div class=\"avatar__info\">\\n    <div>\\n      <span class=\"c__darker\">\\n        4 articles in this collection\\n      </span>\\n      <br>\\n      Written by <span class=\\'c__darker\\'> Nick Carchedi</span> and <span class=\\'c__darker\\'> Becca Robins</span>\\n    </div>\\n  </div>\\n</div>\\n\\n          </div>\\n        </div>\\n      </a>\\n    </div>\\n    <div class=\"g__space\">\\n      <a href=\"/tips-and-tricks\" class=\"paper \">\\n        <div class=\"collection o__ltr\">\\n          <div class=\"collection__photo\">\\n            <svg role=\\'img\\' viewBox=\\'0 0 48 48\\'><g id=\"comms-mail\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linejoin=\"round\"><path d=\"M47 3L1 22l18 7L47 3z\"></path><path d=\"M47 3l-8 37-20-11L47 3zM19 29v16l7-12\"></path></g></svg>\\n          </div>\\n          <div class=\"collection_meta\" dir=\"ltr\">\\n            <h2 class=\"t__h3 c__primary\">Tips &amp; Tricks</h2>\\n            <p class=\"paper__preview\">Become a DataCamp wizard!</p>\\n            <div class=\"avatar\">\\n  <div class=\"avatar__photo avatars__images o__ltr\">\\n        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\\n\\n  </div>\\n  <div class=\"avatar__info\">\\n    <div>\\n      <span class=\"c__darker\">\\n        6 articles in this collection\\n      </span>\\n      <br>\\n      Written by <span class=\\'c__darker\\'> Becca Robins</span>\\n    </div>\\n  </div>\\n</div>\\n\\n          </div>\\n        </div>\\n      </a>\\n    </div>\\n    <div class=\"g__space\">\\n      <a href=\"/frequently-asked-questions-faq\" class=\"paper \">\\n        <div class=\"collection o__ltr\">\\n          <div class=\"collection__photo\">\\n            <svg role=\\'img\\' viewBox=\\'0 0 48 48\\'><g id=\"chat-question\" fill=\"none\" fill-rule=\"evenodd\"><path d=\"M47 21.268c0 10.363-10.297 18.765-23 18.765-2.835 0-5.55-.418-8.058-1.184L2.725 45 7.9 34.668c-4.258-3.406-6.9-8.15-6.9-13.4C1 10.904 11.297 2.502 24 2.502s23 8.402 23 18.766z\" stroke-width=\"2\" stroke-linejoin=\"round\"></path><path d=\"M25 28.502a2 2 0 1 0 0 4 2 2 0 0 0 0-4\" fill=\"#231F1F\"></path><path d=\"M19 17.75c0-3.312 2.686-6.124 6-6.124 3.313 0 6 2.626 6 5.938 0 3.315-2.687 5.938-6 5.938V26\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path></g></svg>\\n          </div>\\n          <div class=\"collection_meta\" dir=\"ltr\">\\n            <h2 class=\"t__h3 c__primary\">Frequently Asked Questions (FAQ)</h2>\\n            <p class=\"paper__preview\">Common questions that arise during content creation.</p>\\n            <div class=\"avatar\">\\n  <div class=\"avatar__photo avatars__images o__ltr\">\\n        <img src=\"https://static.intercomassets.com/avatars/2366194/square_128/richie-in-hairnet-1537451295.JPG?1537451295\" alt=\"Richie Cotton avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2637958/square_128/YR_Headshot-1539175806.JPG?1539175806\" alt=\"Yashas Roy avatar\" class=\"avatar__image\">\\n\\n      <span class=\"avatar__image avatar__fallback\">+3</span>\\n  </div>\\n  <div class=\"avatar__info\">\\n    <div>\\n      <span class=\"c__darker\">\\n        47 articles in this collection\\n      </span>\\n      <br>\\n      Written by <span class=\\'c__darker\\'> Richie Cotton,</span> <span class=\\'c__darker\\'> Becca Robins,</span> <span class=\\'c__darker\\'> Yashas Roy</span> and 3 others\\n    </div>\\n  </div>\\n</div>\\n\\n          </div>\\n        </div>\\n      </a>\\n    </div>\\n    <div class=\"g__space\">\\n      <a href=\"/miscellaneous\" class=\"paper \">\\n        <div class=\"collection o__ltr\">\\n          <div class=\"collection__photo\">\\n            <svg role=\\'img\\' viewBox=\\'0 0 48 48\\'><g id=\"tools-edit\"><path d=\"M14.932 43.968L2 47l3.033-12.93 31.2-31.203a4 4 0 0 1 5.658 0l4.247 4.243a4 4 0 0 1 0 5.656L14.932 43.968zm29.84-29.735L34.82 4.28m7.125 12.782L31.992 7.11M15.436 43.465l-9.9-9.9\" stroke-width=\"2\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path></g></svg>\\n          </div>\\n          <div class=\"collection_meta\" dir=\"ltr\">\\n            <h2 class=\"t__h3 c__primary\">Miscellaneous</h2>\\n            <p class=\"paper__preview\">Have a question for DataCamp, but not about creating content? You&#39;ll probably find the answer here.</p>\\n            <div class=\"avatar\">\\n  <div class=\"avatar__photo avatars__images o__ltr\">\\n        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2830289/square_128/IMG_0665_a-1545331304.jpg?1545331304\" alt=\"Lisa Monteleone avatar\" class=\"avatar__image\">\\n\\n        <img src=\"https://static.intercomassets.com/avatars/2859053/square_128/gabriel_about_pic-1546620603.jpg?1546620603\" alt=\"Gabriel de Selding avatar\" class=\"avatar__image\">\\n\\n  </div>\\n  <div class=\"avatar__info\">\\n    <div>\\n      <span class=\"c__darker\">\\n        9 articles in this collection\\n      </span>\\n      <br>\\n      Written by <span class=\\'c__darker\\'> Becca Robins,</span> <span class=\\'c__darker\\'> Lisa Monteleone,</span> and <span class=\\'c__darker\\'> Gabriel de Selding</span>\\n    </div>\\n  </div>\\n</div>\\n\\n          </div>\\n        </div>\\n      </a>\\n    </div>\\n</section>\\n</div>\\n    </div>\\n    <footer class=\"footer\">\\n  <div class=\"container\">\\n    <div class=\"content\">\\n      <div class=\"u__cf\"  dir=\"ltr\">\\n        <div class=\"footer__logo\">\\n          <a href=\"/\">\\n              <img alt=\"DataCamp Help Center\" src=\"https://downloads.intercomcdn.com/i/o/81221/856b63d438031754b681746b/4ea2737e4266936fb423911d9c587812.png\" />\\n          </a>\\n        </div>\\n        <div class=\"footer__advert logo\">\\n          <img src=\"https://intercom.help/_assets/intercom-a6a6ac0f033657af1aebe2e9e15b94a3cd5eabf6ae8b9916df6ea49099a894d8.png\" alt=\"Intercom\" />\\n          <a href=\"https://www.intercom.com/intercom-link?company=DataCamp&amp;solution=customer-support&amp;utm_campaign=intercom-link&amp;utm_content=We+run+on+Intercom&amp;utm_medium=help-center&amp;utm_referrer=http%3A%2F%2Finstructor-support.datacamp.com%2F&amp;utm_source=desktop-web\">We run on Intercom</a>\\n        </div>\\n      </div>\\n    </div>\\n  </div>\\n</footer>\\n\\n    \\n  <script nonce=\"iBhG1aBK559vFuuIJC/jx2zCoI0f+e1mnOuF73KIJ/s=\">\\n    window.intercomSettings = {\"app_id\":\"ug0ps1rq\"};\\n</script>\\n  <script nonce=\"iBhG1aBK559vFuuIJC/jx2zCoI0f+e1mnOuF73KIJ/s=\">\\n    (function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic(\\'reattach_activator\\');ic(\\'update\\',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement(\\'script\\');s.type=\\'text/javascript\\';s.async=true;s.src=\"https://widget.intercom.io/widget/ug0ps1rq\";var x=d.getElementsByTagName(\\'script\\')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent(\\'onload\\',l);}else{w.addEventListener(\\'load\\',l,false);}}})()\\n</script>\\n\\n    \\n\\n    <script src=\"https://intercom.help/_assets/application-809c5f9ba0b658f344176473e8aaba9ba50950ba4af2d0b79bafeeb1f69f77fd.js\" nonce=\"iBhG1aBK559vFuuIJC/jx2zCoI0f+e1mnOuF73KIJ/s=\"></script>\\n  </body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# This packages the request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Extract the response: html\n",
    "html = response.read()\n",
    "\n",
    "# Print the html\n",
    "print(html)\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing HTTP requests in Python using requests\n",
    "#### Now that you've got your head and hands around making HTTP requests using the urllib package, you're going to figure out how to do the same using the higher-level requests library. You'll once again be pinging DataCamp servers for their \"http://www.datacamp.com/teach/documentation\" page.\n",
    "#### Note that unlike in the previous exercises using urllib, you don't have to close the connection when using requests!\n",
    "\n",
    "* Import the package requests.\n",
    "* Assign the URL of interest to the variable url.\n",
    "* Package the request to the URL, send the request and catch the response with a single function requests.get(), assigning the response to the variable r.\n",
    "* Use the text attribute of the object r to return the HTML of the webpage as a string; store the result in a variable text.\n",
    "* Hit submit to print the HTML of the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=\"en\" data-direction=\"ltr\">\n",
      "  <head>\n",
      "    <link href=\"https://fonts.intercomcdn.com\" rel=\"preconnect\" crossorigin>\n",
      "      <script src=\"https://www.googletagmanager.com/gtag/js?id=UA-39297847-9\" async=\"async\" nonce=\"Y0xe7oVnJe+w2ubdZ8hqIy35hkk71h8yjc0n6/Wxxu4=\"></script>\n",
      "      <script nonce=\"Y0xe7oVnJe+w2ubdZ8hqIy35hkk71h8yjc0n6/Wxxu4=\">\n",
      "        window.dataLayer = window.dataLayer || [];\n",
      "        function gtag(){dataLayer.push(arguments);}\n",
      "        gtag('js', new Date());\n",
      "        gtag('config', 'UA-39297847-9');\n",
      "</script>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "    <title>DataCamp Help Center</title>\n",
      "    <meta name=\"description\" content=\"\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "      <meta name=\"intercom:trackingEvent\" content=\"{&quot;name&quot;:&quot;Viewed Help Center&quot;,&quot;metadata&quot;:{&quot;action&quot;:&quot;viewed&quot;,&quot;object&quot;:&quot;educate_home&quot;,&quot;place&quot;:&quot;help_center&quot;,&quot;owner&quot;:&quot;educate&quot;}}\" />\n",
      "\n",
      "    <link rel=\"stylesheet\" media=\"all\" href=\"https://intercom.help/_assets/application-cf96f613358ad1f77fb9ea03098706a52f28f50d9c46df57184f74e53e1941ba.css\" />\n",
      "    <link rel=\"canonical\" href=\"http://instructor-support.datacamp.com/\"/>\n",
      "\n",
      "        <link href=\"https://static.intercomassets.com/assets/educate/educate-favicon-64x64-at-2x-52016a3500a250d0b118c0a04ddd13b1a7364a27759483536dd1940bccdefc20.png\" rel=\"shortcut icon\" type=\"image/png\" />\n",
      "      <style>\n",
      "        .header, .avatar__image-extra { background-color: #263e63; }\n",
      "        .article a, .c__primary { color: #263e63; }\n",
      "        .avatar__fallback { background-color: #263e63; }\n",
      "        article a.intercom-h2b-button { background-color: #263e63; border: 0; }\n",
      "      </style>\n",
      "\n",
      "      <meta property=\"og:title\" content=\"DataCamp Help Center\" />\n",
      "  <meta name=\"twitter:title\" content=\"DataCamp Help Center\" />\n",
      "\n",
      "\n",
      "<meta property=\"og:type\" content=\"website\" />\n",
      "<meta property=\"og:image\" content=\"\" />\n",
      "\n",
      "<meta name=\"twitter:image\" content=\"\" />\n",
      "\n",
      "  </head>\n",
      "  <body class=\"\">\n",
      "    <header class=\"header\">\n",
      "  <div class=\"container header__container o__ltr\" dir=\"ltr\">\n",
      "    <div class=\"content\">\n",
      "      <div class=\"mo o__centered o__reversed header__meta_wrapper\">\n",
      "        <div class=\"mo__body\">\n",
      "          <div class=\"header__logo\">\n",
      "            <a href=\"/\">\n",
      "                <img alt=\"DataCamp Help Center\" src=\"https://downloads.intercomcdn.com/i/o/81221/856b63d438031754b681746b/4ea2737e4266936fb423911d9c587812.png\" />\n",
      "            </a>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"mo__aside\">\n",
      "          <div class=\"header__home__url\">\n",
      "              <a target=\"_blank\" rel='noopener' href=\"http://www.datacamp.com/teach\"><svg width=\"14\" height=\"14\" viewBox=\"0 0 14 14\" xmlns=\"http://www.w3.org/2000/svg\"><title>Group 65</title><g stroke=\"#FFF\" fill=\"none\" fill-rule=\"evenodd\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M11.5 6.73v6.77H.5v-11h7.615M4.5 9.5l7-7M13.5 5.5v-5h-5\"/></g></svg><span>Go to DataCamp</span></a>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "          <h1 class=\"header__headline\">Advice and answers from the DataCamp Team</h1>\n",
      "        <form action=\"/\" autocomplete=\"off\" class=\"header__form search\">\n",
      "          <input type=\"text\" autocomplete=\"off\" class=\"search__input js__search-input o__ltr\" placeholder=\"Search for answers...\" tabindex=\"1\" name=\"q\" value=\"\">\n",
      "          <div class=\"search_icons\">\n",
      "            <button type=\"submit\" class=\"search__submit o__ltr\"></button>\n",
      "            <a class=\"search__clear-text__icon\">\n",
      "              <svg class=\"interface-icon\" xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 16 16\">\n",
      "                <path d=\"M8.018 6.643L5.375 4 4 5.375l2.643 2.643L4 10.643 5.375 12l2.643-2.625L10.625 12 12 10.643 9.357 8.018 12 5.375 10.643 4z\" />\n",
      "              </svg>\n",
      "            </a>\n",
      "        </form>\n",
      "      </div>\n",
      "    </div>\n",
      "  </div>\n",
      "</header>\n",
      "\n",
      "    <div class=\"container\">\n",
      "      <div class=\"content educate_content\"><section class=\"section\">\n",
      "    <div class=\"g__space\">\n",
      "      <a href=\"/getting-started\" class=\"paper \">\n",
      "        <div class=\"collection o__ltr\">\n",
      "          <div class=\"collection__photo\">\n",
      "            <svg role='img' viewBox='0 0 48 48'><g id=\"chat-star\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linejoin=\"round\"><path d=\"M20 34.942c-2.083-.12-4.292-.42-6-.942L3 39l4-9c-3.858-3.086-6-7.246-6-12C1 8.61 10.328 1 21.835 1 33.343 1 43 8.61 43 18c0 1.044-.117 2.065-.342 3.057\"></path><path d=\"M36.016 25L40 33h7l-6 5 3 9-8-5.494L28 47l3-9-6-5h7l4.016-8z\"></path></g></svg>\n",
      "          </div>\n",
      "          <div class=\"collection_meta\" dir=\"ltr\">\n",
      "            <h2 class=\"t__h3 c__primary\">Getting Started</h2>\n",
      "            <p class=\"paper__preview\">Everything you need to know to begin your DataCamp journey!</p>\n",
      "            <div class=\"avatar\">\n",
      "  <div class=\"avatar__photo avatars__images o__ltr\">\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2678519/square_128/pic2-1539176502.JPG?1539176502\" alt=\"Jen Bricker avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2637958/square_128/YR_Headshot-1539175806.JPG?1539175806\" alt=\"Yashas Roy avatar\" class=\"avatar__image\">\n",
      "\n",
      "      <span class=\"avatar__image avatar__fallback\">+2</span>\n",
      "  </div>\n",
      "  <div class=\"avatar__info\">\n",
      "    <div>\n",
      "      <span class=\"c__darker\">\n",
      "        11 articles in this collection\n",
      "      </span>\n",
      "      <br>\n",
      "      Written by <span class='c__darker'> Becca Robins,</span> <span class='c__darker'> Jen Bricker,</span> <span class='c__darker'> Yashas Roy</span> and 2 others\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "\n",
      "          </div>\n",
      "        </div>\n",
      "      </a>\n",
      "    </div>\n",
      "    <div class=\"g__space\">\n",
      "      <a href=\"/courses\" class=\"paper \">\n",
      "        <div class=\"collection o__ltr\">\n",
      "          <div class=\"collection__photo\">\n",
      "            <svg role='img' viewBox='0 0 48 48'><g id=\"devices-laptop\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linecap=\"round\"><path d=\"M41 31H7V11h34v20z\"></path><path d=\"M3 35V10a3 3 0 0 1 3-3h36a3 3 0 0 1 3 3v25m-16 0v2H19v-2H1v4a2 2 0 0 0 2 2h42a2 2 0 0 0 2-2v-4H29z\" stroke-linejoin=\"round\"></path></g></svg>\n",
      "          </div>\n",
      "          <div class=\"collection_meta\" dir=\"ltr\">\n",
      "            <h2 class=\"t__h3 c__primary\">Courses</h2>\n",
      "            <p class=\"paper__preview\">Everything you need to know about creating DataCamp courses.</p>\n",
      "            <div class=\"avatar\">\n",
      "  <div class=\"avatar__photo avatars__images o__ltr\">\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2637958/square_128/YR_Headshot-1539175806.JPG?1539175806\" alt=\"Yashas Roy avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2247397/square_128/IMG_2763_final_square_small-1532522734.jpg?1532522734\" alt=\"Nick Carchedi avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2298587/square_128/about_pic-1539247923.jpg?1539247923\" alt=\"Vincent Vankrunkelsven avatar\" class=\"avatar__image\">\n",
      "\n",
      "      <span class=\"avatar__image avatar__fallback\">+6</span>\n",
      "  </div>\n",
      "  <div class=\"avatar__info\">\n",
      "    <div>\n",
      "      <span class=\"c__darker\">\n",
      "        73 articles in this collection\n",
      "      </span>\n",
      "      <br>\n",
      "      Written by <span class='c__darker'> Yashas Roy,</span> <span class='c__darker'> Nick Carchedi,</span> <span class='c__darker'> Vincent Vankrunkelsven</span> and 6 others\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "\n",
      "          </div>\n",
      "        </div>\n",
      "      </a>\n",
      "    </div>\n",
      "    <div class=\"g__space\">\n",
      "      <a href=\"/projects\" class=\"paper \">\n",
      "        <div class=\"collection o__ltr\">\n",
      "          <div class=\"collection__photo\">\n",
      "            <svg role='img' viewBox='0 0 48 48'><g id=\"book-opened2\"><path d=\"M24 11c0-3.866 10.297-7 23-7v33c-12.703 0-23 3.134-23 7 0-3.866-10.3-7-23-7V4c12.7 0 23 3.134 23 7zm0 0v32m-5-27.52c-3.22-1.232-7.773-2.128-13-2.48m13 8.48c-3.22-1.232-7.773-2.128-13-2.48m13 8.48c-3.22-1.232-7.773-2.128-13-2.48m13 8.48c-3.22-1.23-7.773-2.127-13-2.48m23-15.52c3.223-1.232 7.773-2.128 13-2.48m-13 8.48c3.223-1.232 7.773-2.128 13-2.48m-13 8.48c3.223-1.232 7.773-2.128 13-2.48m-13 8.48c3.223-1.23 7.773-2.127 13-2.48\" stroke-width=\"2\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path></g></svg>\n",
      "          </div>\n",
      "          <div class=\"collection_meta\" dir=\"ltr\">\n",
      "            <h2 class=\"t__h3 c__primary\">Projects</h2>\n",
      "            <p class=\"paper__preview\">Everything you need to know about creating DataCamp projects.</p>\n",
      "            <div class=\"avatar\">\n",
      "  <div class=\"avatar__photo avatars__images o__ltr\">\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2360843/square_128/20170928_DavidV_ByBBImagery-022-1380-1537479799.jpg?1537479799\" alt=\"David Venturi avatar\" class=\"avatar__image\">\n",
      "\n",
      "  </div>\n",
      "  <div class=\"avatar__info\">\n",
      "    <div>\n",
      "      <span class=\"c__darker\">\n",
      "        15 articles in this collection\n",
      "      </span>\n",
      "      <br>\n",
      "      Written by <span class='c__darker'> Becca Robins</span> and <span class='c__darker'> David Venturi</span>\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "\n",
      "          </div>\n",
      "        </div>\n",
      "      </a>\n",
      "    </div>\n",
      "    <div class=\"g__space\">\n",
      "      <a href=\"/course-editor-basics\" class=\"paper \">\n",
      "        <div class=\"collection o__ltr\">\n",
      "          <div class=\"collection__photo\">\n",
      "            <svg role='img' viewBox='0 0 48 48'><g id=\"book-bookmark\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linecap=\"round\"><path d=\"M35 31l-6-6-6 6V7h12v24z\"></path><path d=\"M35 9h6v38H11a4 4 0 0 1-4-4V5\" stroke-linejoin=\"round\"></path><path d=\"M39 9V1H11a4 4 0 0 0 0 8h12\" stroke-linejoin=\"round\"></path></g></svg>\n",
      "          </div>\n",
      "          <div class=\"collection_meta\" dir=\"ltr\">\n",
      "            <h2 class=\"t__h3 c__primary\">Course Editor Basics</h2>\n",
      "            <p class=\"paper__preview\">Everything you need to know to get going with our online course editor.</p>\n",
      "            <div class=\"avatar\">\n",
      "  <div class=\"avatar__photo avatars__images o__ltr\">\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2247397/square_128/IMG_2763_final_square_small-1532522734.jpg?1532522734\" alt=\"Nick Carchedi avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\n",
      "\n",
      "  </div>\n",
      "  <div class=\"avatar__info\">\n",
      "    <div>\n",
      "      <span class=\"c__darker\">\n",
      "        4 articles in this collection\n",
      "      </span>\n",
      "      <br>\n",
      "      Written by <span class='c__darker'> Nick Carchedi</span> and <span class='c__darker'> Becca Robins</span>\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "\n",
      "          </div>\n",
      "        </div>\n",
      "      </a>\n",
      "    </div>\n",
      "    <div class=\"g__space\">\n",
      "      <a href=\"/tips-and-tricks\" class=\"paper \">\n",
      "        <div class=\"collection o__ltr\">\n",
      "          <div class=\"collection__photo\">\n",
      "            <svg role='img' viewBox='0 0 48 48'><g id=\"comms-mail\" stroke-width=\"2\" fill=\"none\" fill-rule=\"evenodd\" stroke-linejoin=\"round\"><path d=\"M47 3L1 22l18 7L47 3z\"></path><path d=\"M47 3l-8 37-20-11L47 3zM19 29v16l7-12\"></path></g></svg>\n",
      "          </div>\n",
      "          <div class=\"collection_meta\" dir=\"ltr\">\n",
      "            <h2 class=\"t__h3 c__primary\">Tips &amp; Tricks</h2>\n",
      "            <p class=\"paper__preview\">Become a DataCamp wizard!</p>\n",
      "            <div class=\"avatar\">\n",
      "  <div class=\"avatar__photo avatars__images o__ltr\">\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\n",
      "\n",
      "  </div>\n",
      "  <div class=\"avatar__info\">\n",
      "    <div>\n",
      "      <span class=\"c__darker\">\n",
      "        6 articles in this collection\n",
      "      </span>\n",
      "      <br>\n",
      "      Written by <span class='c__darker'> Becca Robins</span>\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "\n",
      "          </div>\n",
      "        </div>\n",
      "      </a>\n",
      "    </div>\n",
      "    <div class=\"g__space\">\n",
      "      <a href=\"/frequently-asked-questions-faq\" class=\"paper \">\n",
      "        <div class=\"collection o__ltr\">\n",
      "          <div class=\"collection__photo\">\n",
      "            <svg role='img' viewBox='0 0 48 48'><g id=\"chat-question\" fill=\"none\" fill-rule=\"evenodd\"><path d=\"M47 21.268c0 10.363-10.297 18.765-23 18.765-2.835 0-5.55-.418-8.058-1.184L2.725 45 7.9 34.668c-4.258-3.406-6.9-8.15-6.9-13.4C1 10.904 11.297 2.502 24 2.502s23 8.402 23 18.766z\" stroke-width=\"2\" stroke-linejoin=\"round\"></path><path d=\"M25 28.502a2 2 0 1 0 0 4 2 2 0 0 0 0-4\" fill=\"#231F1F\"></path><path d=\"M19 17.75c0-3.312 2.686-6.124 6-6.124 3.313 0 6 2.626 6 5.938 0 3.315-2.687 5.938-6 5.938V26\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path></g></svg>\n",
      "          </div>\n",
      "          <div class=\"collection_meta\" dir=\"ltr\">\n",
      "            <h2 class=\"t__h3 c__primary\">Frequently Asked Questions (FAQ)</h2>\n",
      "            <p class=\"paper__preview\">Common questions that arise during content creation.</p>\n",
      "            <div class=\"avatar\">\n",
      "  <div class=\"avatar__photo avatars__images o__ltr\">\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2366194/square_128/richie-in-hairnet-1537451295.JPG?1537451295\" alt=\"Richie Cotton avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2637958/square_128/YR_Headshot-1539175806.JPG?1539175806\" alt=\"Yashas Roy avatar\" class=\"avatar__image\">\n",
      "\n",
      "      <span class=\"avatar__image avatar__fallback\">+3</span>\n",
      "  </div>\n",
      "  <div class=\"avatar__info\">\n",
      "    <div>\n",
      "      <span class=\"c__darker\">\n",
      "        47 articles in this collection\n",
      "      </span>\n",
      "      <br>\n",
      "      Written by <span class='c__darker'> Richie Cotton,</span> <span class='c__darker'> Becca Robins,</span> <span class='c__darker'> Yashas Roy</span> and 3 others\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "\n",
      "          </div>\n",
      "        </div>\n",
      "      </a>\n",
      "    </div>\n",
      "    <div class=\"g__space\">\n",
      "      <a href=\"/miscellaneous\" class=\"paper \">\n",
      "        <div class=\"collection o__ltr\">\n",
      "          <div class=\"collection__photo\">\n",
      "            <svg role='img' viewBox='0 0 48 48'><g id=\"tools-edit\"><path d=\"M14.932 43.968L2 47l3.033-12.93 31.2-31.203a4 4 0 0 1 5.658 0l4.247 4.243a4 4 0 0 1 0 5.656L14.932 43.968zm29.84-29.735L34.82 4.28m7.125 12.782L31.992 7.11M15.436 43.465l-9.9-9.9\" stroke-width=\"2\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path></g></svg>\n",
      "          </div>\n",
      "          <div class=\"collection_meta\" dir=\"ltr\">\n",
      "            <h2 class=\"t__h3 c__primary\">Miscellaneous</h2>\n",
      "            <p class=\"paper__preview\">Have a question for DataCamp, but not about creating content? You&#39;ll probably find the answer here.</p>\n",
      "            <div class=\"avatar\">\n",
      "  <div class=\"avatar__photo avatars__images o__ltr\">\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2352718/square_128/Rebecca_Robins_-_Headshot-1535969735.jpg?1535969735\" alt=\"Becca Robins avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2830289/square_128/IMG_0665_a-1545331304.jpg?1545331304\" alt=\"Lisa Monteleone avatar\" class=\"avatar__image\">\n",
      "\n",
      "        <img src=\"https://static.intercomassets.com/avatars/2859053/square_128/gabriel_about_pic-1546620603.jpg?1546620603\" alt=\"Gabriel de Selding avatar\" class=\"avatar__image\">\n",
      "\n",
      "  </div>\n",
      "  <div class=\"avatar__info\">\n",
      "    <div>\n",
      "      <span class=\"c__darker\">\n",
      "        9 articles in this collection\n",
      "      </span>\n",
      "      <br>\n",
      "      Written by <span class='c__darker'> Becca Robins,</span> <span class='c__darker'> Lisa Monteleone,</span> and <span class='c__darker'> Gabriel de Selding</span>\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "\n",
      "          </div>\n",
      "        </div>\n",
      "      </a>\n",
      "    </div>\n",
      "</section>\n",
      "</div>\n",
      "    </div>\n",
      "    <footer class=\"footer\">\n",
      "  <div class=\"container\">\n",
      "    <div class=\"content\">\n",
      "      <div class=\"u__cf\"  dir=\"ltr\">\n",
      "        <div class=\"footer__logo\">\n",
      "          <a href=\"/\">\n",
      "              <img alt=\"DataCamp Help Center\" src=\"https://downloads.intercomcdn.com/i/o/81221/856b63d438031754b681746b/4ea2737e4266936fb423911d9c587812.png\" />\n",
      "          </a>\n",
      "        </div>\n",
      "        <div class=\"footer__advert logo\">\n",
      "          <img src=\"https://intercom.help/_assets/intercom-a6a6ac0f033657af1aebe2e9e15b94a3cd5eabf6ae8b9916df6ea49099a894d8.png\" alt=\"Intercom\" />\n",
      "          <a href=\"https://www.intercom.com/intercom-link?company=DataCamp&amp;solution=customer-support&amp;utm_campaign=intercom-link&amp;utm_content=We+run+on+Intercom&amp;utm_medium=help-center&amp;utm_referrer=http%3A%2F%2Finstructor-support.datacamp.com%2F&amp;utm_source=desktop-web\">We run on Intercom</a>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div>\n",
      "  </div>\n",
      "</footer>\n",
      "\n",
      "    \n",
      "  <script nonce=\"Y0xe7oVnJe+w2ubdZ8hqIy35hkk71h8yjc0n6/Wxxu4=\">\n",
      "    window.intercomSettings = {\"app_id\":\"ug0ps1rq\"};\n",
      "</script>\n",
      "  <script nonce=\"Y0xe7oVnJe+w2ubdZ8hqIy35hkk71h8yjc0n6/Wxxu4=\">\n",
      "    (function(){var w=window;var ic=w.Intercom;if(typeof ic===\"function\"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src=\"https://widget.intercom.io/widget/ug0ps1rq\";var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}}})()\n",
      "</script>\n",
      "\n",
      "    \n",
      "\n",
      "    <script src=\"https://intercom.help/_assets/application-809c5f9ba0b658f344176473e8aaba9ba50950ba4af2d0b79bafeeb1f69f77fd.js\" nonce=\"Y0xe7oVnJe+w2ubdZ8hqIy35hkk71h8yjc0n6/Wxxu4=\"></script>\n",
      "  </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Specify the url: url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response: text\n",
    "text = r.text\n",
    "\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the web in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "* Mix of unstructured and structured data\n",
    "* Structured data:\n",
    "    * Has pre-defined data model, or\n",
    "    * Organized in a defined manner\n",
    "* Unstructured data: neither of these properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "* Parse and extract structured data from HTML\n",
    "* \"https://www.crummy.com/software/BeautifulSoup/\"\n",
    "* Make tag soup beautiful and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = 'https://www.crummy.com/software/BeautifulSoup/'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n",
      "\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <title>\n",
      "   Beautiful Soup: We called him Tortoise because he taught us.\n",
      "  </title>\n",
      "  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "  <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      " </head>\n",
      " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\n",
      "  <br/>\n",
      "  <p>\n",
      "   You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "  </p>\n",
      "  <div align=\"center\">\n",
      "   <a href=\"bs4/download/\">\n",
      "    <h1>\n",
      "     Beautiful Soup\n",
      "    </h1>\n",
      "   </a>\n",
      "   <p>\n",
      "    \"A tremendous boon.\" -- Python411 Podcast\n",
      "   </p>\n",
      "   <p>\n",
      "    [\n",
      "    <a href=\"#Download\">\n",
      "     Download\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"bs4/doc/\">\n",
      "     Documentation\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"#HallOfFame\">\n",
      "     Hall of Fame\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://code.launchpad.net/beautifulsoup\">\n",
      "     Source\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">\n",
      "     Changelog\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "     Discussion group\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"zine/\">\n",
      "     Zine\n",
      "    </a>\n",
      "    ]\n",
      "   </p>\n",
      "   <p>\n",
      "    <small>\n",
      "     If you use Beautiful Soup as part of your work, please consider a\n",
      "     <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "      Tidelift subscription\n",
      "     </a>\n",
      "     . This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "     <p>\n",
      "      If Beautiful Soup is useful to you on a personal level, you might like to read\n",
      "      <a href=\"zine/\">\n",
      "       <i>\n",
      "        Tool Safety\n",
      "       </i>\n",
      "      </a>\n",
      "      , a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "     </p>\n",
      "    </small>\n",
      "   </p>\n",
      "  </div>\n",
      "  <p>\n",
      "   <i>\n",
      "    If you have questions, send them to\n",
      "    <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "     the discussion\n",
      "group\n",
      "    </a>\n",
      "    . If you find a bug,\n",
      "    <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "     file it\n",
      "    </a>\n",
      "    .\n",
      "   </i>\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "   <ol>\n",
      "    <li>\n",
      "     Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "     <li>\n",
      "      Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "      <li>\n",
      "       Beautiful Soup sits on top of popular Python parsers like\n",
      "       <a href=\"http://lxml.de/\">\n",
      "        lxml\n",
      "       </a>\n",
      "       and\n",
      "       <a href=\"http://code.google.com/p/html5lib/\">\n",
      "        html5lib\n",
      "       </a>\n",
      "       , allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "      </li>\n",
      "     </li>\n",
      "    </li>\n",
      "   </ol>\n",
      "   <p>\n",
      "    Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class\n",
      "    <tt>\n",
      "     externalLink\n",
      "    </tt>\n",
      "    \", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "    <p>\n",
      "     Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "     <p>\n",
      "      Interested?\n",
      "      <a href=\"bs4/doc/\">\n",
      "       Read more.\n",
      "      </a>\n",
      "      <a name=\"Download\">\n",
      "       <h2>\n",
      "        Download Beautiful Soup\n",
      "       </h2>\n",
      "      </a>\n",
      "      <p>\n",
      "       The current release is\n",
      "       <a href=\"bs4/download/\">\n",
      "        Beautiful Soup\n",
      "4.7.1\n",
      "       </a>\n",
      "       (January 6, 2019). You can install Beautiful Soup 4 with\n",
      "       <code>\n",
      "        pip install beautifulsoup4\n",
      "       </code>\n",
      "       .\n",
      "       <p>\n",
      "        In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "        <code>\n",
      "         python-bs4\n",
      "        </code>\n",
      "        package (for Python 2) or the\n",
      "        <code>\n",
      "         python3-bs4\n",
      "        </code>\n",
      "        package (for Python 3). In Fedora it's\n",
      "available as the\n",
      "        <code>\n",
      "         python-beautifulsoup4\n",
      "        </code>\n",
      "        package.\n",
      "        <p>\n",
      "         Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the\n",
      "         <code>\n",
      "          bs4/\n",
      "         </code>\n",
      "         directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using\n",
      "         <code>\n",
      "          2to3\n",
      "         </code>\n",
      "         .)\n",
      "         <p>\n",
      "          Beautiful Soup 4 works on both Python 2 (2.7+) and Python 3.\n",
      "          <h3>\n",
      "           Beautiful Soup 3\n",
      "          </h3>\n",
      "          <p>\n",
      "           Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It is considered stable, and only\n",
      "critical security bugs will be fixed.\n",
      "           <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\n",
      "            Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "           </a>\n",
      "           <p>\n",
      "            Beautiful Soup 3 works only under Python 2.x. It is licensed under\n",
      "the same license as Python itself.\n",
      "            <p>\n",
      "             The current release of Beautiful Soup 3 is\n",
      "             <a href=\"download/3.x/BeautifulSoup-3.2.1.tar.gz\">\n",
      "              3.2.1\n",
      "             </a>\n",
      "             (February 16,\n",
      "2012). You can install Beautiful Soup 3 with\n",
      "             <code>\n",
      "              pip install\n",
      "BeautifulSoup\n",
      "             </code>\n",
      "             . It's also available as\n",
      "             <code>\n",
      "              python-beautifulsoup\n",
      "             </code>\n",
      "             in Debian and Ubuntu, and as\n",
      "             <code>\n",
      "              python-BeautifulSoup\n",
      "             </code>\n",
      "             in Fedora.\n",
      "             <p>\n",
      "              You can also download the tarball and use\n",
      "              <code>\n",
      "               BeautifulSoup.py\n",
      "              </code>\n",
      "              in your project directly.\n",
      "              <a name=\"HallOfFame\">\n",
      "               <h2>\n",
      "                Hall of Fame\n",
      "               </h2>\n",
      "              </a>\n",
      "              <p>\n",
      "               Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "               <ul>\n",
      "                <li>\n",
      "                 <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\n",
      "                  \"Movable\n",
      " Type\"\n",
      "                 </a>\n",
      "                 , a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "                 <li>\n",
      "                  Reddit uses Beautiful Soup to\n",
      "                  <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\n",
      "                   parse\n",
      "a page that's been linked to and find a representative image\n",
      "                  </a>\n",
      "                  .\n",
      "                  <li>\n",
      "                   Alexander Harrowell uses Beautiful Soup to\n",
      "                   <a href=\"http://www.harrowell.org.uk/viktormap.html\">\n",
      "                    track the business\n",
      " activities\n",
      "                   </a>\n",
      "                   of an arms merchant.\n",
      "                   <li>\n",
      "                    The developers of Python itself used Beautiful Soup to\n",
      "                    <a href=\"http://svn.python.org/view/tracker/importer/\">\n",
      "                     migrate the Python\n",
      "bug tracker from Sourceforge to Roundup\n",
      "                    </a>\n",
      "                    .\n",
      "                    <li>\n",
      "                     The\n",
      "                     <a href=\"http://www2.ljworld.com/\">\n",
      "                      Lawrence Journal-World\n",
      "                     </a>\n",
      "                     uses Beautiful Soup to\n",
      "                     <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\n",
      "                      gather\n",
      "statewide election results\n",
      "                     </a>\n",
      "                     .\n",
      "                     <li>\n",
      "                      The\n",
      "                      <a href=\"http://esrl.noaa.gov/gsd/fab/\">\n",
      "                       NOAA's Forecast\n",
      "Applications Branch\n",
      "                      </a>\n",
      "                      uses Beautiful Soup in\n",
      "                      <a href=\"http://laps.noaa.gov/topograbber/\">\n",
      "                       TopoGrabber\n",
      "                      </a>\n",
      "                      , a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "                     </li>\n",
      "                    </li>\n",
      "                   </li>\n",
      "                  </li>\n",
      "                 </li>\n",
      "                </li>\n",
      "               </ul>\n",
      "               <p>\n",
      "                If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or\n",
      "                <a href=\"http://groups.google.com/group/beautifulsoup/\">\n",
      "                 the discussion\n",
      "group\n",
      "                </a>\n",
      "                .\n",
      "                <h2>\n",
      "                 Development\n",
      "                </h2>\n",
      "                <p>\n",
      "                 Development happens at\n",
      "                 <a href=\"https://launchpad.net/beautifulsoup\">\n",
      "                  Launchpad\n",
      "                 </a>\n",
      "                 . You can\n",
      "                 <a href=\"https://code.launchpad.net/beautifulsoup/\">\n",
      "                  get the source\n",
      "code\n",
      "                 </a>\n",
      "                 or\n",
      "                 <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "                  file\n",
      "bugs\n",
      "                 </a>\n",
      "                 .\n",
      "                 <hr/>\n",
      "                 <table>\n",
      "                  <tr>\n",
      "                   <td valign=\"top\">\n",
      "                    <p>\n",
      "                     This document (\n",
      "                     <a href=\"/source/software/BeautifulSoup/index.bhtml\">\n",
      "                      source\n",
      "                     </a>\n",
      "                     ) is part of Crummy, the webspace of\n",
      "                     <a href=\"/self/\">\n",
      "                      Leonard Richardson\n",
      "                     </a>\n",
      "                     (\n",
      "                     <a href=\"/self/contact.html\">\n",
      "                      contact information\n",
      "                     </a>\n",
      "                     ). It was last modified on Monday, January 07 2019, 00:54:05 Nowhere Standard Time and last built on Thursday, January 17 2019, 18:00:01 Nowhere Standard Time.\n",
      "                    </p>\n",
      "                    <p>\n",
      "                     <table class=\"licenseText\">\n",
      "                      <tr>\n",
      "                       <td>\n",
      "                        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "                         <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\n",
      "                        </a>\n",
      "                       </td>\n",
      "                       <td valign=\"top\">\n",
      "                        Crummy is © 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a\n",
      "                        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "                         Creative Commons License\n",
      "                        </a>\n",
      "                        .\n",
      "                       </td>\n",
      "                      </tr>\n",
      "                     </table>\n",
      "                    </p>\n",
      "                   </td>\n",
      "                  </tr>\n",
      "                 </table>\n",
      "                </p>\n",
      "               </p>\n",
      "              </p>\n",
      "             </p>\n",
      "            </p>\n",
      "           </p>\n",
      "          </p>\n",
      "         </p>\n",
      "        </p>\n",
      "       </p>\n",
      "      </p>\n",
      "     </p>\n",
      "    </p>\n",
      "   </p>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "<!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\n",
      "<td valign=\"top\">\n",
      " <p>\n",
      "  <b>\n",
      "   Document tree:\n",
      "  </b>\n",
      "  <dl>\n",
      "   <dd>\n",
      "    <a href=\"http://www.crummy.com/\">\n",
      "     http://www.crummy.com/\n",
      "    </a>\n",
      "    <dl>\n",
      "     <dd>\n",
      "      <a href=\"http://www.crummy.com/software/\">\n",
      "       software/\n",
      "      </a>\n",
      "      <dl>\n",
      "       <dd>\n",
      "        <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\n",
      "         BeautifulSoup/\n",
      "        </a>\n",
      "       </dd>\n",
      "      </dl>\n",
      "     </dd>\n",
      "    </dl>\n",
      "   </dd>\n",
      "  </dl>\n",
      "  Site Search:\n",
      "  <form action=\"/search/\" method=\"get\">\n",
      "   <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "  </form>\n",
      " </p>\n",
      "</td>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prettified Soup\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Beautiful Soup: We called him Tortoise because he taught us.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "\n",
      "Beautiful Soup\n",
      "\"A tremendous boon.\" -- Python411 Podcast\n",
      "[ Download | Documentation | Hall of Fame | Source | Changelog | Discussion group  | Zine ]\n",
      "If you use Beautiful Soup as part of your work, please consider a Tidelift subscription. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "If Beautiful Soup is useful to you on a personal level, you might like to read Tool Safety, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "\n",
      "If you have questions, send them to the discussion\n",
      "group. If you find a bug, file it.\n",
      "Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "\n",
      "Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "\n",
      "Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class externalLink\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "Interested? Read more.\n",
      "Download Beautiful Soup\n",
      "The current release is Beautiful Soup\n",
      "4.7.1 (January 6, 2019). You can install Beautiful Soup 4 with\n",
      "pip install beautifulsoup4.\n",
      "\n",
      "In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "python-bs4 package (for Python 2) or the\n",
      "python3-bs4 package (for Python 3). In Fedora it's\n",
      "available as the python-beautifulsoup4 package.\n",
      "\n",
      "Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the bs4/ directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using 2to3.)\n",
      "\n",
      "Beautiful Soup 4 works on both Python 2 (2.7+) and Python 3.\n",
      "\n",
      "Beautiful Soup 3\n",
      "Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It is considered stable, and only\n",
      "critical security bugs will be fixed. Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "Beautiful Soup 3 works only under Python 2.x. It is licensed under\n",
      "the same license as Python itself.\n",
      "\n",
      "The current release of Beautiful Soup 3 is 3.2.1 (February 16,\n",
      "2012). You can install Beautiful Soup 3 with pip install\n",
      "BeautifulSoup. It's also available as\n",
      "python-beautifulsoup in Debian and Ubuntu, and as\n",
      "python-BeautifulSoup in Fedora.\n",
      "\n",
      "You can also download the tarball and use\n",
      "BeautifulSoup.py in your project directly.\n",
      "\n",
      "\n",
      "Hall of Fame\n",
      "Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "\n",
      "\"Movable\n",
      " Type\", a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "Reddit uses Beautiful Soup to parse\n",
      "a page that's been linked to and find a representative image.\n",
      "\n",
      "Alexander Harrowell uses Beautiful Soup to track the business\n",
      " activities of an arms merchant.\n",
      "\n",
      "The developers of Python itself used Beautiful Soup to migrate the Python\n",
      "bug tracker from Sourceforge to Roundup.\n",
      "\n",
      "The Lawrence Journal-World\n",
      "uses Beautiful Soup to gather\n",
      "statewide election results.\n",
      "\n",
      "The NOAA's Forecast\n",
      "Applications Branch uses Beautiful Soup in TopoGrabber, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "\n",
      "If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or the discussion\n",
      "group.\n",
      "\n",
      "Development\n",
      "Development happens at Launchpad. You can get the source\n",
      "code or file\n",
      "bugs.\n",
      "This document (source) is part of Crummy, the webspace of Leonard Richardson (contact information). It was last modified on Monday, January 07 2019, 00:54:05 Nowhere Standard Time and last built on Thursday, January 17 2019, 18:00:01 Nowhere Standard Time.Crummy is © 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a Creative Commons License.Document tree:\n",
      "http://www.crummy.com/software/BeautifulSoup/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring BeautifulSoup\n",
    "## Many methods such as:\n",
    "print(soup.title)\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs4/download/\n",
      "#Download\n",
      "bs4/doc/\n",
      "#HallOfFame\n",
      "https://code.launchpad.net/beautifulsoup\n",
      "https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\n",
      "https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\n",
      "zine/\n",
      "https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website\n",
      "zine/\n",
      "https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\n",
      "https://bugs.launchpad.net/beautifulsoup/\n",
      "http://lxml.de/\n",
      "http://code.google.com/p/html5lib/\n",
      "bs4/doc/\n",
      "None\n",
      "bs4/download/\n",
      "http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\n",
      "download/3.x/BeautifulSoup-3.2.1.tar.gz\n",
      "None\n",
      "http://www.nytimes.com/2007/10/25/arts/design/25vide.html\n",
      "https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\n",
      "http://www.harrowell.org.uk/viktormap.html\n",
      "http://svn.python.org/view/tracker/importer/\n",
      "http://www2.ljworld.com/\n",
      "http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\n",
      "http://esrl.noaa.gov/gsd/fab/\n",
      "http://laps.noaa.gov/topograbber/\n",
      "http://groups.google.com/group/beautifulsoup/\n",
      "https://launchpad.net/beautifulsoup\n",
      "https://code.launchpad.net/beautifulsoup/\n",
      "https://bugs.launchpad.net/beautifulsoup/\n",
      "/source/software/BeautifulSoup/index.bhtml\n",
      "/self/\n",
      "/self/contact.html\n",
      "http://creativecommons.org/licenses/by-sa/2.0/\n",
      "http://creativecommons.org/licenses/by-sa/2.0/\n",
      "http://www.crummy.com/\n",
      "http://www.crummy.com/software/\n",
      "http://www.crummy.com/software/BeautifulSoup/\n"
     ]
    }
   ],
   "source": [
    "## find_all()\n",
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing HTML with BeautifulSoup\n",
    "#### In this interactive exercise, you'll learn how to use the BeautifulSoup package to parse, prettify and extract information from HTML. You'll scrape the data from the webpage of Guido van Rossum, Python's very own Benevolent Dictator for Life. In the following exercises, you'll prettify the HTML and then extract the text and the hyperlinks.\n",
    "#### The URL of interest is url = 'https://www.python.org/~guido/'.\n",
    "\n",
    "* Import the function BeautifulSoup from the package bs4.\n",
    "* Assign the URL of interest to the variable url.\n",
    "* Package the request to the URL, send the request and catch the response with a single function requests.get(), assigning the response to the variable r.\n",
    "* Use the text attribute of the object r to return the HTML of the webpage as a string; store the result in a variable html_doc.\n",
    "* Create a BeautifulSoup object soup from the resulting HTML using the function BeautifulSoup().\n",
    "* Use the method prettify() on soup and assign the result to pretty_soup.\n",
    "* Hit submit to print to prettified HTML to your shell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Guido's Personal Home Page\n",
      "  </title>\n",
      " </head>\n",
      " <body bgcolor=\"#FFFFFF\" text=\"#000000\">\n",
      "  <h1>\n",
      "   <a href=\"pics.html\">\n",
      "    <img border=\"0\" src=\"images/IMG_2192.jpg\"/>\n",
      "   </a>\n",
      "   Guido van Rossum - Personal Home Page\n",
      "  </h1>\n",
      "  <p>\n",
      "   <a href=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\">\n",
      "    <i>\n",
      "     \"Gawky and proud of it.\"\n",
      "    </i>\n",
      "   </a>\n",
      "   <h3>\n",
      "    <a href=\"http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\">\n",
      "     Who\n",
      "I Am\n",
      "    </a>\n",
      "   </h3>\n",
      "   <p>\n",
      "    Read\n",
      "my\n",
      "    <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\n",
      "     \"King's\n",
      "Day Speech\"\n",
      "    </a>\n",
      "    for some inspiration.\n",
      "    <p>\n",
      "     I am the author of the\n",
      "     <a href=\"http://www.python.org\">\n",
      "      Python\n",
      "     </a>\n",
      "     programming language.  See also my\n",
      "     <a href=\"Resume.html\">\n",
      "      resume\n",
      "     </a>\n",
      "     and my\n",
      "     <a href=\"Publications.html\">\n",
      "      publications list\n",
      "     </a>\n",
      "     , a\n",
      "     <a href=\"bio.html\">\n",
      "      brief bio\n",
      "     </a>\n",
      "     , assorted\n",
      "     <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "      writings\n",
      "     </a>\n",
      "     ,\n",
      "     <a href=\"http://legacy.python.org/doc/essays/ppt/\">\n",
      "      presentations\n",
      "     </a>\n",
      "     and\n",
      "     <a href=\"interviews.html\">\n",
      "      interviews\n",
      "     </a>\n",
      "     (all about Python), some\n",
      "     <a href=\"pics.html\">\n",
      "      pictures of me\n",
      "     </a>\n",
      "     ,\n",
      "     <a href=\"http://neopythonic.blogspot.com\">\n",
      "      my new blog\n",
      "     </a>\n",
      "     , and\n",
      "my\n",
      "     <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">\n",
      "      old\n",
      "blog\n",
      "     </a>\n",
      "     on Artima.com.  I am\n",
      "     <a href=\"https://twitter.com/gvanrossum\">\n",
      "      @gvanrossum\n",
      "     </a>\n",
      "     on Twitter.  I\n",
      "also have\n",
      "a\n",
      "     <a href=\"https://plus.google.com/u/0/115212051037621986145/posts\">\n",
      "      G+\n",
      "profile\n",
      "     </a>\n",
      "     .\n",
      "     <p>\n",
      "      In January 2013 I joined\n",
      "      <a href=\"http://www.dropbox.com\">\n",
      "       Dropbox\n",
      "      </a>\n",
      "      .  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my\n",
      "      <a href=\"Resume.html\">\n",
      "       resume\n",
      "      </a>\n",
      "      .)  I created Python while at CWI.\n",
      "      <h3>\n",
      "       How to Reach Me\n",
      "      </h3>\n",
      "      <p>\n",
      "       You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "       <a href=\"http://groups.google.com/groups?q=comp.lang.python\">\n",
      "        comp.lang.python\n",
      "       </a>\n",
      "       or\n",
      "       <a href=\"http://stackoverflow.com\">\n",
      "        StackOverflow\n",
      "       </a>\n",
      "       .  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "       <h3>\n",
      "        My Name\n",
      "       </h3>\n",
      "       <p>\n",
      "        My name often poses difficulties for Americans.\n",
      "        <p>\n",
      "         <b>\n",
      "          Pronunciation:\n",
      "         </b>\n",
      "         in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "         <a href=\"guido.au\">\n",
      "          sound clip\n",
      "         </a>\n",
      "         .)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "         <p>\n",
      "          <b>\n",
      "           Spelling:\n",
      "          </b>\n",
      "          my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "          <p>\n",
      "           <b>\n",
      "            Alphabetization:\n",
      "           </b>\n",
      "           in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "           <h3>\n",
      "            More Hyperlinks\n",
      "           </h3>\n",
      "           <ul>\n",
      "            <li>\n",
      "             Here's a collection of\n",
      "             <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "              essays\n",
      "             </a>\n",
      "             relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "             <p>\n",
      "              <li>\n",
      "               I own the official\n",
      "               <a href=\"images/license.jpg\">\n",
      "                <img align=\"center\" border=\"0\" height=\"75\" src=\"images/license_thumb.jpg\" width=\"100\"/>\n",
      "                Python license.\n",
      "               </a>\n",
      "               <p>\n",
      "               </p>\n",
      "              </li>\n",
      "             </p>\n",
      "            </li>\n",
      "           </ul>\n",
      "           <h3>\n",
      "            The Audio File Formats FAQ\n",
      "           </h3>\n",
      "           <p>\n",
      "            I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at\n",
      "            <a href=\"http://www.cnpbagwell.com/audio-faq\">\n",
      "             http://www.cnpbagwell.com/audio-faq\n",
      "            </a>\n",
      "            .  And here is a link to\n",
      "            <a href=\"http://sox.sourceforge.net/\">\n",
      "             SOX\n",
      "            </a>\n",
      "            , to which I contributed\n",
      "some early code.\n",
      "           </p>\n",
      "          </p>\n",
      "         </p>\n",
      "        </p>\n",
      "       </p>\n",
      "      </p>\n",
      "     </p>\n",
      "    </p>\n",
      "   </p>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "<hr/>\n",
      "<a href=\"images/internetdog.gif\">\n",
      " \"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "</a>\n",
      "<hr/>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "# Print the response\n",
    "print(pretty_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning a webpage into data using BeautifulSoup: getting the text\n",
    "#### As promised, in the following exercises, you'll learn the basics of extracting information from HTML soup. In this exercise, you'll figure out how to extract the text from the BDFL's webpage, along with printing the webpage's title.\n",
    "\n",
    "* In the sample code, the HTML response object html_doc has already been created: your first task is to Soupify it using the function BeautifulSoup() and to assign the resulting soup to the variable soup.\n",
    "* Extract the title from the HTML soup soup using the attribute title and assign the result to guido_title.\n",
    "* Print the title of Guido's webpage to the shell using the print() function.\n",
    "* Extract the text from the HTML soup soup using the method get_text() and assign to guido_text.\n",
    "* Hit submit to print the text from Guido's webpage to the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "\n",
      "\n",
      "Guido's Personal Home Page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Guido van Rossum - Personal Home Page\n",
      "\"Gawky and proud of it.\"\n",
      "Who\n",
      "I Am\n",
      "Read\n",
      "my \"King's\n",
      "Day Speech\" for some inspiration.\n",
      "\n",
      "I am the author of the Python\n",
      "programming language.  See also my resume\n",
      "and my publications list, a brief bio, assorted writings, presentations and interviews (all about Python), some\n",
      "pictures of me,\n",
      "my new blog, and\n",
      "my old\n",
      "blog on Artima.com.  I am\n",
      "@gvanrossum on Twitter.  I\n",
      "also have\n",
      "a G+\n",
      "profile.\n",
      "\n",
      "In January 2013 I joined\n",
      "Dropbox.  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my resume.)  I created Python while at CWI.\n",
      "\n",
      "How to Reach Me\n",
      "You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "comp.lang.python or\n",
      "StackOverflow.  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "\n",
      "My Name\n",
      "My name often poses difficulties for Americans.\n",
      "\n",
      "Pronunciation: in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "sound clip.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "Spelling: my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "Alphabetization: in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "More Hyperlinks\n",
      "\n",
      "Here's a collection of essays relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "I own the official \n",
      "Python license.\n",
      "\n",
      "The Audio File Formats FAQ\n",
      "I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at http://www.cnpbagwell.com/audio-faq.  And here is a link to\n",
      "SOX, to which I contributed\n",
      "some early code.\n",
      "\n",
      "\n",
      "\n",
      "\"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guido's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text = soup.get_text()\n",
    "\n",
    "# Print Guido's text to the shell\n",
    "print(guido_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning a webpage into data using BeautifulSoup: getting the hyperlinks\n",
    "#### In this exercise, you'll figure out how to extract the URLs of the hyperlinks from the BDFL's webpage. In the process, you'll become close friends with the soup method find_all().\n",
    "\n",
    "* Use the method find_all() to find all hyperlinks in soup, remembering that hyperlinks are defined by the HTML tag \"a\";  store the result in the variable a_tags.\n",
    "* The variable a_tags is a results set: your job now is to enumerate over it, using a for loop and to print the actual URLs of the hyperlinks; to do this, for every element link in a_tags, you want to print() link.get('href')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "https://plus.google.com/u/0/115212051037621986145/posts\n",
      "http://www.dropbox.com\n",
      "Resume.html\n",
      "http://groups.google.com/groups?q=comp.lang.python\n",
      "http://stackoverflow.com\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to APIs and JSONs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API's\n",
    "* Application Programming Interface\n",
    "* Protocols and routines\n",
    "    * Building and interacting with software applications\n",
    "* OMDb - Open Move Database\n",
    "* Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON's\n",
    "* JavaScript Object Notation\n",
    "* Real-time server-to-browser communication\n",
    "* Invented by Douglas Crockford\n",
    "* Human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/snakes.json'\n",
    "#url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/hackers.json'\n",
    "# Save file locally\n",
    "urlretrieve(url, 'snakes.json')\n",
    "#urlretrieve(url, 'hackers.json')\n",
    "\n",
    "# Loading JSONs in Python\n",
    "import json\n",
    "with open('snakes.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "print(type(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: Rafael Moreu\n",
      "Country: USA\n",
      "Plot: A young boy is arrested by the U.S. Secret Service for writing a computer virus and is banned from using a computer until his 18th birthday. Years later, he and his new-found friends ...\n",
      "Rated: PG-13\n",
      "Title: Hackers\n",
      "imdbVotes: 53,874\n",
      "Runtime: 107 min\n",
      "Actors: Jonny Lee Miller, Angelina Jolie, Jesse Bradford, Matthew Lillard\n",
      "imdbID: tt0113243\n",
      "Genre: Comedy, Crime, Drama\n",
      "Released: 15 Sep 1995\n",
      "Language: English, Italian, Russian, Japanese\n",
      "Director: Iain Softley\n",
      "Awards: N/A\n",
      "imdbRating: 6.2\n",
      "Response: True\n",
      "Metascore: 46\n",
      "Type: movie\n",
      "Year: 1995\n",
      "Poster: http://ia.media-imdb.com/images/M/MV5BODg0NjQ5ODQ3OF5BMl5BanBnXkFtZTcwNjU4MjkzNA@@._V1_SX300.jpg\n"
     ]
    }
   ],
   "source": [
    "for key, value in json_data.items():\n",
    "    print(key + ':', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and exploring a JSON\n",
    "#### Now that you know what a JSON is, you'll load one into your Python environment and explore it yourself. Here, you'll load the JSON 'a_movie.json' into the variable json_data, which will be a dictionary. You'll then explore the JSON contents by printing the key-value pairs of json_data to the shell.\n",
    "\n",
    "* Load the JSON 'a_movie.json' into the variable json_data within the context provided by the with statement. To do so, use the function json.load() within the context manager.\n",
    "* Use a for loop to print all key-value pairs in the dictionary json_data. Recall that you can access a value in a dictionary using the syntax: dictionary[key]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer:  Aaron Sorkin (screenplay), Ben Mezrich (book)\n",
      "Country:  USA\n",
      "Plot:  Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\n",
      "Rated:  PG-13\n",
      "Title:  The Social Network\n",
      "Actors:  Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\n",
      "Released:  01 Oct 2010\n",
      "Language:  English, French\n",
      "Director:  David Fincher\n",
      "BoxOffice:  $96,400,000\n",
      "Production:  Columbia Pictures\n",
      "imdbRating:  7.7\n",
      "Response:  True\n",
      "Metascore:  95\n",
      "Poster:  https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\n",
      "Type:  movie\n",
      "Year:  2010\n",
      "Awards:  Won 3 Oscars. Another 165 wins & 168 nominations.\n"
     ]
    }
   ],
   "source": [
    "# Load JSON: json_data\n",
    "with open(\"a_movie.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop quiz: Exploring your JSON\n",
    "#### Load the JSON 'a_movie.json' into a variable, which will be a dictionary. Do so by copying, pasting and executing the following code in the IPython Shell:\n",
    "#### import json\n",
    "#### with open(\"a_movie.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "#### Print the values corresponding to the keys 'Title' and 'Year' and answer the following question about the movie that the JSON describes:\n",
    "\n",
    "#### Which of the following statements is true of the movie in question?\n",
    "* The title is 'Kung Fu Panda' and the year is 2010.\n",
    "* The title is 'Kung Fu Panda' and the year is 2008.\n",
    "* The title is 'The Social Network' and the year is 2010.\n",
    "* The title is 'The Social Network' and the year is 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Social Network\n",
      "2010\n"
     ]
    }
   ],
   "source": [
    "print(json_data['Title'])\n",
    "print(json_data['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIs and interacting with the world wide web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an API?\n",
    "* Set of protocols and routines\n",
    "* Bunch of code\n",
    "    * Allows two software programs to communicate with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs are everywhere\n",
    "* Twitter\n",
    "* Uber\n",
    "* Facebook \n",
    "* Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: USA, Germany\n",
      "Language: English\n",
      "DVD: 02 Jan 2007\n",
      "imdbVotes: 124,643\n",
      "Actors: Samuel L. Jackson, Julianna Margulies, Nathan Phillips, Rachel Blanchard\n",
      "imdbID: tt0417148\n",
      "Genre: Action, Thriller\n",
      "Released: 18 Aug 2006\n",
      "Director: David R. Ellis\n",
      "Awards: 3 wins & 7 nominations.\n",
      "Response: True\n",
      "Production: New Line Cinema\n",
      "Type: movie\n",
      "Poster: https://m.media-amazon.com/images/M/MV5BZDY3ODM2YTgtYTU5NC00MTE4LTkzNjktMzNhZWZmMzJjMWRjXkEyXkFqcGdeQXVyMTQxNzMzNDI@._V1_SX300.jpg\n",
      "Writer: John Heffernan (screenplay), Sebastian Gutierrez (screenplay), David Dalessandro (story), John Heffernan (story)\n",
      "Website: http://www.snakesonaplane.com/\n",
      "Plot: An F.B.I. Agent takes on a plane full of deadly venomous snakes, deliberately released to kill a witness being flown from Honolulu to Los Angeles to testify against a mob boss.\n",
      "Rated: R\n",
      "Title: Snakes on a Plane\n",
      "Runtime: 105 min\n",
      "Ratings: [{'Value': '5.5/10', 'Source': 'Internet Movie Database'}, {'Value': '69%', 'Source': 'Rotten Tomatoes'}, {'Value': '58/100', 'Source': 'Metacritic'}]\n",
      "BoxOffice: $33,886,034\n",
      "imdbRating: 5.5\n",
      "Metascore: 58\n",
      "Year: 2006\n"
     ]
    }
   ],
   "source": [
    "# Connecting to an API in Python\n",
    "import requests\n",
    "\n",
    "#url = 'http://www.omdbapi.com/?t=hackers&apikey=72bc447a'\n",
    "url = 'http://www.omdbapi.com/?t=snakes+on+a+plane&apikey=72bc447a'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "json_data = r.json()\n",
    "\n",
    "for key, value in json_data.items():\n",
    "    print(key + \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was that URL?\n",
    "* http - making an HTTP request\n",
    "* www.omdbapi.com - querying the OMDB API\n",
    "* ?t=hackers\n",
    "    * Query string\n",
    "    * Return data for a movie with the title (t) 'Hackers'\n",
    "    * 'http://www.omdbapi.com/?t=hackers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which of the following statements about APIs is NOT true?\n",
    "\n",
    "* An API is a set of protocols and routines for building and interacting with software applications.\n",
    "* API is an acronym and is short for Application Program interface.\n",
    "* It is common to pull data from APIs in the JSON file format.\n",
    "* All APIs transmit data only in the JSON file format.\n",
    "* An API is a bunch of code that allows two software programs to communicate with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API requests\n",
    "#### Now it's your turn to pull some movie data down from the Open Movie Database (OMDB) using their API. The movie you'll query the API about is The Social Network. Recall that, in the video, to query the API about the movie Hackers, Hugo's query string was 'http://www.omdbapi.com/?t=hackers' and had a single argument t=hackers.\n",
    "#### Note: recently, OMDB has changed their API: you now also have to specify an API key. This means you'll have to add another argument to the URL: apikey=72bc447a.\n",
    "\n",
    "* Import the requests package.\n",
    "* Assign to the variable url the URL of interest in order to query 'http://www.omdbapi.com' for the data corresponding to the movie The Social Network. The query string should have two arguments: apikey=72bc447a and t=the+social+network. You can combine them as follows: apikey=72bc447a&t=the+social+network.\n",
    "* Print the text of the reponse object r by using its text attribute and passing the result to the print() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Title\":\"The Social Network\",\"Year\":\"2010\",\"Rated\":\"PG-13\",\"Released\":\"01 Oct 2010\",\"Runtime\":\"120 min\",\"Genre\":\"Biography, Drama\",\"Director\":\"David Fincher\",\"Writer\":\"Aaron Sorkin (screenplay), Ben Mezrich (book)\",\"Actors\":\"Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\",\"Plot\":\"Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\",\"Language\":\"English, French\",\"Country\":\"USA\",\"Awards\":\"Won 3 Oscars. Another 165 wins & 168 nominations.\",\"Poster\":\"https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\",\"Ratings\":[{\"Source\":\"Internet Movie Database\",\"Value\":\"7.7/10\"},{\"Source\":\"Rotten Tomatoes\",\"Value\":\"95%\"},{\"Source\":\"Metacritic\",\"Value\":\"95/100\"}],\"Metascore\":\"95\",\"imdbRating\":\"7.7\",\"imdbVotes\":\"556,761\",\"imdbID\":\"tt1285016\",\"Type\":\"movie\",\"DVD\":\"11 Jan 2011\",\"BoxOffice\":\"$96,400,000\",\"Production\":\"Columbia Pictures\",\"Website\":\"http://www.thesocialnetwork-movie.com/\",\"Response\":\"True\"}\n"
     ]
    }
   ],
   "source": [
    "# Import requests package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=the+social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Print the text of the response\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON–from the web to Python\n",
    "#### Wow, congrats! You've just queried your first API programmatically in Python and printed the text of the response to the shell. However, as you know, your response is actually a JSON, so you can do one step better and decode the JSON. You can then print the key-value pairs of the resulting dictionary. That's what you're going to do now!\n",
    "\n",
    "* Pass the variable url to the requests.get() function in order to send the relevant request and catch the response, assigning the resultant response message to the variable r.\n",
    "* Apply the json() method to the response object r and store the resulting dictionary in the variable json_data.\n",
    "* Hit Submit Answer to print the key-value pairs of the dictionary json_data to the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country:  USA\n",
      "Language:  English, French\n",
      "DVD:  11 Jan 2011\n",
      "imdbVotes:  556,761\n",
      "Actors:  Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\n",
      "imdbID:  tt1285016\n",
      "Genre:  Biography, Drama\n",
      "Released:  01 Oct 2010\n",
      "Director:  David Fincher\n",
      "Awards:  Won 3 Oscars. Another 165 wins & 168 nominations.\n",
      "Response:  True\n",
      "Production:  Columbia Pictures\n",
      "Type:  movie\n",
      "Poster:  https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\n",
      "Writer:  Aaron Sorkin (screenplay), Ben Mezrich (book)\n",
      "Website:  http://www.thesocialnetwork-movie.com/\n",
      "Plot:  Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\n",
      "Rated:  PG-13\n",
      "Title:  The Social Network\n",
      "Runtime:  120 min\n",
      "Ratings:  [{'Value': '7.7/10', 'Source': 'Internet Movie Database'}, {'Value': '95%', 'Source': 'Rotten Tomatoes'}, {'Value': '95/100', 'Source': 'Metacritic'}]\n",
      "BoxOffice:  $96,400,000\n",
      "imdbRating:  7.7\n",
      "Metascore:  95\n",
      "Year:  2010\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out the Wikipedia API\n",
    "#### You're doing so well and having so much fun that we're going to throw one more API at you: the Wikipedia API (documented here). You'll figure out how to find and extract information from the Wikipedia page for Pizza. What gets a bit wild here is that your query will return nested JSONs, that is, JSONs with JSONs, but Python can handle that because it will translate them into dictionaries within dictionaries.\n",
    "#### https://www.mediawiki.org/wiki/API:Main_page \n",
    "#### The URL that requests the relevant query from the Wikipedia API is\n",
    "#### https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza\n",
    "\n",
    "* Assign the relevant URL to the variable url.\n",
    "* Apply the json() method to the response object r and store the resulting dictionary in the variable json_data.\n",
    "* The variable pizza_extract holds the HTML of an extract from Wikipedia's Pizza page as a string; use the function print() to print this string to the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"mw-empty-elt\">\n",
      "</p>\n",
      "\n",
      "<p><b>Pizza</b> is a savory dish of Italian origin, consisting of a usually round, flattened base of leavened wheat-based dough topped with tomatoes, cheese, and various other ingredients (anchovies, olives, meat, etc.) baked at a high temperature, traditionally in a  wood-fired oven. In formal settings, like a restaurant, pizza is  eaten with knife and fork, but in casual settings it is cut into wedges to be eaten while held in the hand. Small pizzas are sometimes called pizzettas.   \n",
      "</p><p>The term <i>pizza</i> was first recorded in the 10th century in a Latin manuscript from the Southern Italian town of Gaeta in Lazio, on the border with Campania. Modern pizza was invented in Naples, and the dish and its variants have since become popular in many countries. Today it is one of the most popular foods in the world and a common fast food item in Europe and North America, available at  pizzerias (restaurants specializing in pizza),  restaurants offering Mediterranean cuisine, and via pizza delivery. Many companies sell ready-baked frozen pizzas to be reheated in an ordinary home oven. \n",
      "</p><p>The <i>Associazione Verace Pizza Napoletana</i> (lit. True Neapolitan Pizza Association) is  a non-profit organization founded in 1984 with headquarters in Naples that aims to promote traditional Neapolitan pizza. In 2009, upon Italy's request, Neapolitan pizza was registered with the European Union as a Traditional Speciality Guaranteed dish, and in 2017 the art of its making was included on UNESCO's list of intangible cultural heritage.</p>\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print the Wikipedia page extract\n",
    "pizza_extract = json_data['query']['pages']['24768']['extract']\n",
    "print(pizza_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Twitter API and Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the Twitter API\n",
    "* create a twitter account\n",
    "* login to twitter apps and create an apps\n",
    "* go to keys and access tokens tab\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Tweepy: Authentication handler\n",
    "# tw_auth.py\n",
    "\n",
    "import tweepy, json\n",
    "\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tweepy: define stream listener class\n",
    "# st_class.py\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write(json.dumps(tweet) + '\\n')\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 100:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "on_exception() missing 1 required positional argument: 'exception'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-989a8b300aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# This line filters Twitter Streams to capture data by keywords:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'apples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oranges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filter_level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, is_async)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# call a handler first so that the exception can be logged.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: on_exception() missing 1 required positional argument: 'exception'"
     ]
    }
   ],
   "source": [
    "### Using Tweepy: stream tweets!!\n",
    "# tweets.py\n",
    "# Create Streaming object and authenticate\n",
    "l = MyStreamListener\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "# This line filters Twitter Streams to capture data by keywords:\n",
    "stream.filter(track=['apples', 'oranges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Authentication\n",
    "#### The package tweepy is great at handling all the Twitter API OAuth Authentication details for you. All you need to do is pass it your authentication credentials. In this interactive exercise, we have created some mock authentication credentials (if you wanted to replicate this at home, you would need to create a Twitter App as Hugo detailed in the video). Your task is to pass these credentials to tweepy's OAuth handler.\n",
    "#### https://developer.twitter.com/en/apps \n",
    "\n",
    "* Import the package tweepy.\n",
    "* Pass the parameters consumer_key and consumer_secret to the function tweepy.OAuthHandler().\n",
    "* Complete the passing of OAuth credentials to the OAuth handler auth by applying to it the method set_access_token(), along with arguments access_token and access_token_secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import tweepy\n",
    "\n",
    "# Store OAuth authentication credentials in relevant variables, I couldn't get these to work\n",
    "'''access_token = \"1092294848-aHN7DcRP9B4VMTQIhwqOYiB14YkW92fFO8k8EPy\"\n",
    "access_token_secret = \"X4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\"\n",
    "consumer_key = \"nZ6EA0FxZ293SxGNg8g8aP0HM\"\n",
    "consumer_secret = \"fJGEodwe3KiKUnsYJC3VRndj7jevVvXbK2D5EiJ2nehafRgA6i\"\n",
    "'''\n",
    "''' Other keys to use for twitter\n",
    "#consumer key, consumer secret, access token, access secret.'''\n",
    "consumer_key=\"QIqgjITOfksfMW4lRLDacQ\"\n",
    "consumer_secret=\"R8x0xN9iSKXGNxUtGKA2hgnlIhh5INZIOdgEfxzk\"\n",
    "access_token=\"1401204486-BeLUAuruh294KeJX8NXvdqjCeZOQcLl6HWmMlgA\"\n",
    "access_token_secret=\"pwjiLF42TbORaXtkCS5Oc24qywOU0eFN0esVcibA\"\n",
    "\n",
    "\n",
    "# Pass OAuth details to tweepy's OAuth handler\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming tweets\n",
    "#### Now that you have set up your authentication credentials, it is time to stream some tweets! We have already defined the tweet stream listener class, MyStreamListener, just as Hugo did in the introductory video. You can find the code for the tweet stream listener class here.\n",
    "#### https://gist.github.com/hugobowne/18f1c0c0709ed1a52dc5bcd462ac69f4 \n",
    "#### Your task is to create the Streamobject and to filter tweets according to particular keywords.\n",
    "\n",
    "* Create your Stream object with authentication by passing tweepy.Stream() the authentication handler auth and the Stream listener l;\n",
    "* To filter Twitter streams, pass to the track argument in stream.filter() a list containing the desired keywords 'clinton', 'trump', 'sanders', and 'cruz'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "#from tweet_listener.py import MyStreamListener\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write(json.dumps(tweet) + '\\n')\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 1000:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()\n",
    "\n",
    "# Initialize Stream listener\n",
    "l = MyStreamListener()\n",
    "\n",
    "# Create your Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(track = ['clinton', 'trump', 'sanders', 'cruz'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore your Twitter data\n",
    "#### Now that you've got your Twitter data sitting locally in a text file, it's time to explore it! This is what you'll do in the next few interactive exercises. In this exercise, you'll read the Twitter data into a list: tweets_data.\n",
    "\n",
    "* Assign the filename 'tweets.txt' to the variable tweets_data_path.\n",
    "* Initialize tweets_data as an empty list to store the tweets in.\n",
    "* Within the for loop initiated by for line in tweets_file:, load each tweet into a variable, tweet, using json.loads(), then append tweet to tweets_data using the append() method.\n",
    "* Hit submit and check out the keys of the first tweet dictionary printed to the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['quote_count', 'coordinates', 'id', 'in_reply_to_user_id_str', 'retweeted', 'source', 'favorited', 'in_reply_to_status_id_str', 'timestamp_ms', 'in_reply_to_screen_name', 'created_at', 'in_reply_to_user_id', 'entities', 'is_quote_status', 'geo', 'in_reply_to_status_id', 'user', 'retweeted_status', 'reply_count', 'text', 'place', 'id_str', 'filter_level', 'lang', 'retweet_count', 'truncated', 'favorite_count', 'contributors'])\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import json\n",
    "\n",
    "# String of path to file: tweets_data_path\n",
    "tweets_data_path = 'tweets.txt'\n",
    "#tweets_data_path = 'tweets2.txt'\n",
    "\n",
    "# Initialize empty list to store tweets: tweets_data\n",
    "tweets_data = []\n",
    "\n",
    "# Open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter data to DataFrame\n",
    "#### Now you have the Twitter data in a list of dictionaries, tweets_data, where each dictionary corresponds to a single tweet. Next, you're going to extract the text and language of each tweet. The text in a tweet, t1, is stored as the value t1['text']; similarly, the language is stored in t1['lang']. Your task is to build a DataFrame in which each row is a tweet and the columns are 'text' and 'lang'.\n",
    "\n",
    "* Use pd.DataFrame() to construct a DataFrame of tweet texts and languages; to do so, the first argument should be tweets_data, a list of dictionaries. The second argument to pd.DataFrame() is a list of the keys you wish to have as columns. Assign the result of the pd.DataFrame() call to df.\n",
    "* Print the head of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text lang\n",
      "0  RT @timelywriter: WASHINGTON (@AP) — Special c...   en\n",
      "1  RT @politicususa: Sen. Richard Blumenthal says...   en\n",
      "2  I think Rosenstein leaked the buzzfeed story. ...   en\n",
      "3  Mueller team disputes BuzzFeed report claiming...   en\n",
      "4  RT @mmpadellan: Hello @Twitter?\\n\\nI'm reporti...   en\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns=['text','lang'])\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little bit of Twitter text analysis\n",
    "#### Now that you have your DataFrame of tweets set up, you're going to do a bit of text analysis to count how many tweets contain the words 'clinton', 'trump', 'sanders' and 'cruz'. In the pre-exercise code, we have defined the following function word_in_text(), which will tell you whether the first argument (a word) occurs within the 2nd argument (a tweet).\n",
    "\n",
    "import re\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, text)\n",
    "\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "#### You're going to iterate over the rows of the DataFrame and calculate how many tweets contain each of our keywords! The list of objects for each candidate has been initialized to 0.\n",
    "\n",
    "* Within the for loop for index, row in df.iterrows():, the code currently increases the value of clinton by 1 each time a tweet (text row) mentioning 'Clinton' is encountered; complete the code so that the same happens for trump, sanders and cruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_in_text(word, tweet):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, tweet)\n",
    "    \n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "# Initialize list to store tweet counts\n",
    "[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    clinton += word_in_text('clinton', row['text'])\n",
    "    trump += word_in_text('trump', row['text'])\n",
    "    sanders += word_in_text('sanders', row['text'])\n",
    "    cruz += word_in_text('cruz', row['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting your Twitter data\n",
    "#### Now that you have the number of tweets that each candidate was mentioned in, you can plot a bar chart of this data. You'll use the statistical data visualization library seaborn, which you may not have seen before, but we'll guide you through. You'll first import seaborn as sns. You'll then construct a barplot of the data using sns.barplot, passing it two arguments:\n",
    "\n",
    "#### 1. a list of labels and\n",
    "#### 2. a list containing the variables you wish to plot (clinton, trump and so on.)\n",
    "#### Hopefully, you'll see that Trump was unreasonably represented! We have already run the previous exercise solutions in your environment.\n",
    "\n",
    "* Import both matplotlib.pyplot and seaborn using the aliases plt and sns, respectively.\n",
    "* Complete the arguments of sns.barplot: the first argument should be the labels to appear on the x-axis; the second argument should be the list of the variables you wish to plot, as produced in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['clinton', 'trump', 'sanders', 'cruz']\n",
    "\n",
    "# Plot histogram\n",
    "ax = sns.barplot(cd, [clinton, trump, sanders, cruz])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
