{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnose data for cleaning\n",
    "* Prepare data for analysis\n",
    "* Data almost never comes in clean\n",
    "* Diagnose your data for problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common data problems\n",
    "* Inconsistent column names\n",
    "* Missing data\n",
    "* Outliers\n",
    "* Duplicate rows\n",
    "* Untidy\n",
    "* Need to process columns\n",
    "* Column types can signal unexpected data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('literary_birth_rate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country  Continent female literacy fertility     population  Unnamed: 5  \\\n",
      "0      Chine       ASI            90.5     1.769  1,324,655,000         NaN   \n",
      "1       Inde       ASI            50.8     2.682  1,139,964,932         NaN   \n",
      "2        USA       NAM              99     2.077    304,060,000         NaN   \n",
      "3  Indonésie       ASI            88.8     2.132    227,345,082         NaN   \n",
      "4     Brésil       LAT            90.2     1.827    191,971,506         NaN   \n",
      "\n",
      "   Unnamed: 6  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "                               Country  Continent female literacy fertility  \\\n",
      "177              Antilles néerlandaises       NaN            96.3       NaN   \n",
      "178                       Iles Caïmanes       NaN              99       NaN   \n",
      "179                          Seychelles       NaN            92.3       NaN   \n",
      "180  Territoires autonomes palestiniens       NaN            90.9       NaN   \n",
      "181                               WORLD     WORLD              77       NaN   \n",
      "\n",
      "    population  Unnamed: 5  Unnamed: 6  \n",
      "177        NaN         NaN         NaN  \n",
      "178        NaN         NaN         NaN  \n",
      "179        NaN         NaN         NaN  \n",
      "180        NaN         NaN         NaN  \n",
      "181        NaN         NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Visually inspect\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country ', 'Continent', 'female literacy', 'fertility', 'population',\n",
       "       'Unnamed: 5', 'Unnamed: 6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visually inspect\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visually inspect\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 182 entries, 0 to 181\n",
      "Data columns (total 7 columns):\n",
      "Country            169 non-null object\n",
      "Continent          164 non-null object\n",
      "female literacy    169 non-null object\n",
      "fertility          163 non-null object\n",
      "population         162 non-null object\n",
      "Unnamed: 5         0 non-null float64\n",
      "Unnamed: 6         0 non-null float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Visually inspect\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and viewing your data\n",
    "In this chapter, you're going to look at a subset of the Department of Buildings Job Application Filings dataset from the __[NYC Open Data](https://opendata.cityofnewyork.us/)__ portal. This dataset consists of job applications filed on January 22, 2017.\n",
    "\n",
    "Your first task is to load this dataset into a DataFrame and then inspect it using the .head() and .tail() methods. However, you'll find out very quickly that the printed results don't allow you to see everything you need, since there are too many columns. Therefore, you need to look at the data in another way.\n",
    "\n",
    "The .shape and .columns attributes let you see the shape of the DataFrame and obtain a list of its columns. From here, you can see which columns are relevant to the questions you'd like to ask of the data. To this end, a new DataFrame, df_subset, consisting only of these relevant columns, has been pre-loaded. This is the DataFrame you'll work with in the rest of the chapter.\n",
    "\n",
    "Get acquainted with the dataset now by exploring it with pandas! This initial exploratory analysis is a crucial first step of data cleaning.\n",
    "\n",
    "* Import pandas as pd.\n",
    "* Read 'dob_job_application_filings_subset.csv' into a DataFrame called df.\n",
    "* Print the head and tail of df.\n",
    "* Print the shape of df and its columns. Note: .shape and .columns are attributes, not methods, so you don't need to follow these with parentheses ().\n",
    "* Hit 'Submit Answer' to view the results! Notice the suspicious number of 0 values. Perhaps these represent missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Job #  Doc #        Borough       House #  \\\n",
      "0  121577873      2      MANHATTAN  386            \n",
      "1  520129502      1  STATEN ISLAND  107            \n",
      "2  121601560      1      MANHATTAN  63             \n",
      "3  121601203      1      MANHATTAN  48             \n",
      "4  121601338      1      MANHATTAN  45             \n",
      "\n",
      "                        Street Name  Block  Lot    Bin # Job Type Job Status  \\\n",
      "0  PARK AVENUE SOUTH                   857   38  1016890       A2          D   \n",
      "1  KNOX PLACE                          342    1  5161350       A3          A   \n",
      "2  WEST 131 STREET                    1729    9  1053831       A2          Q   \n",
      "3  WEST 25TH STREET                    826   69  1015610       A2          D   \n",
      "4  WEST 29 STREET                      831    7  1015754       A3          D   \n",
      "\n",
      "            ...                         Owner's Last Name  \\\n",
      "0           ...            MIGLIORE                         \n",
      "1           ...            BLUMENBERG                       \n",
      "2           ...            MARKOWITZ                        \n",
      "3           ...            CASALE                           \n",
      "4           ...            LEE                              \n",
      "\n",
      "              Owner's Business Name Owner's House Number  \\\n",
      "0  MACKLOWE MANAGEMENT                      126            \n",
      "1  NA                                       107            \n",
      "2  635 RIVERSIDE DRIVE NY LLC               619            \n",
      "3  48 W 25 ST LLC C/O BERNSTEIN             150            \n",
      "4  HYUNG-HYANG REALTY CORP                  614            \n",
      "\n",
      "           Owner'sHouse Street Name            City  State    Zip  \\\n",
      "0  EAST 56TH STREET                  NEW YORK           NY  10222   \n",
      "1  KNOX PLACE                        STATEN ISLAND      NY  10314   \n",
      "2  WEST 54TH STREET                  NEW YORK           NY  10016   \n",
      "3  WEST 30TH STREET                  NEW YORK           NY  10001   \n",
      "4  8 AVENUE                          NEW YORK           NY  10001   \n",
      "\n",
      "  Owner'sPhone #                                    Job Description  \\\n",
      "0     2125545837  GENERAL MECHANICAL & PLUMBING MODIFICATIONS AS...   \n",
      "1     3477398892  BUILDERS PAVEMENT PLAN 143 LF.                ...   \n",
      "2     2127652555  GENERAL CONSTRUCTION TO INCLUDE NEW PARTITIONS...   \n",
      "3     2125941414  STRUCTURAL CHANGES ON THE 5TH FLOOR (MOONDOG E...   \n",
      "4     2019881222  FILING HEREWITH FACADE REPAIR PLANS. WORK SCOP...   \n",
      "\n",
      "               DOBRunDate  \n",
      "0  04/26/2013 12:00:00 AM  \n",
      "1  04/26/2013 12:00:00 AM  \n",
      "2  04/26/2013 12:00:00 AM  \n",
      "3  04/26/2013 12:00:00 AM  \n",
      "4  04/26/2013 12:00:00 AM  \n",
      "\n",
      "[5 rows x 82 columns]\n",
      "           Job #  Doc #        Borough       House #  \\\n",
      "12841  520143988      1  STATEN ISLAND  8              \n",
      "12842  121613833      1      MANHATTAN  724            \n",
      "12843  121681260      1      MANHATTAN  350            \n",
      "12844  320771704      1       BROOKLYN  499            \n",
      "12845  520143951      1  STATEN ISLAND  1755           \n",
      "\n",
      "                            Street Name  Block  Lot    Bin # Job Type  \\\n",
      "12841  NOEL STREET                        5382   20  5069722       A2   \n",
      "12842  10 AVENUE                          1059    4  1082503       A2   \n",
      "12843  MANHATTAN AVE.                     1848   31  1055849       A2   \n",
      "12844  UNION STREET                        431   43  3007185       A2   \n",
      "12845  RICHMOND ROAD                       887   28  5022931       A2   \n",
      "\n",
      "      Job Status           ...                         Owner's Last Name  \\\n",
      "12841          D           ...            MALITO                           \n",
      "12842          D           ...            CROMAN                           \n",
      "12843          A           ...            ARYEH                            \n",
      "12844          D           ...            WIGGINS                          \n",
      "12845          D           ...            CAMBRIA                          \n",
      "\n",
      "                  Owner's Business Name Owner's House Number  \\\n",
      "12841  GENO MALITO                              8              \n",
      "12842  722-724 10TH AVENUE HOLDING LLC          632            \n",
      "12843  DG UWS LLC                               619            \n",
      "12844  N/A                                      77             \n",
      "12845  RONALD CAMBRIA                           1755           \n",
      "\n",
      "               Owner'sHouse Street Name            City  State    Zip  \\\n",
      "12841  NOEL STREET                       STATEN ISLAND      NY  10312   \n",
      "12842  BROADWAY                          NEW YORK           NY  10012   \n",
      "12843  WEST 54TH STREET                  NEW YORK           NY  10019   \n",
      "12844  PROSPECT PLACE                    BROOKLYN           NY  11217   \n",
      "12845  RICHMOND ROAD                     STATEN ISLAND      NY  10304   \n",
      "\n",
      "      Owner'sPhone #                                    Job Description  \\\n",
      "12841     9174685659  HORIZONTAL ENLARGEMENT OF ATTACHED ONE CAR GAR...   \n",
      "12842     2122289300  RENOVATION OF EXISTING APARTMENT #3B ON THIRD ...   \n",
      "12843     2127652555  REPLACE BURNER IN EXSTG BOILER WITH NEW GAS BU...   \n",
      "12844     9178487799  INSTALL NEW SPRINKLER SYSTEM THROUGHOUT THE BU...   \n",
      "12845     7184482740  INTERIOR PARTITIONS AND MINOR PLUMBING WORK TO...   \n",
      "\n",
      "                   DOBRunDate  \n",
      "12841  06/13/2013 12:00:00 AM  \n",
      "12842  06/13/2013 12:00:00 AM  \n",
      "12843  06/13/2013 12:00:00 AM  \n",
      "12844  06/13/2013 12:00:00 AM  \n",
      "12845  06/13/2013 12:00:00 AM  \n",
      "\n",
      "[5 rows x 82 columns]\n",
      "(12846, 82)\n",
      "Index(['Job #', 'Doc #', 'Borough', 'House #', 'Street Name', 'Block', 'Lot',\n",
      "       'Bin #', 'Job Type', 'Job Status', 'Job Status Descrp',\n",
      "       'Latest Action Date', 'Building Type', 'Community - Board', 'Cluster',\n",
      "       'Landmarked', 'Adult Estab', 'Loft Board', 'City Owned', 'Little e',\n",
      "       'PC Filed', 'eFiling Filed', 'Plumbing', 'Mechanical', 'Boiler',\n",
      "       'Fuel Burning', 'Fuel Storage', 'Standpipe', 'Sprinkler', 'Fire Alarm',\n",
      "       'Equipment', 'Fire Suppression', 'Curb Cut', 'Other',\n",
      "       'Other Description', 'Applicant's First Name', 'Applicant's Last Name',\n",
      "       'Applicant Professional Title', 'Applicant License #',\n",
      "       'Professional Cert', 'Pre- Filing Date', 'Paid', 'Fully Paid',\n",
      "       'Assigned', 'Approved', 'Fully Permitted', 'Initial Cost',\n",
      "       'Total Est. Fee', 'Fee Status', 'Existing Zoning Sqft',\n",
      "       'Proposed Zoning Sqft', 'Horizontal Enlrgmt', 'Vertical Enlrgmt',\n",
      "       'Enlargement SQ Footage', 'Street Frontage', 'ExistingNo. of Stories',\n",
      "       'Proposed No. of Stories', 'Existing Height', 'Proposed Height',\n",
      "       'Existing Dwelling Units', 'Proposed Dwelling Units',\n",
      "       'Existing Occupancy', 'Proposed Occupancy', 'Site Fill', 'Zoning Dist1',\n",
      "       'Zoning Dist2', 'Zoning Dist3', 'Special District 1',\n",
      "       'Special District 2', 'Owner Type', 'Non-Profit', 'Owner's First Name',\n",
      "       'Owner's Last Name', 'Owner's Business Name', 'Owner's House Number',\n",
      "       'Owner'sHouse Street Name', 'City ', 'State', 'Zip', 'Owner'sPhone #',\n",
      "       'Job Description', 'DOBRunDate'],\n",
      "      dtype='object')\n",
      "Index(['Job #', 'Doc #', 'Borough', 'Initial Cost', 'Total Est. Fee',\n",
      "       'Existing Zoning Sqft', 'Proposed Zoning Sqft',\n",
      "       'Enlargement SQ Footage', 'Street Frontage', 'ExistingNo. of Stories',\n",
      "       'Proposed No. of Stories', 'Existing Height', 'Proposed Height'],\n",
      "      dtype='object')\n",
      "       Job #  Doc #        Borough Initial Cost Total Est. Fee  \\\n",
      "0  121577873      2      MANHATTAN  $75,000.00        $986.00    \n",
      "1  520129502      1  STATEN ISLAND       $0.00      $1,144.00    \n",
      "2  121601560      1      MANHATTAN  $30,000.00        $522.50    \n",
      "3  121601203      1      MANHATTAN   $1,500.00        $225.00    \n",
      "4  121601338      1      MANHATTAN  $19,500.00        $389.50    \n",
      "\n",
      "   Existing Zoning Sqft  Proposed Zoning Sqft  Enlargement SQ Footage  \\\n",
      "0                     0                     0                       0   \n",
      "1                     0                     0                       0   \n",
      "2                     0                     0                       0   \n",
      "3                     0                     0                       0   \n",
      "4                     0                     0                       0   \n",
      "\n",
      "   Street Frontage  ExistingNo. of Stories  Proposed No. of Stories  \\\n",
      "0                0                       0                        0   \n",
      "1              143                       0                        0   \n",
      "2                0                       5                        5   \n",
      "3                0                      12                       12   \n",
      "4                0                       6                        6   \n",
      "\n",
      "   Existing Height  Proposed Height  \n",
      "0                0                0  \n",
      "1                0                0  \n",
      "2               54               54  \n",
      "3              120              120  \n",
      "4               64               64  \n",
      "       Job #  Doc #        Borough Initial Cost Total Est. Fee  \\\n",
      "0  121577873      2      MANHATTAN  $75,000.00        $986.00    \n",
      "1  520129502      1  STATEN ISLAND       $0.00      $1,144.00    \n",
      "2  121601560      1      MANHATTAN  $30,000.00        $522.50    \n",
      "3  121601203      1      MANHATTAN   $1,500.00        $225.00    \n",
      "4  121601338      1      MANHATTAN  $19,500.00        $389.50    \n",
      "\n",
      "   Existing Zoning Sqft  Proposed Zoning Sqft  Enlargement SQ Footage  \\\n",
      "0                     0                     0                       0   \n",
      "1                     0                     0                       0   \n",
      "2                     0                     0                       0   \n",
      "3                     0                     0                       0   \n",
      "4                     0                     0                       0   \n",
      "\n",
      "   Street Frontage  ExistingNo. of Stories  Proposed No. of Stories  \\\n",
      "0                0                       0                        0   \n",
      "1              143                       0                        0   \n",
      "2                0                       5                        5   \n",
      "3                0                      12                       12   \n",
      "4                0                       6                        6   \n",
      "\n",
      "   Existing Height  Proposed Height  \n",
      "0                0                0  \n",
      "1                0                0  \n",
      "2               54               54  \n",
      "3              120              120  \n",
      "4               64               64  \n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('dob_job_application_filings_subset.csv')\n",
    "\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Print the tail of df\n",
    "print(df.tail())\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Print the columns of df\n",
    "print(df.columns)\n",
    "\n",
    "# Print the head and tail of df_subset\n",
    "df_subset = pd.read_csv('df_dob_job_application_filings_subset2.csv')\n",
    "print(df_subset.columns)\n",
    "print(df_subset.head())\n",
    "print(df_subset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further diagnosis\n",
    "In the previous exercise, you identified some potentially unclean or missing data. Now, you'll continue to diagnose your data with the very useful `.info()` method.\n",
    "\n",
    "The `.info()` method provides important information about a DataFrame, such as the number of rows, number of columns, number of non-missing values in each column, and the data type stored in each column. This is the kind of information that will allow you to confirm whether the `'Initial Cost'` and `'Total Est. Fee'` columns are numeric or strings. From the results, you'll also be able to see whether or not all columns have complete data in them.\n",
    "\n",
    "The full DataFrame `df` and the subset DataFrame `df_subset` have been pre-loaded. Your task is to use the `.info()` method on these and analyze the results.\n",
    "\n",
    "* Print the `info` of `df`.\n",
    "* Print the `info` of the subset dataframe, `df_subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12846 entries, 0 to 12845\n",
      "Data columns (total 82 columns):\n",
      "Job #                           12846 non-null int64\n",
      "Doc #                           12846 non-null int64\n",
      "Borough                         12846 non-null object\n",
      "House #                         12846 non-null object\n",
      "Street Name                     12846 non-null object\n",
      "Block                           12846 non-null int64\n",
      "Lot                             12846 non-null int64\n",
      "Bin #                           12846 non-null int64\n",
      "Job Type                        12846 non-null object\n",
      "Job Status                      12846 non-null object\n",
      "Job Status Descrp               12846 non-null object\n",
      "Latest Action Date              12846 non-null object\n",
      "Building Type                   12846 non-null object\n",
      "Community - Board               12846 non-null object\n",
      "Cluster                         0 non-null float64\n",
      "Landmarked                      2067 non-null object\n",
      "Adult Estab                     1 non-null object\n",
      "Loft Board                      65 non-null object\n",
      "City Owned                      1419 non-null object\n",
      "Little e                        365 non-null object\n",
      "PC Filed                        0 non-null float64\n",
      "eFiling Filed                   12846 non-null object\n",
      "Plumbing                        12846 non-null object\n",
      "Mechanical                      12846 non-null object\n",
      "Boiler                          12846 non-null object\n",
      "Fuel Burning                    12846 non-null object\n",
      "Fuel Storage                    12846 non-null object\n",
      "Standpipe                       12846 non-null object\n",
      "Sprinkler                       12846 non-null object\n",
      "Fire Alarm                      12846 non-null object\n",
      "Equipment                       12846 non-null object\n",
      "Fire Suppression                12846 non-null object\n",
      "Curb Cut                        12846 non-null object\n",
      "Other                           12846 non-null object\n",
      "Other Description               12846 non-null object\n",
      "Applicant's First Name          12846 non-null object\n",
      "Applicant's Last Name           12846 non-null object\n",
      "Applicant Professional Title    12846 non-null object\n",
      "Applicant License #             12846 non-null object\n",
      "Professional Cert               6908 non-null object\n",
      "Pre- Filing Date                12846 non-null object\n",
      "Paid                            11961 non-null object\n",
      "Fully Paid                      11963 non-null object\n",
      "Assigned                        3817 non-null object\n",
      "Approved                        4062 non-null object\n",
      "Fully Permitted                 1495 non-null object\n",
      "Initial Cost                    12846 non-null object\n",
      "Total Est. Fee                  12846 non-null object\n",
      "Fee Status                      12846 non-null object\n",
      "Existing Zoning Sqft            12846 non-null int64\n",
      "Proposed Zoning Sqft            12846 non-null int64\n",
      "Horizontal Enlrgmt              231 non-null object\n",
      "Vertical Enlrgmt                142 non-null object\n",
      "Enlargement SQ Footage          12846 non-null int64\n",
      "Street Frontage                 12846 non-null int64\n",
      "ExistingNo. of Stories          12846 non-null int64\n",
      "Proposed No. of Stories         12846 non-null int64\n",
      "Existing Height                 12846 non-null int64\n",
      "Proposed Height                 12846 non-null int64\n",
      "Existing Dwelling Units         12846 non-null object\n",
      "Proposed Dwelling Units         12846 non-null object\n",
      "Existing Occupancy              12846 non-null object\n",
      "Proposed Occupancy              12846 non-null object\n",
      "Site Fill                       8641 non-null object\n",
      "Zoning Dist1                    11263 non-null object\n",
      "Zoning Dist2                    1652 non-null object\n",
      "Zoning Dist3                    88 non-null object\n",
      "Special District 1              3062 non-null object\n",
      "Special District 2              848 non-null object\n",
      "Owner Type                      0 non-null float64\n",
      "Non-Profit                      971 non-null object\n",
      "Owner's First Name              12846 non-null object\n",
      "Owner's Last Name               12846 non-null object\n",
      "Owner's Business Name           12846 non-null object\n",
      "Owner's House Number            12846 non-null object\n",
      "Owner'sHouse Street Name        12846 non-null object\n",
      "City                            12846 non-null object\n",
      "State                           12846 non-null object\n",
      "Zip                             12846 non-null int64\n",
      "Owner'sPhone #                  12846 non-null int64\n",
      "Job Description                 12699 non-null object\n",
      "DOBRunDate                      12846 non-null object\n",
      "dtypes: float64(3), int64(15), object(64)\n",
      "memory usage: 4.9+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 13 columns):\n",
      "Job #                      5 non-null int64\n",
      "Doc #                      5 non-null int64\n",
      "Borough                    5 non-null object\n",
      "Initial Cost               5 non-null object\n",
      "Total Est. Fee             5 non-null object\n",
      "Existing Zoning Sqft       5 non-null int64\n",
      "Proposed Zoning Sqft       5 non-null int64\n",
      "Enlargement SQ Footage     5 non-null int64\n",
      "Street Frontage            5 non-null int64\n",
      "ExistingNo. of Stories     5 non-null int64\n",
      "Proposed No. of Stories    5 non-null int64\n",
      "Existing Height            5 non-null int64\n",
      "Proposed Height            5 non-null int64\n",
      "dtypes: int64(10), object(3)\n",
      "memory usage: 500.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the info of df\n",
    "print(df.info())\n",
    "\n",
    "# Print the info of df_subset\n",
    "print(df_subset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency counts\n",
    "* Count the number of unique values in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 5 columns):\n",
      "Country            168 non-null object\n",
      "Continent          163 non-null object\n",
      "female literacy    168 non-null float64\n",
      "fertility          167 non-null object\n",
      "population         162 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data type of each column\n",
    "# Load your data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('literary_birth_rate.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF           49\n",
      "ASI          47\n",
      "EUR          36\n",
      "LAT          24\n",
      "NaN          18\n",
      "OCE           4\n",
      "NAM           2\n",
      "WORLD         1\n",
      "Continent     1\n",
      "Name: Continent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Frequency counts: continent\n",
    "print(df.Continent.value_counts(dropna=False))\n",
    "\n",
    "#df.Continent -> directly selects the column in the file df \n",
    "#value_counts -> counts the number of times a value is located\n",
    "#dropna=False -> tells us if there are any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF           49\n",
      "ASI          47\n",
      "EUR          36\n",
      "LAT          24\n",
      "NaN          18\n",
      "OCE           4\n",
      "NAM           2\n",
      "WORLD         1\n",
      "Continent     1\n",
      "Name: Continent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Frequency counts: continent\n",
    "#      using bracket notation\n",
    "print(df['Continent'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN            13\n",
       "Arménie         1\n",
       "Tadjikistan     1\n",
       "Kenya           1\n",
       "Soudan          1\n",
       "Name: Country , dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency counts: country\n",
    "#print(df['Country '].head())\n",
    "df['Country '].value_counts(dropna=False).head() # had to use bracket notation because column name has a space\n",
    "\n",
    "# using the head method to limit the output, there are too many countries to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missing    5\n",
       "1.393      2\n",
       "3.371      2\n",
       "1.854      2\n",
       "1.841      2\n",
       "Name: fertility, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency counts: fertility\n",
    "df.fertility.value_counts(dropna=False).head()\n",
    "\n",
    "# 'missing' string should be an int type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN            6\n",
       "191,971,506    1\n",
       "29,021,099     1\n",
       "24,645,686     1\n",
       "9,694,113      1\n",
       "Name: population, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency counts: population\n",
    "df.population.value_counts(dropna=False).head()\n",
    "\n",
    "# missing values 'NaN 6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "* Numeric columns\n",
    "* Outliers\n",
    "    * Considerably higher or lower\n",
    "    * Require futher investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female literacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80.549405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.797066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>90.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       female literacy\n",
       "count       168.000000\n",
       "mean         80.549405\n",
       "std          22.797066\n",
       "min          12.600000\n",
       "25%          67.550000\n",
       "50%          90.300000\n",
       "75%          98.500000\n",
       "max         100.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics\n",
    "df.describe()\n",
    "\n",
    "# only columns with numerical type returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating summary statistics\n",
    "You'll now use the `.describe()` method to calculate summary statistics of your data.\n",
    "\n",
    "In this exercise, the columns `'Initial Cost'` and `'Total Est. Fee'` have been cleaned up for you. That is, the dollar sign has been removed and they have been converted into two new numeric columns: `initial_cost` and `total_est_fee`. You'll learn how to do this yourself in later chapters. It's also worth noting that some columns such as `Job #` are encoded as numeric columns, but it does not make sense to compute summary statistics for such columns.\n",
    "\n",
    "This cleaned DataFrame has been pre-loaded as `df`. Your job is to use the `.describe()` method on it in the IPython Shell and select the statement below that is False.\n",
    "\n",
    "#### Possible Answers\n",
    "* The mean of 'Proposed No. of Stories' is 8.144325.\n",
    "* The standard deviation of 'Existing Height' is 146.917360.\n",
    "* There are 12846 entries in the DataFrame.\n",
    "* The standard deviation of 'Street Frontage' is 11.874080.\n",
    "* The maximum of 'Proposed Height' is 4200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12846 entries, 0 to 12845\n",
      "Data columns (total 82 columns):\n",
      "Job #                           12846 non-null int64\n",
      "Doc #                           12846 non-null int64\n",
      "Borough                         12846 non-null object\n",
      "House #                         12846 non-null object\n",
      "Street Name                     12846 non-null object\n",
      "Block                           12846 non-null int64\n",
      "Lot                             12846 non-null int64\n",
      "Bin #                           12846 non-null int64\n",
      "Job Type                        12846 non-null object\n",
      "Job Status                      12846 non-null object\n",
      "Job Status Descrp               12846 non-null object\n",
      "Latest Action Date              12846 non-null object\n",
      "Building Type                   12846 non-null object\n",
      "Community - Board               12846 non-null object\n",
      "Cluster                         0 non-null float64\n",
      "Landmarked                      2067 non-null object\n",
      "Adult Estab                     1 non-null object\n",
      "Loft Board                      65 non-null object\n",
      "City Owned                      1419 non-null object\n",
      "Little e                        365 non-null object\n",
      "PC Filed                        0 non-null float64\n",
      "eFiling Filed                   12846 non-null object\n",
      "Plumbing                        12846 non-null object\n",
      "Mechanical                      12846 non-null object\n",
      "Boiler                          12846 non-null object\n",
      "Fuel Burning                    12846 non-null object\n",
      "Fuel Storage                    12846 non-null object\n",
      "Standpipe                       12846 non-null object\n",
      "Sprinkler                       12846 non-null object\n",
      "Fire Alarm                      12846 non-null object\n",
      "Equipment                       12846 non-null object\n",
      "Fire Suppression                12846 non-null object\n",
      "Curb Cut                        12846 non-null object\n",
      "Other                           12846 non-null object\n",
      "Other Description               12846 non-null object\n",
      "Applicant's First Name          12846 non-null object\n",
      "Applicant's Last Name           12846 non-null object\n",
      "Applicant Professional Title    12846 non-null object\n",
      "Applicant License #             12846 non-null object\n",
      "Professional Cert               6908 non-null object\n",
      "Pre- Filing Date                12846 non-null object\n",
      "Paid                            11961 non-null object\n",
      "Fully Paid                      11963 non-null object\n",
      "Assigned                        3817 non-null object\n",
      "Approved                        4062 non-null object\n",
      "Fully Permitted                 1495 non-null object\n",
      "Initial Cost                    12846 non-null object\n",
      "Total Est. Fee                  12846 non-null object\n",
      "Fee Status                      12846 non-null object\n",
      "Existing Zoning Sqft            12846 non-null int64\n",
      "Proposed Zoning Sqft            12846 non-null int64\n",
      "Horizontal Enlrgmt              231 non-null object\n",
      "Vertical Enlrgmt                142 non-null object\n",
      "Enlargement SQ Footage          12846 non-null int64\n",
      "Street Frontage                 12846 non-null int64\n",
      "ExistingNo. of Stories          12846 non-null int64\n",
      "Proposed No. of Stories         12846 non-null int64\n",
      "Existing Height                 12846 non-null int64\n",
      "Proposed Height                 12846 non-null int64\n",
      "Existing Dwelling Units         12846 non-null object\n",
      "Proposed Dwelling Units         12846 non-null object\n",
      "Existing Occupancy              12846 non-null object\n",
      "Proposed Occupancy              12846 non-null object\n",
      "Site Fill                       8641 non-null object\n",
      "Zoning Dist1                    11263 non-null object\n",
      "Zoning Dist2                    1652 non-null object\n",
      "Zoning Dist3                    88 non-null object\n",
      "Special District 1              3062 non-null object\n",
      "Special District 2              848 non-null object\n",
      "Owner Type                      0 non-null float64\n",
      "Non-Profit                      971 non-null object\n",
      "Owner's First Name              12846 non-null object\n",
      "Owner's Last Name               12846 non-null object\n",
      "Owner's Business Name           12846 non-null object\n",
      "Owner's House Number            12846 non-null object\n",
      "Owner'sHouse Street Name        12846 non-null object\n",
      "City                            12846 non-null object\n",
      "State                           12846 non-null object\n",
      "Zip                             12846 non-null int64\n",
      "Owner'sPhone #                  12846 non-null int64\n",
      "Job Description                 12699 non-null object\n",
      "DOBRunDate                      12846 non-null object\n",
      "dtypes: float64(3), int64(15), object(64)\n",
      "memory usage: 4.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " # Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('dob_job_application_filings_subset.csv')\n",
    "\n",
    "print(df.info())\n",
    "#print(df['Proposed No. of Stories'].describe())\n",
    "#print(df['Existing Height'].describe())\n",
    "##print(df['Street Frontage'].describe())\n",
    "#print(df['Proposed Height'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency counts for categorical data\n",
    "As you've seen, `.describe()` can only be used on numeric columns. So how can you diagnose data issues when you have categorical data? One way is by using the `.value_counts()` method, which returns the frequency counts for each unique value in a column!\n",
    "\n",
    "This method also has an optional parameter called `dropna` which is `True` by default. What this means is if you have missing data in a column, it will not give a frequency count of them. You want to set the `dropna` column to `False` so if there are missing values in a column, it will give you the frequency counts.\n",
    "\n",
    "In this exercise, you're going to look at the `'Borough'`, `'State'`, and `'Site Fill'` columns to make sure all the values in there are valid. When looking at the output, do a sanity check: Are all values in the `'State'` column from `NY`, for example? Since the dataset consists of applications filed in NY, you would expect this to be the case.\n",
    "\n",
    "* Print the value counts for:\n",
    "    * The 'Borough' column.\n",
    "    * The 'State' column.\n",
    "    * The 'Site Fill' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANHATTAN        6310\n",
      "BROOKLYN         2866\n",
      "QUEENS           2121\n",
      "BRONX             974\n",
      "STATEN ISLAND     575\n",
      "Name: Borough, dtype: int64\n",
      "NY    12391\n",
      "NJ      241\n",
      "PA       38\n",
      "CA       20\n",
      "OH       19\n",
      "FL       17\n",
      "IL       17\n",
      "CT       16\n",
      "TX       13\n",
      "TN       10\n",
      "DC        7\n",
      "MD        7\n",
      "MA        6\n",
      "KS        6\n",
      "GA        6\n",
      "VA        5\n",
      "CO        4\n",
      "WI        3\n",
      "AZ        3\n",
      "MN        3\n",
      "SC        3\n",
      "UT        2\n",
      "NC        2\n",
      "RI        2\n",
      "VT        1\n",
      "WA        1\n",
      "IN        1\n",
      "NM        1\n",
      "MI        1\n",
      "Name: State, dtype: int64\n",
      "NOT APPLICABLE                              7806\n",
      "NaN                                         4205\n",
      "ON-SITE                                      519\n",
      "OFF-SITE                                     186\n",
      "USE UNDER 300 CU.YD                          130\n",
      "Name: Site Fill, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the value counts for 'Borough'\n",
    "print(df['Borough'].value_counts(dropna=False))\n",
    "\n",
    "# Print the value_counts for 'State'\n",
    "print(df['State'].value_counts(dropna=False))\n",
    "\n",
    "# Print the value counts for 'Site Fill'\n",
    "print(df['Site Fill'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "* Great way to spot outliers and obvious errors\n",
    "* More than just looing for patterns\n",
    "* Plan data cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female literacy</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>169.000000</td>\n",
       "      <td>1.630000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80.640828</td>\n",
       "      <td>5.462765e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.760169</td>\n",
       "      <td>2.267754e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>1.035660e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.800000</td>\n",
       "      <td>3.378469e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>90.400000</td>\n",
       "      <td>9.720694e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98.500000</td>\n",
       "      <td>2.892890e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.313000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       female literacy    population\n",
       "count       169.000000  1.630000e+02\n",
       "mean         80.640828  5.462765e+07\n",
       "std          22.760169  2.267754e+08\n",
       "min          12.600000  1.035660e+05\n",
       "25%          67.800000  3.378469e+06\n",
       "50%          90.400000  9.720694e+06\n",
       "75%          98.500000  2.892890e+07\n",
       "max         100.000000  2.313000e+09"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics\n",
    "    #Load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('literary_birth_rate_new.csv')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots and histograms\n",
    "* Bar plots for discrete data counts\n",
    "* Histograms for continuous data counts\n",
    "* Look at frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.population.plot('hist')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>female literacy</th>\n",
       "      <th>fertility</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chine</td>\n",
       "      <td>ASI</td>\n",
       "      <td>90.5</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.324655e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inde</td>\n",
       "      <td>ASI</td>\n",
       "      <td>50.8</td>\n",
       "      <td>2.682</td>\n",
       "      <td>1.139965e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Australia</td>\n",
       "      <td>OCE</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.313000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country Continent  female literacy fertility    population\n",
       "0        Chine       ASI             90.5     1.769  1.324655e+09\n",
       "1         Inde       ASI             50.8     2.682  1.139965e+09\n",
       "162  Australia       OCE             96.0      1.93  2.313000e+09"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying the error\n",
    "df[df.population > 1000000000]\n",
    "\n",
    "# slice data to see populations greater than 1 Billion. Data set from 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not all outliers are bad data points\n",
    "* Same can be an error, but others are valid values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "* Viualize basic summary statistics\n",
    "    * Outliers\n",
    "    * Min/Max\n",
    "    * 25th, 50th, 75th percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box plot\n",
    "df.boxplot(column='population', by='Continent')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots\n",
    "* Relationship between 2 numeric variables\n",
    "* Flag potentially bad data\n",
    "    * Errors not found by looking at 1 variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing single variables with histograms\n",
    "Up until now, you've been looking at descriptive statistics of your data. One of the best ways to confirm what the numbers are telling you is to plot and visualize the data.\n",
    "\n",
    "You'll start by visualizing single variables using a histogram for numeric values. The column you will work on in this exercise is `'Existing Zoning Sqft'`.\n",
    "\n",
    "The `.plot()` method allows you to create a plot of each column of a DataFrame. The `kind` parameter allows you to specify the type of plot to use - `kind='hist'`, for example, plots a histogram.\n",
    "\n",
    "In the IPython Shell, begin by computing summary statistics for the `'Existing Zoning Sqft` column using the `.describe()` method. You'll notice that there are extremely large differences between the `min` and `max` values, and the plot will need to be adjusted accordingly. In such cases, it's good to look at the plot on a log scale. The keyword arguments `logx=True` or `logy=True` can be passed in to `.plot()` depending on which axis you want to rescale.\n",
    "\n",
    "Finally, note that Python will render a plot such that the axis will hold all the information. That is, if you end up with large amounts of whitespace in your plot, it indicates counts or values too small to render.\n",
    "\n",
    "* Import `matplotlib.pyplot` as `plt`.\n",
    "* Create a histogram of the `'Existing Zoning Sqft'` column. Rotate the axis labels by 70 degrees and use a log scale for both axes.\n",
    "* Display the histogram using `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('dob_job_application_filings_subset.csv')\n",
    "\n",
    "#print(df.info())\n",
    "\n",
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Describe the column\n",
    "df['Existing Zoning Sqft'].describe()\n",
    "\n",
    "# Plot the histogram\n",
    "df['Existing Zoning Sqft'].plot(kind='hist', rot=70, logx=True, logy=True)\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n",
    "\n",
    "\"\"\"While visualizing your data is a great way to understand it, \n",
    "keep in mind that no one technique is better than another. \n",
    "As you saw here, you still needed to look at the summary statistics to help understand your data better. \n",
    "You expected a large amount of counts on the left side of the plot because the 25th, 50th, \n",
    "and 75th percentiles have a value of 0. The plot shows us that there are barely any counts near the max value, \n",
    "signifying an outlier.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing multiple variables with boxplots\n",
    "Histograms are great ways of visualizing single variables. To visualize multiple variables, boxplots are useful, especially when one of the variables is categorical.\n",
    "\n",
    "In this exercise, your job is to use a boxplot to compare the `'initial_cost'` across the different values of the `'Borough'` column. The pandas `.boxplot()` method is a quick way to do this, in which you have to specify the `column` and `by` parameters. Here, you want to visualize how `'initial_cost'` varies by `'Borough'`.\n",
    "\n",
    "`pandas` and `matplotlib.pyplot` have been imported for you as `pd` and `plt`, respectively, and the DataFrame has been pre-loaded as `df`.\n",
    "\n",
    "* Using the `.boxplot()` method of `df`, create a boxplot of `'initial_cost'` across the different values of `'Borough'`.\n",
    "* Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFhCAYAAAB9Kq2lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xu8VHW9//HXG0gxRM0bKnigzE4gqSRqFzLQOl4yLbsodrNQO7+CrKyOhcejnnaWhXUys+hQlgVmHetQaVrC1ixveE0gj+QlkbxfEq0M+Pz++K7BYWb23sNm771m9vf9fDzmway1vjPzme9s1met72UtRQRmZpavIWUHYGZm5XIiMDPLnBOBmVnmnAjMzDLnRGBmljknAjOzzDkRWJ+RdIGkz5YdR9m6qwdJx0m6ZqBjKpukTknHlx2HNeZEMAhJulfSXyWtlvSEpF9I2rXsuKpJCkkvLTuOdlbsXP9W/M5PSbpa0ivKjsvajxPB4PXmiNgS2Bl4CDi35Hj6jZJc/5ZnFr/zdkAncGFv3kTSsL4MytpLrv95shERfwN+DEyorJO0taTvSXpE0n2STq3sSCWdL+nHVWW/IOnKYmc7VdJKSZ+R9Ghx5vGurj5b0gmSVkh6XNJCSbsU668uitxWHM0e3eC1QyXNKT7nHkkzi7OIYcX2Tkkdkn4LPAu8RNIuxec8XnzuCVXvt0FzTeW7VC3fK+nTkpYVZ1HfkTS8avvhkm6V9KSk30nas2rbJEk3S3pa0g+B9a/rump0bnEU/wdJBxUr3yHpppqCJ0v6aQ/vR0SsAS5iw995c0lfkbSqeHxF0ubV31/Sv0l6EPhOsb6r32xcdf1X/QbHF8+7/b0KYyX9tqinKyRt39P3soHhRDDISXohcDRwXdXqc4GtgZcArwfeC7y/2HYysGfRlv06YAbwvnj+WiQ7AdsDo4H3AXMl/XODzz0QOAt4J+ms5D7SjoqIOKAotldEbBkRP2wQ+gnAocDewCuBtzQo8x7gRGBk8f4LgJXALsDbgc9VdrJNehdwMLAb8DLg1OK7vBL4NvBB0pH3N4GFxY52M+CnpCPxbYEfAW/r4XP2B+4m1eN/AJdI2hZYCLxY0viqsu+miaP8Io53seHvPBt4FakO9wL2q3ynwk5FzGOBE7v7zZrQzO91LOnvbEdgM+ATTb639beI8GOQPYB7gdXAk8AaYBXwimLbUODvwISq8h8EOquW9wMeJ+0Ipletn1q834iqdRcD/148vwD4bPF8HnB2VbktgX8A44rlAF7azXdYBHywavkNxWuGFcudwJlV23cF1gIjq9adBVxQG1vVd1lZU2f/WrV8GPDH4vn5wH/WxHcnKYkeUNSvqrb9rvqzal53XIPyNwDvqfqsjuL5HsATwOZdvFcn6WzoSeA54CngoKrtfwQOq1o+GLi36vs/Bwyv2t7lb1Y81td/1ecfvxG/16lV2z8E/LLs/yt+pIfPCAavt0TENsDmwEzgKkmVo/nNSDv5ivtIR/gARMQNpCNWkXb01Z6IiGdqXrtLg8/fpfozImI18Fj15/RgF+D+quX7G5SpXrcL8HhEPF0TW7OfV/t+1d9rLHBy0Sz0pKQnSYlnl+LxQBR7t6rXdqdR+cpnfRc4VpJIZzwXR8Tfu3mvjxS/83DgcODHVc1WG/wG1P9Wj0RqOqRR+Y38zZr5vR6sev4sKdFYC3AiGOQiYm1EXEI6Wp4CPEo6yhtbVeyfgAcqC5I+TEogq4BP1bzliySNqHntqgYfvar6M4rXbFf9OT34MzCmarnRqKfqnekqYFtJI2tiq3zeM8ALq7bt1OD9qj+j+nvdTzpK36bq8cKIWFDEObrYcVe/tjuNyq8CiIjrSEfqryM1pTTV+RsR6yLiN8AK4F+K1Rv8BtT/VrWXHu7uN6sk/67qsJnfy1qUE8EgV3TyHgm8CFgeEWtJR/kdkkZKGgt8HPh+Uf5lwGdJbdPvAT4lae+atz1D0mZFH8LhpHbxWvOB90vau+ig/BxwfUTcW2x/iNRH0ZWLgZMkjZa0DfBvxfrbJE2tLRwR95OaZM6SNFzSCuBfgR8URW4FDpO0bXFm9A023KkBfFjSmKK9/jNApe/izUUs+xf1OULSm4qkcy2puewjkoZJOorUtNadHYvyL5D0DmA8cGnV9u8BXwPWRETTcw4kvZrUWby0WLUAOFXSDkXH7GkUv3MXuvzNIuIRUkJ4d9Ex/AFSX0pFV7+XtQEngsHrZ5JWA38BOkgdvpUdxCzSEd7dwDWkHcC3ixEe3we+EBG3RcRdpB3ihZXRJqTT+ydIR48/ILWr/6H2wyPiSuDfgf8hHS3uBhxTVeR04LtFU8s7G8T/LeAK4HbgFtKOcg0wMSI6u/jO00lt2atIzVqfiYhfSTodmAbcRuoLuAI4g9Q8UW1+se3u4lEZZfQccA5p5/wE6aj7uOJ7PgccVSw/QeqYv6SL+CquB3YnnZ11AG+PiMeqtl8ITASaGdL5NaWRV6uL150aEZcV2z4LLCHV4e+Bm6u+U50mfrMTgE+Smov2ICXeiq5+r7VNfAcrmTZsqjTrWnEk/v2IGNNT2X747EOBb0TE2B4L17/2dFLH9Lu7KXMvqePz1xuzrT9I2oLUWb80IiYPxGf2tU35vWzg+YzAWpKkLSQdVjS3jCYNs/yJ0nj/N0g6XdLFSvMhnpa0VNLkqtdXyh1COqs5ujhyvq3YXj0GfjdgFGkY56OSflA0b2xMvEOV5lf8sYjnJhWzuSW9RtKNSvMGbpT0mqrXHSfp7uI19yjNy/gPUof+pCLmJzepMgdAV79X2XFZc0pNBJK+LelhSXc0UXas0sSm24v/xAN+VGoDSqTmmydITQ3LSW3c1Y4gjXPfhjQG/2u1bxIRvyS1df8w0pyFvbr4rKdIzTrjSR2dp29kvB8nNU0dBmwFfAB4tuhv+AXwVVLH6znALyRtV3TGfhU4NCJGAq8Bzi7e5wzg2iLmjUpKJWnm97IWVfYZwQXAIU2W/RLwvYjYEziTNEbcBlBEdA5Us1BEPBsR+0bEyIjYMSLeHxF/qSl2TURcWnSAX0iaNNWbz1oRETtFxGVFp+g5pDkCG+N4Uvv8nZHcVrT7vwm4KyIujIg1xUijP5A6oAHWARMlbRERf46I0UVzyp96813K0uTvZS2q1EQQEVeT2kLXk7SbpF8Wp9a/kfTyYtME4Mri+WLgyAEM1VpT7bj04erFNXMk7SjpIkkPSPoLqcN8Yy9/sCtpAlet2rH8FMuji/kYR5NGN/1Z6eKAL699A7P+VvYZQSNzgVkRsQ9pCvrXi/W38fzU/bcCIyVtV0J81n56GhFxVlFmz4jYijR0Vt2/pM79bDicsqJ2LD9UzW+IiMsj4o2kSzr8gTT6ppmYzfpMSyUCSVuS2kl/JOlW0jVddi42fwJ4vaRbSKftD5CGp5n15CFgnLq+QulIiktyFB2dn+zFZ/w38J+Sdi/mGuxZHKhcCrxM0rFFR+rRpLPbn0saJemIoq/g70UMleGWDwFjlK4hZNavWioRkOJ5MiL2rnqMB4iIVRFxVERMIl1Mi4h4qsxgrW1UJrw9JunmBtvPIF0o7SlSx25P8wAaOYc0qeoK0tyNecAWRT/B4aSL+T1Gmql9eEQ8Svp7P5l01vA46QDnQ8X7LSJNDHtQ0qO9iMesaaXPI5A0Dvh5REwsln8HfDkifiRJpNP124qZkY9HxDpJHcDaiPCoBDOzTVT28NEFpCn6/6x0bfQZpEvpzijGey/l+U7hqcCdkv6PNOa7o4SQzcwGndLPCMzahaTLSBeDq/W5iPjcQMdj1lecCMzMMtdqncVmZjbASrth9fbbbx/jxo0r6+M38MwzzzBixIieC2bEdVLPdVLPdVKvlerkpptuejQiduipXGmJYNy4cSxZsqSsj99AZ2cnU6dOLTuMluI6qec6qec6qddKdSKpp7vlAW4aMjPLnhOBmVnmnAjMzDLnRGBmljknAjOzzDkRmPVgwYIFTJw4kYMOOoiJEyeyYMGCskMy61OlDR81awcLFixg9uzZzJs3j7Vr1zJ06FBmzJgBwPTp00uOzqxv+IzArBsdHR3MmzePadOmMWzYMKZNm8a8efPo6PA1D23wcCIw68by5cuZMmXKBuumTJnC8uXLS4rIrO85EZh1Y/z48VxzzTUbrLvmmmsYP358SRGZ9T0nArNuzJ49mxkzZrB48WLWrFnD4sWLmTFjBrNnzy47NLM+485is25UOoRnzZrF8uXLGT9+PB0dHe4otkHFicCsB9OnT2f69OktdTExs77kpiEzs8w5EZiZZc6JwMwsc04EZmaZcyIwM8ucE4GZWeacCMzMMudEYGaWOScCM7PMORGYmWXOicDMLHNOBGZmmXMiMDPLXFOJQNIhku6UtELSKQ22/5OkxZJukXS7pMP6PlQzM+sPPSYCSUOB84BDgQnAdEkTaoqdClwcEZOAY4Cv93WgZmbWP5o5I9gPWBERd0fEc8BFwJE1ZQLYqni+NbCq70I0M7P+1MyNaUYD91ctrwT2rylzOnCFpFnACOANfRKdmZn1u2YSgRqsi5rl6cAFETFH0quBCyVNjIh1G7yRdCJwIsCoUaPo7OzsRch9b/Xq1S0TS6twndRzndRzndRrxzppJhGsBHatWh5DfdPPDOAQgIi4VtJwYHvg4epCETEXmAswefLkaJXb/vkWhPVcJ/VcJ/VcJ/XasU6a6SO4Edhd0oslbUbqDF5YU+ZPwEEAksYDw4FH+jJQMzPrHz0mgohYA8wELgeWk0YHLZV0pqQjimInAydIug1YABwXEbXNR2Zm1oKaaRoiIi4FLq1Zd1rV82XAa/s2NDMzGwieWWxmljknAjOzzDkRmJllzonAzCxzTgRmZplzIjAzy5wTgZlZ5pwIzMwy50RgZpY5JwIzs8w5EZiZZc6JwMwsc04EZmaZcyIwM8ucE4GZWeacCMzMMudEYGaWOScCM7PMORGYmWXOicDMLHNOBGZmmXMiMDPLnBOBmVnmnAjMzDLnRGBmljknAjOzzDkRmJllzonAzCxzTgRmZplzIjAzy5wTgZlZ5pwIzMwy50RgZpY5JwIzs8w5EZiZZa6pRCDpEEl3Sloh6ZQuyrxT0jJJSyXN79swzcysvwzrqYCkocB5wBuBlcCNkhZGxLKqMrsDnwZeGxFPSNqxvwI2M7O+1cwZwX7Aioi4OyKeAy4CjqwpcwJwXkQ8ARARD/dtmGZm1l96PCMARgP3Vy2vBPavKfMyAEm/BYYCp0fEL2vfSNKJwIkAo0aNorOzsxch973Vq1e3TCytwnVSz3VSz3VSrx3rpJlEoAbrosH77A5MBcYAv5E0MSKe3OBFEXOBuQCTJ0+OqVOnbmy8/aKzs5NWiaVVuE7quU7quU7qtWOdNNM0tBLYtWp5DLCqQZn/jYh/RMQ9wJ2kxGBmZi2umURwI7C7pBdL2gw4BlhYU+anwDQASduTmoru7stAzcysf/SYCCJiDTATuBxYDlwcEUslnSnpiKLY5cBjkpYBi4FPRsRj/RW0mZn1nWb6CIiIS4FLa9adVvU8gI8XDzMzayOeWWxmljknAjOzzDkRmJllzonAzCxzTgRmZplzIjAzy5wTgZlZ5pwIzMwy50RgZpY5JwIzs8w5EZiZZc6JwMwsc04EZmaZcyIwM8ucE4GZWeacCMzMMudEYGaWOScCM7PMORGYmWXOicDMLHNOBGZmmXMiMDPLnBOBmVnmnAjMzDLnRGBmljknAjOzzDkRmJllzonAzCxzTgRmZplzIjAzy5wTgZlZ5pwIzMwy50RgZpY5JwIzs8w1lQgkHSLpTkkrJJ3STbm3SwpJk/suRDMz6089JgJJQ4HzgEOBCcB0SRMalBsJfAS4vq+DNDOz/tPMGcF+wIqIuDsingMuAo5sUO4/gbOBv/VhfGZm1s+aSQSjgfurllcW69aTNAnYNSJ+3oexmZnZABjWRBk1WBfrN0pDgC8Dx/X4RtKJwIkAo0aNorOzs6kg+9vq1atbJpZW4Tqp5zqp5zqp14510kwiWAnsWrU8BlhVtTwSmAh0SgLYCVgo6YiIWFL9RhExF5gLMHny5Jg6dWrvI+9DnZ2dtEosrcJ1Us91Us91Uq8d66SZpqEbgd0lvVjSZsAxwMLKxoh4KiK2j4hxETEOuA6oSwJmZtaaekwEEbEGmAlcDiwHLo6IpZLOlHREfwdoZmb9q5mmISLiUuDSmnWndVF26qaHZWZmA8Uzi83MMudEYGaWOScCM7PMORGYmWXOicDMLHNOBGZmmXMiMDPLnBOBmVnmnAjMzDLnRGBmljknAjOzzDkRmJllzonAzCxzTgRmZplzIjAzy5wTgZlZ5pwIzMwy50RgZpY5JwIzs8w5EZiZZc6JwMwsc04EZmaZcyIwM8ucE4GZWeacCMzMMudEYGaWOScCM7PMORGYmWXOicDMLHNOBGZmmXMiMDPLnBOBmVnmnAjMzDLnRGBmljknAjOzzDWVCCQdIulOSSskndJg+8clLZN0u6QrJY3t+1DNzKw/9JgIJA0FzgMOBSYA0yVNqCl2CzA5IvYEfgyc3deBmplZ/2jmjGA/YEVE3B0RzwEXAUdWF4iIxRHxbLF4HTCmb8M0M7P+0kwiGA3cX7W8sljXlRnAZZsSlJmZDZxhTZRRg3XRsKD0bmAy8Poutp8InAgwatQoOjs7m4uyn61evbplYmkVrpN6rpN6rpN67VgnzSSClcCuVctjgFW1hSS9AZgNvD4i/t7ojSJiLjAXYPLkyTF16tSNjbdfdHZ20iqxtArXST3XST3XSb12rJNmmoZuBHaX9GJJmwHHAAurC0iaBHwTOCIiHu77MM3MrL/0mAgiYg0wE7gcWA5cHBFLJZ0p6Yii2BeBLYEfSbpV0sIu3s7MzFpMM01DRMSlwKU1606rev6GPo7LzMwGiGcWm5llzonAzCxzTgRmZplzIjAzy5wTgZlZ5pwIzMwy50RgZpY5JwIzs8w5EZiZZc6JwMwsc04EZmaZcyIwM8ucE4GZWeacCMzMMudEYGaWOScCM7PMORGYmWXOicDMLHNOBGZmmXMiMDPLnBOBmVnmnAjMzDLnRGBmljknAjOzzDkRmJllzonAzCxzTgRmZplzIjAzy5wTgVkPFixYwMSJEznooIOYOHEiCxYsKDsksz41rOwAzFrZggULmD17NvPmzWPt2rUMHTqUGTNmADB9+vSSozPrGz4jMOtGR0cH8+bNY9q0aQwbNoxp06Yxb948Ojo6yg7NrM84EZh1Y/ny5UyZMmWDdVOmTGH58uUlRWTW95wIzLoxfvx4zjjjjA36CM444wzGjx9fdmilmjVrFsOHD2fatGkMHz6cWbNmlR2SbQInAtuA/4NvaNq0aXR0dLB06VLWrVvH0qVL6ejoYNq0aWWHVppZs2Zx3nnnsXbtWgDWrl3Leeedl/3fSluLiB4fwCHAncAK4JQG2zcHflhsvx4Y19N77rPPPlG2mTNnxuabbx5AbL755jFz5syyQyrVzJkzA6h75FwvI0aMaFgnI0aMKDu00gwZMqRhnQwZMqTs0Eo1f/782GOPPWLIkCGxxx57xPz588sOKYAl0cw+vscCMBT4I/ASYDPgNmBCTZkPAd8onh8D/LCn9y07EXinV69RfVQeuXKd1HOd1Js/f37D+ig7GTSbCJTKdk3Sq4HTI+LgYvnTxZnEWVVlLi/KXCtpGPAgsEN08+aTJ0+OJUuWdPvZ/UlSl9t6qpPBynVSz3VSz3VSr7pOJk6cyB133LF+ucw6kXRTREzuqVwzfQSjgfurllcW6xqWiYg1wFPAds2FWq6IYPHixdn+ATfiOqm3aNEifvWrX7Fo0aKyQ2kZc+bM4bLLLmPOnDllh9IyIoJzzz237f7vNHNG8A7g4Ig4vlh+D7BfRMyqKrO0KLOyWP5jUeaxmvc6ETgRYNSoUftcdNFFmxT8rPtaq3Pq3LHnlh2C66QLrVQvrpN6rpN6fVEn06ZNa+qMoJmZxSuBXauWxwCruiizsmga2hp4vPaNImIuMBdS09DUqVOb+Piu/Z7f9/q1lVO5OXPmMGHCBJYtW8bJJ59ciXOT4ipTX9RJI+1cJ9D7enGd1KvUyZAhQ1i3bt36f8F1smjRovUz0A888ECgPeqkmURwI7C7pBcDD5A6g4+tKbMQeB9wLfB2YFF3/QOtpLLzN7ONU9n5V/411u/8202PiSAi1kiaCVxOGkH07YhYKulMUo/0QmAecKGkFaQzgWP6M+i+EBENj/baJH/1C9dJPddJPddJvXavk6YmlEXEpRHxsojYLSI6inWnFUmAiPhbRLwjIl4aEftFxN39GXRfqQydqnSMtsuP1p9cJ/VcJ/VcJ/XauU48s9jMLHNOBGZmmXMiMDPLnBOBmVnmnAjMzDLX48zifvtg6RHgvlI+vN72wKNlB9FiXCf1XCf1XCf1WqlOxkbEDj0VKi0RtBJJS5qZhp0T10k910k910m9dqwTNw2ZmWXOicDMLHNOBMncsgNoQa6Teq6Teq6Tem1XJ+4jMDPLnM8IzMwy50RgZpY5JwIzs00kaQdJPY7Xb1XZJQJJu3az7XUDGYuZtS8lp0t6FPgD8H+SHpF0Wtmxbaxm7lA22Fwl6RvAORGxBkDSKGAO8M/AvmUGVwZJvwK6GjUQEXHwQMbTCiQtpvs6OWgg4ymbpDcDt0fEfcXyacDbSFcHOCki7ikzvpJ8FHgtsG/l+0t6CXC+pI9FxJdLjW4jZDdqSNKLgM8DrwFOAl4BfBw4Gzg/IrK7756k/Rusngx8CngsIl45wCGVTtI+DVa/ilQnD0dEVgcMkm4HXhURz0o6HDgHmA5MAt6R6cHCLcAbI+LRmvU7AFdExKRyItt42Z0RRMQTwAclnQT8GlhF+gNfWW5k5YmI6yvPJb0W+Hdga2BmRPystMBKFBE3VZ5Lej2pTjYH/jUiListsPJERDxbPD8KmFfU0U2SPlRiXGV6QW0SAIiIRyS9oIyAeiu7RCBpG+ALwP7AIcBhwGWSToqIRaUGVyJJB5F2dgF8LiJ+VXJIpZN0MKlO/gZ0RMTikkMqkyRtCTwLHAR8vWrb8HJCKt1zvdzWcrJLBMDNpD/iDxd9BFdI2hv4uqT7ImJ6ueENPEnXATsBXwR+U6zbs7I9Im4vKbTSSLoR2IFUJ9cW69Y3kUXEzSWFVpavALcCfwGWR8QSAEmTgD+XGViJ9pL0lwbrRZslxxz7CMY0agaSJOD4iPhWCWGVStI1PN8xGqQ/5IqIiAMGPqpySeqk+zo5cMCDKpmk0cCOwG2VvjRJO5OaSP5UanC2SbJLBFZP0pYRsbrsONqFpBdExD/KjmMgSfqn7rY7EbS37BKBpKd5/kivcpQXpGayzSIiu+YySSuAUyLix2XH0qqKM8ZpwLHAmyNiVMkhDShJv6fBmRGp+WzHiBhaSmAlqtqX1NZJ2+1LsptQFhEjI2Kr4jES2AXoAB4E/qvc6ErzRuC9ki6T9OKyg2klkvaX9F+k8fILSX0oLy83qoEXEa+IiD2Lf18BvBn4LbCaNJ4+O1X7kpHtvi/J7oygohg99FHgvcB84MsR8Vi5UZWrmDT0LeA6YP18iog4qrSgSiKpA3gn8CdgAfATYElEZJ0oJe0OzCaNupsDfDe3ZrJag2Ff0janLn1F0vbAycDRwLeBSRHxVLlRla/4Dz6LlATOoyoRZOpE4E7gfODnEfE3SXkeNQGSJpISwB6kyZczImJtuVGVazDtS7I7I5D0DPAI8B3g6drtEXHOgAdVMkmfBd4OfCIifl52PK1A0lDgX0izZw8EFgNvAHatXJokJ5LWAvcDvwDqEkBEfGTAgyrZYNqXZHdGQBoXXsl+I8sMpIW8gHQ089faDZL2r555nIviaPcy0mTD4cDhwAuBByRdGRHHlhrgwJtB19deylV3+5K2qqvszghs40j6U0R0O3RwMJJ0VERc0mD9VsBbI+K7JYTVkiQNy/EsqTuS9o2IG8uOo1nZjRoCkHSopKslPVpcNvYqSYeVHVeLUs9FBqVTG62MiL/kmASKSYeV5xfWbL5hgMNpSZImSDpT0l2kvqW2kV3TkKQTgA+SriK5pFg9Gfh8Meu47W483c98ymgAI6qe71GzLdeDBSSNJfUjTQfWAGOByRFxb5lxbazsEgHwMWBKRDxetW6RpEOBa4DsEoGkn9F4hy9guwEOp1W8vLj0ci2RLjGxZ4Ntg1l3BwRZHixI+h3pKr0XAW+PiLsk3dNuSQDyTASqSQIARMRjafJolr7Uy22D2T2kSVOWbCPpraTm5G0kVeaWiLQzzNEjwBhgFGmG9V20aVLMMRH8RdJeEXFb9UpJe9FgCFgmNuvqstOSvgBcNcDxtIK/V+7GZQBcDRxRPL+KDZPk1QMfTvki4khJW5Pu1HaGpJeSkuR+EdFW/SbZjRqSNAX4AWns702kDL4v8D7g3RFxTTcvH5Qk/R/wsYj4RdW6IaRJMjtFxCGlBVcSSb8vLqVg1hRJO5Iml00nzTfp8v7orSa7UUPFjn5/0nc/DvhA8fxVOSaBwr8Acyqn+5K2IF1XZzPybR7xcMgqkr5S9fykmm0XDHhALSgiHo6IcyPiNbTZSKrszgi6I+m1EfHbsuMog6QxwOXAucB7gOsj4uPlRlUeSTfneK/mrlTXR23duK7qtdv8m+z6CIpLB7wTGA1cFhFLi5txfwbYgnQz7qxU3XnrU8D3gF8B36+sz/BuXOBRQ7XUxXNrrK3qKLtEAMwDdiWdup0raRVpHsEpEfHTUiMrz5yq57eTRkFU1gXpWju58aihDQ2R9CJSM2rleWVnl929CAAkbdvVJtosEWTXNCTpDmDPiFhXXEPmQWC3drtsrPUvSbdERHZnh12RdC/pirSNdnARES8Z2IjKJ+ke6m9MU9FWdZLjGcFzlfutFpcWvttJYP2Ihw+TZo0GsAw4LyIeLjWw8nTZVyRpVEQ8NJDBlC0ixpUdQ6sZTPemyPGM4FlgRWUR2K1YzrXtF0mvJd1Q4wLSkFoBryQNqX1Xrh3o1arGix8LjI+I0SWHNKCq+pEqAng0Iu4vI55WUFxe4snKPQgiqCprAAAJUUlEQVQkTQPeAtxLOoh6rsTwNkqOiWBsd9tznEQk6Trg/0XELTXr9wa+GRH7lxNZuYphtEeQdv6vJF1q+C3A1ZWzylxIWtxg9bakIcbTI+LWAQ6pdJKuJ12JdlXxf+XXwFnAnsA/IuL4UgPcCNklgkaKOw09FplWhqRlETFhY7cNZpJ+ABwAXEG6lswiYMVgag7oC5ImA+dExAFlxzLQJN1eaUGQ9CVgXUR8qpiMeWs7tS5kN6FM0qskdUq6RNKkovP4DuAhSdnNoC2oGAVSu3JbMvwbKUwEngCWA38oblST5YFCdyJiCbBl2XGUpLqT+EDgSoB2PFvMsbP4a6Q5A1uTjvIOjYjrJL2cdJPyX5YZXEm+DFwh6RNAZc7APsAXim3ZiYi9ir+JY4FfS3oYGClpp4h4sOTwWoakUeSbIBdJuhj4M/Ai0v4ESTsDbdM/ABk2DUm6NSL2Lp4vj4jxVduyHTJYTKr7FM9fa34p8MWI+Fl5UbWOognkWNK9nVcWlxHIhqRzqd/hbwu8Bjgpx78TpcsVHw3sDFwcEQ8U6ycBO0bE5WXGtzFyTASeKm+9VvznPyAisroiq6T3FU9HkFoStiadPd6Y8RDjQSPHRLAWeIbUvrcF8GxlEzA8Il5QVmxlKm7McwobziP4QkRcWmpgJeniCHi9iPjIAIZTOkmbAWcD7yUNjxSwI3BuRHxe0qTaUWeDnaSn6fqGThERWw1wSL2WXR9BRGQ5Hb47vn1nQ0uqnp8B/EdZgbSIL5EOnMZGxNMAkrYCviTpfOAQIKsRVRExsuwY+kp2ZwRWT9Iy6m/fiaTtgGuq+1FylHPfUYWkFcDutUOsi4s4Pkox6KKU4GyT5To00DbU5e07ywimBfloKY2Rr6uHYljtI04C7c2JwKC4fWftysxv32kbWibpvbUrJb2bNNfC2pibhsy372ygpiPwhWw4qKCtOgL7gqTRwCXAX9nwb2QL0mUWHigxPNtETgQGgKSdgA+RRg2JNI/gPE+esmqSDqTqbyQiriw5pNJUXYZ6/aqq5YiI3QY+qt5xIrBu5Xz7TrPuFIMpqg0h3f3wE8DNEfG2gY+qd7IbPmr1fPvOelVNQ9XXkwnS/5nNIsL/dzJXGUxRXGTuPcAngVuBN0XEsjJj21j+Yzbw7Tvr1I4RlzSS1HT2QeAnpQRlLUXSC4APAB8DrgGOjIg/lhtV77hpyHz7zm5I2gb4KGlG7Xzgy64XA5C0ElgDfAX4U+32iLhkwIPqJZ8RGPj2nXWKe1ScTLqo2LeBSZU7UZkVfk1qLtyreFQL0iirtuAzAvPtOxuQ9AzwCGlIbd1ciog4Z8CDMusnPiMwgKwvIdGFL/L8UMDaa8r46MmQ9JWI+Gjx/KSI+K+qbRdExHGlBbeRfEZgDeV++87uSNo3Im4sOw4r12C6pL0vMWG+fWcTJE2QdKaku4Dzy47HWoK6eN523DRk4Nt3NiRpLDC9eKwBxgKTI+LeMuOyljGkuNf3kKrnlYTQVpe7d9OQ+fadDUj6HSkxXgRcFBF3SbonIrK65r51TdK9wDoanw1ERLxkYCPqPZ8RGKQ/5oq/1mzL9UjhEWAMMArYAbiLfOvCGnt9RNxXdhB9wWcE5tt3dkHS1sDbSE1DLwW2AQ6OiBtKDcxaQrt1CHfHicCsCZJGkSaXHQPsGhG7lhySlWwwNZs6EZhtJEljB0uTgPWepIdJfUgNRcRHBjCcTeI+ArMGJC3socgRAxKItbLKTXranhOBWWOvBu4nDZ+9njYfJ2794rGI+G7ZQfQFJwKzxnYC3kjqKD4W+AWwICKWlhqVtZLnyg6gr3hmsVkDEbE2In4ZEe8DXkW6CF+npFklh2YtIiJeVbtO0m6STi1m57cNJwKzLkjaXNJRwPeBDwNfpY0uLWwDQ9LOkj4q6QbSvb6Hks4k24ZHDZk1IOm7wETgMtLM4rY6wrP+J+kE0g5/DHBx8fjfdpx97kRg1oCkdaRJdrDhjOLKPRq2GviorJVIeg64Fjg5IpYU6+5up0tLVLiz2KyBiHCzqfVkF+AdwDnFhMOLgbache8zAjOzTSRpDGnW+XTghcBPIuIz5UbVPB/1mJn1gqT1o4YiYmVEfCki9gHeAvy9vMg2ns8IzMx6YTBddM5nBGZmmfMZgZlZL0h6Eri6q+0R0TbXo/KoITOz3nkEmFN2EH3BicDMrHdWR8RVZQfRF9xHYGbWO/eUHUBfcSIwM+udsyTtVFmQ9F5J/yvpq5K2LTOwjeVEYGbWO9+kuBS1pAOAzwPfA54C5pYY10ZzH4GZWe8MjYjHi+dHA3Mj4n+A/5F0a4lxbTSfEZiZ9c5QSZWD6YOARVXb2uogu62CNTNrIQuAqyQ9Srp/8W8AJL2U1DzUNjyhzMysl4rrDe0MXBERzxTrXgZsGRE3lxrcRnAiMDPLnPsIzMwy50RgZpY5JwIbtCStlXSrpNsk3SzpNSXGcpykr5X1+Wbd8aghG8z+GhF7A0g6GDgLeH0zL5Q0NCLW9mdwZq3CZwSWi62AJwCUfFHSHZJ+L+noYv1USb+RtBBYXqz7eFHuDkkfLdaNk3RH5Y0lfULS6cXzfSXdXpyJfLG6HLCLpF9KukvS2QPztc165jMCG8y2KGZ4DicN8TuwWH8UsDewF7A9cKOkynXlXwlMjIh7JO0DvB/YHxBwvaSrKBJKF74DnBgRv5P0+ZptewOTSLcxvFPSuRFx/yZ/S7NN5DMCG8z+GhF7R8TLgUOA70kSMAVYEBFrI+Ih4Cpg3+I1N0RE5aqSU0g3IX8mIlYDlwCv6+rDJG0DjIyI3xWr5tcUuTIinoqIvwHLgLF98SXNNpUTgWUhIq4lHf3vQDq678ozVc+7KreGDf/vDO+hfEX1Dc3X4jNyaxFOBJYFSS8HhgKPkW4veLSkoZJ2AA4AbmjwsquBt0h6oaQRwFtJlxF4CNhR0naSNgcOB4iIJ4Cni9mmAMf065cy6yM+IrHBrNJHAOlo/X0RsVbST4BXA7cBAXwqIh4sksV6EXGzpAt4Pkn8d0TcAiDpzGL9KuAPVS+bAXxL0jpSk1NbXXPG8uRLTJj1IUlbFv0JSDoF2DkiTio5LLNu+YzArG+9SdKnSf+37gOOKzccs575jMDMLHPuLDYzy5wTgZlZ5pwIzMwy50RgZpY5JwIzs8w5EZiZZe7/A+rbp0+hzKO3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('dob_job_application_filings_subset.csv')\n",
    "\n",
    "#print(df.info())\n",
    "\n",
    "# Create the boxplot\n",
    "df.boxplot(column='initial_cost', by='Borough', rot=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "'''You can see the 2 extreme outliers are in the borough of Manhattan. \n",
    "An initial guess could be that since land in Manhattan is extremely expensive, \n",
    "these outliers may be valid data points. Again, further investigation is needed to determine whether or \n",
    "not you can drop or keep those points in your data.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing multiple variables with scatter plots\n",
    "Boxplots are great when you have a numeric column that you want to compare across different categories. When you want to visualize two numeric columns, scatter plots are ideal.\n",
    "\n",
    "In this exercise, your job is to make a scatter plot with `'initial_cost'` on the x-axis and the `'total_est_fee'` on the y-axis. You can do this by using the DataFrame `.plot()` method with `kind='scatter'`. You'll notice right away that there are 2 major outliers shown in the plots.\n",
    "\n",
    "Since these outliers dominate the plot, an additional DataFrame, `df_subset`, has been provided, in which some of the extreme values have been removed. After making a scatter plot using this, you'll find some interesting patterns here that would not have been seen by looking at summary statistics or 1 variable plots.\n",
    "\n",
    "When you're done, you can cycle between the two plots by clicking the 'Previous Plot' and 'Next Plot' buttons below the plot.\n",
    "\n",
    "* Using `df`, create a scatter plot (`kind='scatter'`) with `'initial_cost'` on the x-axis and the `'total_est_fee'` on the y-axis. Rotate the x-axis labels by 70 degrees.\n",
    "* Create another scatter plot exactly as above, substituting `df_subset` in place of `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" In general, from the second plot it seems like there is a strong correlation between 'initial_cost' \\nand 'total_est_fee'. In addition, take note of the large number of points that have an 'initial_cost' of 0. \\nIt is difficult to infer any trends from the first plot because it is dominated by the outliers.\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('dob_job_application_filings_subset.csv')\n",
    "df_subset = pd.read_csv('df_dob_job_application_filings_subset2.csv')\n",
    "\n",
    "# Create and display the first scatter plot\n",
    "df.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)\n",
    "plt.show()\n",
    "\n",
    "# Create and display the second scatter plot\n",
    "df_subset.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)\n",
    "plt.show()\n",
    "\n",
    "''' In general, from the second plot it seems like there is a strong correlation between 'initial_cost' \n",
    "and 'total_est_fee'. In addition, take note of the large number of points that have an 'initial_cost' of 0. \n",
    "It is difficult to infer any trends from the first plot because it is dominated by the outliers.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"Tidy Data\" paper by Hadley Wickham, PhD\n",
    "* Formalize the way we describe the shape of data\n",
    "* Gives us a goal when formatting our data\n",
    "* \"Standard way to organize data values within a dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principles of tidy data\n",
    "* Columns represent separate variables\n",
    "* Rows represent individual observations\n",
    "* Observational units for tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to tidy data\n",
    "* Forms that are better for reporting\n",
    "* Forms that are better for analysis\n",
    "* Tidy data makes it easier to fix common data problems\n",
    "* The data problem we are trying to fix:\n",
    "    * Columns containing values, instead of variables\n",
    "* Solution: `pd.melt()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>treatment a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>treatment a</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane</td>\n",
       "      <td>treatment a</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>treatment b</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>treatment b</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jane</td>\n",
       "      <td>treatment b</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name     variable  value\n",
       "0  Daniel  treatment a    NaN\n",
       "1    John  treatment a   12.0\n",
       "2    Jane  treatment a   24.0\n",
       "3  Daniel  treatment b   42.0\n",
       "4    John  treatment b   31.0\n",
       "5    Jane  treatment b   27.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melting\n",
    "\n",
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('treatment.csv')\n",
    "\n",
    "pd.melt(frame=df, id_vars='name',\n",
    "        value_vars=['treatment a', 'treatment b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>treatment</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>treatment a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>treatment a</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane</td>\n",
       "      <td>treatment a</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>treatment b</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>treatment b</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jane</td>\n",
       "      <td>treatment b</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name    treatment  result\n",
       "0  Daniel  treatment a     NaN\n",
       "1    John  treatment a    12.0\n",
       "2    Jane  treatment a    24.0\n",
       "3  Daniel  treatment b    42.0\n",
       "4    John  treatment b    31.0\n",
       "5    Jane  treatment b    27.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melting\n",
    "    # Changing column names\n",
    "pd.melt(frame=df, id_vars='name',\n",
    "        value_vars=['treatment a', 'treatment b'],\n",
    "        var_name='treatment', value_name='result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognizing tidy data\n",
    "For data to be tidy, it must have:\n",
    "\n",
    "* Each variable as a separate column.\n",
    "* Each row as a separate observation.\n",
    "\n",
    "As a data scientist, you'll encounter data that is represented in a variety of different ways, so it is important to be able to recognize tidy (or untidy) data when you see it.\n",
    "\n",
    "In this exercise, two example datasets have been pre-loaded into the DataFrames `df1` and `df2`. Only one of them is tidy. Your job is to explore these further in the IPython Shell and identify the one that is not tidy, and why it is not tidy.\n",
    "\n",
    "In the rest of this course, you will frequently be asked to explore the structure of DataFrames in the IPython Shell prior to performing different operations on them. Doing this will not only strengthen your comprehension of the data cleaning concepts covered in this course, but will also help you realize and take advantage of the relationship between working in the Shell and in the script.\n",
    "\n",
    "#### Possible Answers\n",
    "* df2; the rows are not all separate observations.\n",
    "* df1; each variable is not a separate column.\n",
    "* df2; each variable is not a separate column.\n",
    "* df1; the rows are not all separate observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      116 non-null float64\n",
      "Solar.R    146 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 4 columns):\n",
      "Month       60 non-null int64\n",
      "Day         60 non-null int64\n",
      "variable    60 non-null object\n",
      "value       60 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.4+ KB\n",
      "None\n",
      "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0   41.0    190.0   7.4    67      5    1\n",
      "1   36.0    118.0   8.0    72      5    2\n",
      "2   12.0    149.0  12.6    74      5    3\n",
      "3   18.0    313.0  11.5    62      5    4\n",
      "4    NaN      NaN  14.3    56      5    5\n",
      "   Month  Day variable value\n",
      "0      5    1  Solar.R    41\n",
      "1      5    2    Ozone    36\n",
      "2      5    3     Temp    12\n",
      "3      5    4     Wind    18\n",
      "4      5    5  Solar.R   NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Notice that the variable column of df2 contains the values Solar.R, Ozone, Temp, and Wind. \\nFor it to be tidy, these should all be in separate columns, as in df1.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df1 = pd.read_csv('./datasets/airquality.csv')\n",
    "df2 = pd.read_csv('./datasets/airquality2.csv')\n",
    "\n",
    "print(df1.info())\n",
    "print(df2.info())\n",
    "\n",
    "print(df1.head())\n",
    "print(df2.head())\n",
    "\n",
    "'''Notice that the variable column of df2 contains the values Solar.R, Ozone, Temp, and Wind. \n",
    "For it to be tidy, these should all be in separate columns, as in df1.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping your data using melt\n",
    "Melting data is the process of turning columns of your data into rows of data. Consider the DataFrames from the previous exercise. In the tidy DataFrame, the variables `Ozone`, `Solar.R`, `Wind`, and `Temp` each had their own column. If, however, you wanted these variables to be in rows instead, you could melt the DataFrame. In doing so, however, you would make the data untidy! This is important to keep in mind: Depending on how your data is represented, you will have to reshape it differently (e.g., this could make it easier to plot values).\n",
    "\n",
    "In this exercise, you will practice melting a DataFrame using `pd.melt()`. There are two parameters you should be aware of: `id_vars` and `value_vars`. The `id_vars` represent the columns of the data you do not want to melt (i.e., keep it in its current shape), while the `value_vars` represent the columns you do wish to melt into rows. By default, if no `value_vars` are provided, all columns not set in the `id_vars` will be melted. This could save a bit of typing, depending on the number of columns that need to be melted.\n",
    "\n",
    "The (tidy) DataFrame `airquality` has been pre-loaded. Your job is to melt its `Ozone`, `Solar.R`, `Wind`, and `Temp` columns into rows. Later in this chapter, you'll learn how to bring this melted DataFrame back into a tidy form.\n",
    "\n",
    "* Print the head of airquality.\n",
    "* Use pd.melt() to melt the Ozone, Solar.R, Wind, and Temp columns of airquality into rows. Do this by using id_vars to specify the columns you do not wish to melt: 'Month' and 'Day'.\n",
    "* Print the head of airquality_melt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0   41.0    190.0   7.4    67      5    1\n",
      "1   36.0    118.0   8.0    72      5    2\n",
      "2   12.0    149.0  12.6    74      5    3\n",
      "3   18.0    313.0  11.5    62      5    4\n",
      "4    NaN      NaN  14.3    56      5    5\n",
      "   Month  Day variable  value\n",
      "0      5    1    Ozone   41.0\n",
      "1      5    2    Ozone   36.0\n",
      "2      5    3    Ozone   12.0\n",
      "3      5    4    Ozone   18.0\n",
      "4      5    5    Ozone    NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This exercise demonstrates that melting a DataFrame is not always appropriate if you want to make it tidy. \\nYou may have to perform other transformations depending on how your data is represented. '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(frame = airquality, id_vars=['Month', 'Day'])\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "\n",
    "'''This exercise demonstrates that melting a DataFrame is not always appropriate if you want to make it tidy. \n",
    "You may have to perform other transformations depending on how your data is represented. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing melted data\n",
    "When melting DataFrames, it would be better to have column names more meaningful than variable and value (the default names used by pd.melt()).\n",
    "\n",
    "The default names may work in certain situations, but it's best to always have data that is self explanatory.\n",
    "\n",
    "You can rename the variable column by specifying an argument to the var_name parameter, and the value column by specifying an argument to the value_name parameter. You will now practice doing exactly this. Pandas as pd and the DataFrame airquality has been pre-loaded for you.\n",
    "\n",
    "* Print the head of airquality.\n",
    "* Melt the columns of airquality with the defaultvariablecolumn renamed to'measurement'and the defaultvaluecolumn renamed to'reading'. You can do this by specifying, respectively, the `varname` and `valuename` parameters.\n",
    "* Print the head of airquality_melt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0   41.0    190.0   7.4    67      5    1\n",
      "1   36.0    118.0   8.0    72      5    2\n",
      "2   12.0    149.0  12.6    74      5    3\n",
      "3   18.0    313.0  11.5    62      5    4\n",
      "4    NaN      NaN  14.3    56      5    5\n",
      "   Month  Day measurement  reading\n",
      "0      5    1       Ozone     41.0\n",
      "1      5    2       Ozone     36.0\n",
      "2      5    3       Ozone     12.0\n",
      "3      5    4       Ozone     18.0\n",
      "4      5    5       Ozone      NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The DataFrame is more informative now. \\nIn the next video, you'll learn about pivoting, which is the opposite of melting. \\nYou'll then be able to convert this DataFrame back into its original, tidy, form!\\n\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(airquality, id_vars=['Month', 'Day'], var_name='measurement', value_name='reading')\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "\n",
    "'''The DataFrame is more informative now. \n",
    "In the next video, you'll learn about pivoting, which is the opposite of melting. \n",
    "You'll then be able to convert this DataFrame back into its original, tidy, form!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot: un-melting data\n",
    "* Opposite of melting\n",
    "* In melting, turn columns into rows\n",
    "* Pivoting: turn unique value into separate columns\n",
    "* Turn analysis friendly shape to reporting friendly shape\n",
    "* Data violate tidy data principle: rows contain observations\n",
    "    * Multiple variables stored in the same column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date element  value\n",
      "0  1/30/2010    tmax   27.8\n",
      "1  1/30/2010    tmin   14.5\n",
      "2   2/2/2010    tmax   27.3\n",
      "3   2/2/2010    tmin   14.4\n",
      "element    tmax  tmin\n",
      "date                 \n",
      "1/30/2010  27.8  14.5\n",
      "2/2/2010   27.3  14.4\n"
     ]
    }
   ],
   "source": [
    "# Pivot\n",
    "weather = pd.read_csv('./datasets/weather.csv')\n",
    "\n",
    "weather_tidy = weather.pivot(index='date',\n",
    "                             columns = 'element',\n",
    "                             values = 'value')\n",
    "print(weather)\n",
    "\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-9eaa4e251fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m weather2_tidy = weather2.pivot(index='date',\n\u001b[1;32m      5\u001b[0m                              \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'element'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                              values = 'value')\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   5192\u001b[0m         \"\"\"\n\u001b[1;32m   5193\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5196\u001b[0m     _shared_docs['pivot_table'] = \"\"\"\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m    413\u001b[0m             indexed = self._constructor_sliced(self[values].values,\n\u001b[1;32m    414\u001b[0m                                                index=index)\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   2897\u001b[0m         \"\"\"\n\u001b[1;32m   2898\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    499\u001b[0m         unstacker = _Unstacker(obj.values, obj.index, level=level,\n\u001b[1;32m    500\u001b[0m                                \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                                constructor=obj._constructor_expanddim)\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munstacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, index, level, value_columns, fill_value, constructor)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_sorted_values_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_sorted_values_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             raise ValueError('Index contains duplicate entries, '\n\u001b[0m\u001b[1;32m    176\u001b[0m                              'cannot reshape')\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "# Pivot\n",
    "weather2 = pd.read_csv('./datasets/weather2.csv')\n",
    "\n",
    "weather2_tidy = weather2.pivot(index='date',\n",
    "                             columns = 'element',\n",
    "                             values = 'value')\n",
    "print(weather2)\n",
    "\n",
    "print(weather2_tidy)\n",
    "# Error-> ValueError: Index contains duplicate entries, cannot reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot table method\n",
    "* Has a parameter that specifies how to deal with duplicate values\n",
    "* Example: Can aggregate the duplicate values by taking their average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element    tmax  tmin\n",
      "date                 \n",
      "1/30/2010  27.8  14.5\n",
      "2/2/2010   27.3  15.4\n"
     ]
    }
   ],
   "source": [
    "# Pivot Table method\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# read file\n",
    "weather2 = pd.read_csv('./datasets/weather2.csv')\n",
    "# perform pivot\n",
    "weather2_tidy = weather2.pivot_table(index='date',\n",
    "                                     columns = 'element',\n",
    "                                     values = 'value',\n",
    "                                     aggfunc = np.mean) # give average of duplicate values\n",
    "print(weather2_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot data\n",
    "Pivoting data is the opposite of melting it. Remember the tidy form that the airquality DataFrame was in before you melted it? You'll now begin pivoting it back into that form using the .pivot_table() method!\n",
    "\n",
    "While melting takes a set of columns and turns it into a single column, pivoting will create a new column for each unique value in a specified column.\n",
    "\n",
    ".pivot_table() has an index parameter which you can use to specify the columns that you don't want pivoted: It is similar to the id_vars parameter of pd.melt(). Two other parameters that you have to specify are columns (the name of the column you want to pivot), and values (the values to be used when the column is pivoted). The melted DataFrame airquality_melt has been pre-loaded for you.\n",
    "\n",
    "* Print the head of airquality_melt.\n",
    "* Pivot airquality_melt by using .pivot_table() with the rows indexed by 'Month' and 'Day', the columns indexed by 'measurement', and the values populated with 'reading'.\n",
    "* Print the head of airquality_pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Day measurement  reading\n",
      "0      5    1       Ozone     41.0\n",
      "1      5    2       Ozone     36.0\n",
      "2      5    3       Ozone     12.0\n",
      "3      5    4       Ozone     18.0\n",
      "4      5    5       Ozone      NaN\n",
      "measurement  Ozone  Solar.R  Temp  Wind\n",
      "Month Day                              \n",
      "5     1       41.0    190.0  67.0   7.4\n",
      "      2       36.0    118.0  72.0   8.0\n",
      "      3       12.0    149.0  74.0  12.6\n",
      "      4       18.0    313.0  62.0  11.5\n",
      "      5        NaN      NaN  56.0  14.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Notice that the pivoted DataFrame does not actually look like the original DataFrame. \\nIn the next exercise, you'll turn this pivoted DataFrame back into its original form. \""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "# Open connection to file\n",
    "#aq_melt_file = open('./datasets/airqualit_melt.csv', \"w\")\n",
    "# save to file\n",
    "#airquality_melt.to_csv(aq_melt_file)\n",
    "\n",
    "# Pivot airquality_melt: airquality_pivot\n",
    "airquality_pivot = airquality_melt.pivot_table(index=['Month', 'Day'], columns='measurement', values='reading')\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())\n",
    "\n",
    "'''Notice that the pivoted DataFrame does not actually look like the original DataFrame. \n",
    "In the next exercise, you'll turn this pivoted DataFrame back into its original form. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting the index of a DataFrame\n",
    "After pivoting `airquality_melt` in the previous exercise, you didn't quite get back the original DataFrame.\n",
    "\n",
    "What you got back instead was a pandas DataFrame with a [hierarchical index (also known as a MultiIndex)](http://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html).\n",
    "\n",
    "Hierarchical indexes are covered in depth in [Manipulating DataFrames with pandas](https://www.datacamp.com/courses/manipulating-dataframes-with-pandas). In essence, they allow you to group columns or rows by another variable - in this case, by `'Month'` as well as `'Day'`.\n",
    "\n",
    "There's a very simple method you can use to get back the original DataFrame from the pivoted DataFrame: `.reset_index()`. Dan didn't show you how to use this method in the video, but you're now going to practice using it in this exercise to get back the original DataFrame from `airquality_pivot`, which has been pre-loaded.\n",
    "\n",
    "* Print the index of airquality_pivot by accessing its .index attribute. This has been done for you.\n",
    "* Reset the index of airquality_pivot using its .reset_index() method.\n",
    "* Print the new index of airquality_pivot.\n",
    "* Print the head of airquality_pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex(levels=[[5, 6, 7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]],\n",
      "           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]],\n",
      "           names=['Month', 'Day'])\n",
      "RangeIndex(start=0, stop=153, step=1)\n",
      "measurement  Month  Day  Ozone  Solar.R  Temp  Wind\n",
      "0                5    1   41.0    190.0  67.0   7.4\n",
      "1                5    2   36.0    118.0  72.0   8.0\n",
      "2                5    3   12.0    149.0  74.0  12.6\n",
      "3                5    4   18.0    313.0  62.0  11.5\n",
      "4                5    5    NaN      NaN  56.0  14.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" You've now converted the DataFrame back into its original form! \""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the index of airquality_pivot\n",
    "print(airquality_pivot.index)\n",
    "\n",
    "# Reset the index of airquality_pivot: airquality_pivot_reset\n",
    "airquality_pivot_reset = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the new index of airquality_pivot_reset\n",
    "print(airquality_pivot_reset.index)\n",
    "\n",
    "# Print the head of airquality_pivot_reset\n",
    "print(airquality_pivot_reset.head())\n",
    "\n",
    "''' You've now converted the DataFrame back into its original form! '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting duplicate values\n",
    "So far, you've used the .pivot_table() method when there are multiple index values you want to hold constant during a pivot. In the video, Dan showed you how you can also use pivot tables to deal with duplicate values by providing an aggregation function through the aggfunc parameter. Here, you're going to combine both these uses of pivot tables.\n",
    "\n",
    "Let's say your data collection method accidentally duplicated your dataset. Such a dataset, in which each row is duplicated, has been pre-loaded as airquality_dup. In addition, the airquality_melt DataFrame from the previous exercise has been pre-loaded. Explore their shapes in the IPython Shell by accessing their .shape attributes to confirm the duplicate rows present in airquality_dup.\n",
    "\n",
    "You'll see that by using .pivot_table() and the aggfunc parameter, you can not only reshape your data, but also remove duplicates. Finally, you can then flatten the columns of the pivoted DataFrame using .reset_index().\n",
    "\n",
    "NumPy and pandas have been imported as np and pd respectively.\n",
    "\n",
    "* Pivot airquality_dup by using .pivot_table() with the rows indexed by 'Month' and 'Day', the columns indexed by 'measurement', and the values populated with 'reading'. Use np.mean for the aggregation function.\n",
    "* Print the head of airquality_pivot.\n",
    "* Flatten airquality_pivot by resetting its index.\n",
    "* Print the head of airquality_pivot and then the original airquality DataFrame to compare their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement  Ozone  Solar.R  Wind\n",
      "Month Day                        \n",
      "5     1       41.0    190.0   7.4\n",
      "      2       36.0    118.0   8.0\n",
      "      3       12.0    149.0  12.6\n",
      "      4       18.0    313.0  11.5\n",
      "      5        NaN      NaN  14.3\n",
      "measurement  Month  Day  Ozone  Solar.R  Wind\n",
      "0                5    1   41.0    190.0   7.4\n",
      "1                5    2   36.0    118.0   8.0\n",
      "2                5    3   12.0    149.0  12.6\n",
      "3                5    4   18.0    313.0  11.5\n",
      "4                5    5    NaN      NaN  14.3\n",
      "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0   41.0    190.0   7.4    67      5    1\n",
      "1   36.0    118.0   8.0    72      5    2\n",
      "2   12.0    149.0  12.6    74      5    3\n",
      "3   18.0    313.0  11.5    62      5    4\n",
      "4    NaN      NaN  14.3    56      5    5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fantastic! The default aggregation function used by .pivot_table() is np.mean(). \\nSo you could have pivoted the duplicate values in this DataFrame even without explicitly specifying the aggfunc parameter.\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot Table method\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# read file\n",
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "airquality_dup = pd.read_csv('./datasets/airquality_dup.csv')\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(airquality, id_vars=['Month', 'Day'], var_name='measurement', value_name='reading')\n",
    "\n",
    "# Pivot table the airquality_dup: airquality_pivot\n",
    "airquality_pivot = airquality_dup.pivot_table(index=['Month', 'Day'], \n",
    "                                              columns = 'measurement', \n",
    "                                              values = 'reading', \n",
    "                                              aggfunc = np.mean)\n",
    "\n",
    "# Print the head of airquality_pivot before reset_index\n",
    "print(airquality_pivot.head())\n",
    "\n",
    "# Reset the index of airquality_pivot\n",
    "airquality_pivot = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())\n",
    "\n",
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "\n",
    "'''Fantastic! The default aggregation function used by .pivot_table() is np.mean(). \n",
    "So you could have pivoted the duplicate values in this DataFrame even without explicitly specifying the aggfunc parameter.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Beyond melt and pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond melt and pivot\n",
    "* Melting and pivoting are basic tools\n",
    "* Another common problem:\n",
    "    * Columns contain multiple bits of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>m1524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>m1524</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AF</td>\n",
       "      <td>2000</td>\n",
       "      <td>m1524</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year variable  value\n",
       "0      AD  2000     m014      0\n",
       "1      AE  2000     m014      2\n",
       "2      AF  2000     m014     52\n",
       "3      AD  2000    m1524      0\n",
       "4      AE  2000    m1524      4\n",
       "5      AF  2000    m1524    228"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melting and parsing\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tb = pd.read_csv('./datasets/tuburculosis.csv')\n",
    "#tb = pd.read_csv('./datasets/tb.csv')\n",
    "\n",
    "tb_melt = pd.melt(frame=tb, id_vars=['country', 'year'])\n",
    "\n",
    "tb_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melting and parsing\n",
    "* Nothing inherently wrong about original data shape\n",
    "    * Lots of data comes this way\n",
    "* Not conducive for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>2000</td>\n",
       "      <td>m014</td>\n",
       "      <td>52</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>2000</td>\n",
       "      <td>m1524</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE</td>\n",
       "      <td>2000</td>\n",
       "      <td>m1524</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AF</td>\n",
       "      <td>2000</td>\n",
       "      <td>m1524</td>\n",
       "      <td>228</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year variable  value sex\n",
       "0      AD  2000     m014      0   m\n",
       "1      AE  2000     m014      2   m\n",
       "2      AF  2000     m014     52   m\n",
       "3      AD  2000    m1524      0   m\n",
       "4      AE  2000    m1524      4   m\n",
       "5      AF  2000    m1524    228   m"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melting and parsing\n",
    "tb_melt['sex'] = tb_melt.variable.str[0]\n",
    "    # using the first letter in the 'variable' column \n",
    "\n",
    "tb_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting a column with .str\n",
    "The dataset you saw in the video, consisting of case counts of tuberculosis by country, year, gender, and age group, has been pre-loaded into a DataFrame as tb.\n",
    "\n",
    "In this exercise, you're going to tidy the 'm014' column, which represents males aged 0-14 years of age. In order to parse this value, you need to extract the first letter into a new column for gender, and the rest into a column for age_group. Here, since you can parse values by position, you can take advantage of pandas' vectorized string slicing by using the str attribute of columns of type object.\n",
    "\n",
    "Begin by printing the columns of tb in the IPython Shell using its .columns attribute, and take note of the problematic column.\n",
    "\n",
    "* Melt tb keeping 'country' and 'year' fixed.\n",
    "* Create a 'gender' column by slicing the first letter of the variable column of tb_melt.\n",
    "* Create an 'age_group' column by slicing the rest of the variable column of tb_melt.\n",
    "* Print the head of tb_melt. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country  year variable  value gender age_group\n",
      "0      AD  2000     m014    0.0      m       014\n",
      "1      AE  2000     m014    2.0      m       014\n",
      "2      AF  2000     m014   52.0      m       014\n",
      "3      AG  2000     m014    0.0      m       014\n",
      "4      AL  2000     m014    2.0      m       014\n"
     ]
    }
   ],
   "source": [
    "# Melting and parsing\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tb = pd.read_csv('./datasets/tb.csv')\n",
    "\n",
    "# Melt tb: tb_melt\n",
    "tb_melt = pd.melt(frame=tb, id_vars=['country', 'year'])\n",
    "\n",
    "# Create the 'gender' column\n",
    "tb_melt['gender'] = tb_melt.variable.str[0]\n",
    "\n",
    "# Create the 'age_group' column\n",
    "tb_melt['age_group'] = tb_melt.variable.str[1:]\n",
    "\n",
    "# Print the head of tb_melt\n",
    "print(tb_melt.head())\n",
    "#tb_melt\n",
    "'''Notice the new 'gender' and 'age_group' columns you created. \n",
    "It is vital to be able to split columns as needed so you can access the data that \n",
    "is relevant to your question.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting a column with .split() and .get()\n",
    "Another common way multiple variables are stored in columns is with a delimiter. You'll learn how to deal with such cases in this exercise, using a [dataset consisting of Ebola cases and death counts by state and country](https://data.humdata.org/dataset/ebola-cases-2014). It has been pre-loaded into a DataFrame as ebola.\n",
    "\n",
    "Print the columns of ebola in the IPython Shell using ebola.columns. Notice that the data has column names such as Cases_Guinea and Deaths_Guinea. Here, the underscore _ serves as a delimiter between the first part (cases or deaths), and the second part (country).\n",
    "\n",
    "This time, you cannot directly slice the variable by position as in the previous exercise. You now need to use Python's built-in string method called .split(). By default, this method will split a string into parts separated by a space. However, in this case you want it to split by an underscore. You can do this on Cases_Guinea, for example, using Cases_Guinea.split('_'), which returns the list `['Cases', 'Guinea']`.\n",
    "\n",
    "The next challenge is to extract the first element of this list and assign it to a type variable, and the second element of the list to a country variable. You can accomplish this by accessing the str attribute of the column and using the .get() method to retrieve the 0 or 1 index, depending on the part you want.\n",
    "\n",
    "* Melt ebola using 'Date' and 'Day' as the id_vars, 'type_country' as the var_name, and 'counts' as the value_name.\n",
    "* Create a column called 'str_split' by splitting the 'type_country' column of ebola_melt on '_'. Note that you will first have to access the str attribute of type_country before you can use .split().\n",
    "* Create a column called 'type' by using the .get() method to retrieve index 0 of the 'str_split' column of ebola_melt.\n",
    "* Create a column called 'country' by using the .get() method to retrieve index 1 of the 'str_split' column of ebola_melt.\n",
    "* Print the head of ebola. This has been done for you, so hit 'Submit Answer' to view the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
       "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
       "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
       "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
       "       'Deaths_Spain', 'Deaths_Mali'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "ebola = pd.read_csv('./datasets/ebola.csv')\n",
    "\n",
    "ebola.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  type_country  counts        str_split   type country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  [Cases, Guinea]  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  [Cases, Guinea]  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  [Cases, Guinea]  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  [Cases, Guinea]  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  [Cases, Guinea]  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "# Melt ebola: ebola_melt\n",
    "ebola_melt = pd.melt(ebola, id_vars=['Date', 'Day'], var_name='type_country'\n",
    ", value_name='counts')\n",
    "\n",
    "# Create the 'str_split' column\n",
    "ebola_melt['str_split'] = ebola_melt.type_country.str.split('_')\n",
    "\n",
    "# Create the 'type' column\n",
    "ebola_melt['type'] = ebola_melt.str_split.str.get(0)\n",
    "\n",
    "# Create the 'country' column\n",
    "ebola_melt['country'] = ebola_melt.str_split.str.get(1)\n",
    "\n",
    "# Print the head of ebola_melt\n",
    "print(ebola_melt.head())\n",
    "#ebola_melt.to_csv('./datasets/ebola_melt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining data\n",
    "* Data may not always come in 1 huge file\n",
    "    * 5 million row dataset may be broken into 5 separate datasets\n",
    "    * Easier to store and share\n",
    "    * May have new data for each day, like stocks\n",
    "* Important to be able to combine then clean, or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date element  value\n",
      "0  1/30/2010    tmax   27.8\n",
      "1  1/31/2010    tmin   14.5\n",
      "0  1/30/2010    tmax   27.3\n",
      "1  1/31/2010    tmin   14.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "weather_p1 = pd.read_csv('./datasets/weather_p1.csv')\n",
    "weather_p2 = pd.read_csv('./datasets/weather_p2.csv')\n",
    "\n",
    "# pandas concat\n",
    "concatenated = pd.concat([weather_p1, weather_p2])\n",
    "print(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date element  value\n",
      "0  1/30/2010    tmax   27.8\n",
      "0  1/30/2010    tmax   27.3\n"
     ]
    }
   ],
   "source": [
    "# pandas concat\n",
    "concatenated = concatenated.loc[0, :]\n",
    "print(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date element  value\n",
      "0  1/30/2010    tmax   27.8\n",
      "1  1/31/2010    tmin   14.5\n",
      "2  1/30/2010    tmax   27.3\n",
      "3  1/31/2010    tmin   14.4\n"
     ]
    }
   ],
   "source": [
    "# pandas concat\n",
    "concatenated = pd.concat([weather_p1, weather_p2], ignore_index=True)\n",
    "print(concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining rows of data\n",
    "The dataset you'll be working with here relates to [NYC Uber data](http://data.beta.nyc/dataset/uber-trip-data-foiled-apr-sep-2014). The original dataset has all the originating Uber pickup locations by time and latitude and longitude. For didactic purposes, you'll be working with a very small portion of the actual data.\n",
    "\n",
    "Three DataFrames have been pre-loaded: uber1, which contains data for April 2014, uber2, which contains data for May 2014, and uber3, which contains data for June 2014. Your job in this exercise is to concatenate these DataFrames together such that the resulting DataFrame has the data for all three months.\n",
    "\n",
    "Begin by exploring the structure of these three DataFrames in the IPython Shell using methods such as .head().\n",
    "\n",
    "* Concatenate uber1, uber2, and uber3 together using pd.concat(). You'll have to pass the DataFrames in as a list.\n",
    "* Print the shape and then the head of the concatenated DataFrame, row_concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 4)\n",
      "       Date/Time      Lat      Lon    Base\n",
      "0  4/1/2014 0:11  40.7690 -73.9549  B02512\n",
      "1  4/1/2014 0:17  40.7267 -74.0345  B02512\n",
      "2  4/1/2014 0:21  40.7316 -73.9873  B02512\n",
      "3  4/1/2014 0:28  40.7588 -73.9776  B02512\n",
      "4  4/1/2014 0:33  40.7594 -73.9722  B02512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You have successfully concatenated the three uber DataFrames! \\nNotice that the head of row_concat is the same as the head of uber1, \\nwhile the tail of row_concat is the same as the tail of uber3.\\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "uber1 = pd.read_csv('./datasets/uber_1.csv')\n",
    "uber2 = pd.read_csv('./datasets/uber_2.csv')\n",
    "uber3 = pd.read_csv('./datasets/uber_3.csv')\n",
    "\n",
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1, uber2, uber3])\n",
    "\n",
    "# Print the shape of row_concat\n",
    "print(row_concat.shape)\n",
    "\n",
    "# Print the head of row_concat\n",
    "print(row_concat.head())\n",
    "''' You have successfully concatenated the three uber DataFrames! \n",
    "Notice that the head of row_concat is the same as the head of uber1, \n",
    "while the tail of row_concat is the same as the tail of uber3.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining columns of data\n",
    "Think of column-wise concatenation of data as stitching data together from the sides instead of the top and bottom. To perform this action, you use the same pd.concat() function, but this time with the keyword argument axis=1. The default, axis=0, is for a row-wise concatenation.\n",
    "\n",
    "You'll return to the [Ebola dataset](https://data.humdata.org/dataset/ebola-cases-2014) you worked with briefly in the last chapter. It has been pre-loaded into a DataFrame called ebola_melt. In this DataFrame, the status and country of a patient is contained in a single column. This column has been parsed into a new DataFrame, status_country, where there are separate columns for status and country.\n",
    "\n",
    "Explore the ebola_melt and status_country DataFrames in the IPython Shell. Your job is to concatenate them column-wise in order to obtain a final, clean DataFrame.\n",
    "\n",
    "* Concatenate ebola_melt and status_country column-wise into a single DataFrame called ebola_tidy. Be sure to specify axis=1 and to pass the two DataFrames in as a list.\n",
    "* Print the shape and then the head of the concatenated DataFrame, ebola_tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day status_country  counts\n",
      "0    1/5/2015  289   Cases_Guinea  2776.0\n",
      "1    1/4/2015  288   Cases_Guinea  2775.0\n",
      "2    1/3/2015  287   Cases_Guinea  2769.0\n",
      "3    1/2/2015  286   Cases_Guinea     NaN\n",
      "4  12/31/2014  284   Cases_Guinea  2730.0 \n",
      "\n",
      "  status country\n",
      "0  Cases  Guinea\n",
      "1  Cases  Guinea\n",
      "2  Cases  Guinea\n",
      "3  Cases  Guinea\n",
      "4  Cases  Guinea \n",
      "\n",
      "(1952, 6) \n",
      "\n",
      "         Date  Day status_country  counts status country\n",
      "0    1/5/2015  289   Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288   Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287   Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286   Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284   Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The concatenated DataFrame has 6 columns, as it should. \\nNotice how the status and country columns have been concatenated column-wise.\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "ebola_melt = pd.read_csv('./datasets/ebola_melt.csv')\n",
    "status_country = pd.read_csv('./datasets/ebola_status_country.csv')\n",
    "\n",
    "print(ebola_melt.head(),'\\n')\n",
    "print(status_country.head(),'\\n')\n",
    "\n",
    "# Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "ebola_tidy = pd.concat([ebola_melt, status_country], axis=1)\n",
    "\n",
    "# Print the shape of ebola_tidy\n",
    "print(ebola_tidy.shape,'\\n')\n",
    "\n",
    "# Print the head of ebola_tidy\n",
    "print(ebola_tidy.head())\n",
    "\n",
    "''' The concatenated DataFrame has 6 columns, as it should. \n",
    "Notice how the status and country columns have been concatenated column-wise.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding and concatenating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating many files\n",
    "* Leverage Python's features with data cleaning in pandas\n",
    "* In order to concatenate DataFrames:\n",
    "    * The must be in a list\n",
    "    * Can individually load if there are a few datasets\n",
    "    * But what if there are thousands?\n",
    "* Solution: glob funciton to find files based on a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globbing\n",
    "* Pattern matching for file names\n",
    "* Wildcards:\"*\" \"?\"\n",
    "    * Any csv file: *.csv\n",
    "    * Any single character: file_?.csv\n",
    "* Ruturns a list of file names\n",
    "* Can use this list to lad into separate DataFrames\n",
    "\n",
    "* Load files from globbing into pandas\n",
    "* Add the DataFrames into a list\n",
    "* concatenate multiple datasets at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./datasets/uber_3.csv', './datasets/uber_1.csv', './datasets/uber_2.csv']\n"
     ]
    }
   ],
   "source": [
    "# find and concatenate\n",
    "import glob\n",
    "#csv_files = glob.glob('*.csv')\n",
    "csv_files = glob.glob('./datasets/uber_?.csv')\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/1/2014 0:01</td>\n",
       "      <td>40.7131</td>\n",
       "      <td>-74.0097</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/1/2014 0:04</td>\n",
       "      <td>40.3461</td>\n",
       "      <td>-74.6610</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/1/2014 0:04</td>\n",
       "      <td>40.7555</td>\n",
       "      <td>-73.9833</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/1/2014 0:07</td>\n",
       "      <td>40.6880</td>\n",
       "      <td>-74.1831</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/1/2014 0:08</td>\n",
       "      <td>40.7152</td>\n",
       "      <td>-73.9917</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/1/2014 0:08</td>\n",
       "      <td>40.7282</td>\n",
       "      <td>-73.9910</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6/1/2014 0:08</td>\n",
       "      <td>40.3042</td>\n",
       "      <td>-73.9794</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6/1/2014 0:09</td>\n",
       "      <td>40.7270</td>\n",
       "      <td>-73.9915</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6/1/2014 0:10</td>\n",
       "      <td>40.7221</td>\n",
       "      <td>-73.9965</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6/1/2014 0:11</td>\n",
       "      <td>40.7153</td>\n",
       "      <td>-74.0146</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6/1/2014 0:15</td>\n",
       "      <td>40.6176</td>\n",
       "      <td>-74.0197</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6/1/2014 0:16</td>\n",
       "      <td>40.7025</td>\n",
       "      <td>-73.9897</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6/1/2014 0:17</td>\n",
       "      <td>40.7350</td>\n",
       "      <td>-74.1650</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6/1/2014 0:17</td>\n",
       "      <td>40.7357</td>\n",
       "      <td>-74.0068</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6/1/2014 0:18</td>\n",
       "      <td>40.6904</td>\n",
       "      <td>-73.9572</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6/1/2014 0:19</td>\n",
       "      <td>40.7384</td>\n",
       "      <td>-73.9857</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6/1/2014 0:20</td>\n",
       "      <td>40.7406</td>\n",
       "      <td>-74.0066</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6/1/2014 0:21</td>\n",
       "      <td>40.7535</td>\n",
       "      <td>-73.9813</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6/1/2014 0:21</td>\n",
       "      <td>40.7220</td>\n",
       "      <td>-73.9804</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6/1/2014 0:23</td>\n",
       "      <td>40.8095</td>\n",
       "      <td>-74.1037</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6/1/2014 0:23</td>\n",
       "      <td>40.7482</td>\n",
       "      <td>-73.9745</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6/1/2014 0:30</td>\n",
       "      <td>40.7043</td>\n",
       "      <td>-73.9330</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6/1/2014 0:32</td>\n",
       "      <td>40.7298</td>\n",
       "      <td>-73.9898</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6/1/2014 0:32</td>\n",
       "      <td>40.7397</td>\n",
       "      <td>-74.0053</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6/1/2014 0:34</td>\n",
       "      <td>40.7607</td>\n",
       "      <td>-74.0025</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6/1/2014 0:37</td>\n",
       "      <td>40.7578</td>\n",
       "      <td>-73.9703</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6/1/2014 0:39</td>\n",
       "      <td>40.7349</td>\n",
       "      <td>-73.9850</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6/1/2014 0:39</td>\n",
       "      <td>40.7133</td>\n",
       "      <td>-73.9775</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6/1/2014 0:40</td>\n",
       "      <td>40.7273</td>\n",
       "      <td>-73.9936</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6/1/2014 0:40</td>\n",
       "      <td>40.7610</td>\n",
       "      <td>-73.6035</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5/1/2014 5:17</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>-74.0027</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5/1/2014 5:18</td>\n",
       "      <td>40.7781</td>\n",
       "      <td>-73.9749</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5/1/2014 5:21</td>\n",
       "      <td>40.7612</td>\n",
       "      <td>-73.9995</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5/1/2014 5:23</td>\n",
       "      <td>40.7592</td>\n",
       "      <td>-74.0234</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5/1/2014 5:24</td>\n",
       "      <td>40.8895</td>\n",
       "      <td>-73.7939</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5/1/2014 5:27</td>\n",
       "      <td>40.7449</td>\n",
       "      <td>-73.9772</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5/1/2014 5:27</td>\n",
       "      <td>40.7449</td>\n",
       "      <td>-73.9772</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5/1/2014 5:29</td>\n",
       "      <td>40.6951</td>\n",
       "      <td>-74.1784</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5/1/2014 5:30</td>\n",
       "      <td>40.7705</td>\n",
       "      <td>-73.9857</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5/1/2014 5:34</td>\n",
       "      <td>40.7327</td>\n",
       "      <td>-74.0088</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5/1/2014 5:35</td>\n",
       "      <td>40.7985</td>\n",
       "      <td>-73.9729</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5/1/2014 5:36</td>\n",
       "      <td>40.7486</td>\n",
       "      <td>-73.9737</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5/1/2014 5:38</td>\n",
       "      <td>40.7372</td>\n",
       "      <td>-74.0372</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5/1/2014 5:38</td>\n",
       "      <td>40.7372</td>\n",
       "      <td>-74.0372</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5/1/2014 5:38</td>\n",
       "      <td>40.7912</td>\n",
       "      <td>-73.9651</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5/1/2014 5:39</td>\n",
       "      <td>40.7323</td>\n",
       "      <td>-73.9941</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5/1/2014 5:40</td>\n",
       "      <td>40.7828</td>\n",
       "      <td>-73.9797</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5/1/2014 5:40</td>\n",
       "      <td>40.7828</td>\n",
       "      <td>-73.9797</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5/1/2014 5:41</td>\n",
       "      <td>40.7179</td>\n",
       "      <td>-73.9895</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5/1/2014 5:46</td>\n",
       "      <td>40.7290</td>\n",
       "      <td>-74.0066</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5/1/2014 5:49</td>\n",
       "      <td>40.8109</td>\n",
       "      <td>-74.1575</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5/1/2014 5:49</td>\n",
       "      <td>40.7149</td>\n",
       "      <td>-74.0065</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5/1/2014 5:56</td>\n",
       "      <td>40.7186</td>\n",
       "      <td>-74.0079</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5/1/2014 6:03</td>\n",
       "      <td>40.7745</td>\n",
       "      <td>-73.9838</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5/1/2014 6:03</td>\n",
       "      <td>40.7753</td>\n",
       "      <td>-73.9901</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5/1/2014 6:07</td>\n",
       "      <td>40.7204</td>\n",
       "      <td>-74.0085</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5/1/2014 6:07</td>\n",
       "      <td>40.7175</td>\n",
       "      <td>-74.0022</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5/1/2014 6:07</td>\n",
       "      <td>40.7321</td>\n",
       "      <td>-73.9885</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5/1/2014 6:08</td>\n",
       "      <td>40.7273</td>\n",
       "      <td>-73.9922</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6/1/2014 0:00</td>\n",
       "      <td>40.7293</td>\n",
       "      <td>-73.9920</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date/Time      Lat      Lon    Base\n",
       "0   6/1/2014 0:01  40.7131 -74.0097  B02512\n",
       "1   6/1/2014 0:04  40.3461 -74.6610  B02512\n",
       "2   6/1/2014 0:04  40.7555 -73.9833  B02512\n",
       "3   6/1/2014 0:07  40.6880 -74.1831  B02512\n",
       "4   6/1/2014 0:08  40.7152 -73.9917  B02512\n",
       "5   6/1/2014 0:08  40.7282 -73.9910  B02512\n",
       "6   6/1/2014 0:08  40.3042 -73.9794  B02512\n",
       "7   6/1/2014 0:09  40.7270 -73.9915  B02512\n",
       "8   6/1/2014 0:10  40.7221 -73.9965  B02512\n",
       "9   6/1/2014 0:11  40.7153 -74.0146  B02512\n",
       "10  6/1/2014 0:15  40.6176 -74.0197  B02512\n",
       "11  6/1/2014 0:16  40.7025 -73.9897  B02512\n",
       "12  6/1/2014 0:17  40.7350 -74.1650  B02512\n",
       "13  6/1/2014 0:17  40.7357 -74.0068  B02512\n",
       "14  6/1/2014 0:18  40.6904 -73.9572  B02512\n",
       "15  6/1/2014 0:19  40.7384 -73.9857  B02512\n",
       "16  6/1/2014 0:20  40.7406 -74.0066  B02512\n",
       "17  6/1/2014 0:21  40.7535 -73.9813  B02512\n",
       "18  6/1/2014 0:21  40.7220 -73.9804  B02512\n",
       "19  6/1/2014 0:23  40.8095 -74.1037  B02512\n",
       "20  6/1/2014 0:23  40.7482 -73.9745  B02512\n",
       "21  6/1/2014 0:30  40.7043 -73.9330  B02512\n",
       "22  6/1/2014 0:32  40.7298 -73.9898  B02512\n",
       "23  6/1/2014 0:32  40.7397 -74.0053  B02512\n",
       "24  6/1/2014 0:34  40.7607 -74.0025  B02512\n",
       "25  6/1/2014 0:37  40.7578 -73.9703  B02512\n",
       "26  6/1/2014 0:39  40.7349 -73.9850  B02512\n",
       "27  6/1/2014 0:39  40.7133 -73.9775  B02512\n",
       "28  6/1/2014 0:40  40.7273 -73.9936  B02512\n",
       "29  6/1/2014 0:40  40.7610 -73.6035  B02512\n",
       "..            ...      ...      ...     ...\n",
       "70  5/1/2014 5:17  40.7388 -74.0027  B02512\n",
       "71  5/1/2014 5:18  40.7781 -73.9749  B02512\n",
       "72  5/1/2014 5:21  40.7612 -73.9995  B02512\n",
       "73  5/1/2014 5:23  40.7592 -74.0234  B02512\n",
       "74  5/1/2014 5:24  40.8895 -73.7939  B02512\n",
       "75  5/1/2014 5:27  40.7449 -73.9772  B02512\n",
       "76  5/1/2014 5:27  40.7449 -73.9772  B02512\n",
       "77  5/1/2014 5:29  40.6951 -74.1784  B02512\n",
       "78  5/1/2014 5:30  40.7705 -73.9857  B02512\n",
       "79  5/1/2014 5:34  40.7327 -74.0088  B02512\n",
       "80  5/1/2014 5:35  40.7985 -73.9729  B02512\n",
       "81  5/1/2014 5:36  40.7486 -73.9737  B02512\n",
       "82  5/1/2014 5:38  40.7372 -74.0372  B02512\n",
       "83  5/1/2014 5:38  40.7372 -74.0372  B02512\n",
       "84  5/1/2014 5:38  40.7912 -73.9651  B02512\n",
       "85  5/1/2014 5:39  40.7323 -73.9941  B02512\n",
       "86  5/1/2014 5:40  40.7828 -73.9797  B02512\n",
       "87  5/1/2014 5:40  40.7828 -73.9797  B02512\n",
       "88  5/1/2014 5:41  40.7179 -73.9895  B02512\n",
       "89  5/1/2014 5:46  40.7290 -74.0066  B02512\n",
       "90  5/1/2014 5:49  40.8109 -74.1575  B02512\n",
       "91  5/1/2014 5:49  40.7149 -74.0065  B02512\n",
       "92  5/1/2014 5:56  40.7186 -74.0079  B02512\n",
       "93  5/1/2014 6:03  40.7745 -73.9838  B02512\n",
       "94  5/1/2014 6:03  40.7753 -73.9901  B02512\n",
       "95  5/1/2014 6:07  40.7204 -74.0085  B02512\n",
       "96  5/1/2014 6:07  40.7175 -74.0022  B02512\n",
       "97  5/1/2014 6:07  40.7321 -73.9885  B02512\n",
       "98  5/1/2014 6:08  40.7273 -73.9922  B02512\n",
       "99  6/1/2014 0:00  40.7293 -73.9920  B02512\n",
       "\n",
       "[299 rows x 4 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find and concatenate\n",
    "list_data = []\n",
    "\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "\n",
    "pd.concat(list_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding files that match a pattern\n",
    "You're now going to practice using the glob module to find all csv files in the workspace. In the next exercise, you'll programmatically load them into DataFrames.\n",
    "\n",
    "As Dan showed you in the video, the glob module has a function called glob that takes a pattern and returns a list of the files in the working directory that match that pattern.\n",
    "\n",
    "For example, if you know the pattern is part_ single digit number .csv, you can write the pattern as 'part_?.csv' (which would match part_1.csv, part_2.csv, part_3.csv, etc.)\n",
    "\n",
    "Similarly, you can find all .csv files with '*.csv', or all parts with 'part_*'. The ? wildcard represents any 1 character, and the * wildcard represents any number of characters.\n",
    "\n",
    "* Import the glob module along with pandas (as its usual alias pd).\n",
    "* Write a pattern to match all .csv files.\n",
    "* Save all files that match the pattern using the glob() function within the glob module. That is, by using glob.glob().\n",
    "* Print the list of file names. This has been done for you.\n",
    "* Read the second file in csv_files (i.e., index 1) into a DataFrame called csv2.\n",
    "* Hit 'Submit Answer' to print the head of csv2. Does it look familiar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./datasets/uber_3.csv', './datasets/uber_1.csv', './datasets/uber_2.csv']\n",
      "       Date/Time      Lat      Lon    Base\n",
      "0  4/1/2014 0:11  40.7690 -73.9549  B02512\n",
      "1  4/1/2014 0:17  40.7267 -74.0345  B02512\n",
      "2  4/1/2014 0:21  40.7316 -73.9873  B02512\n",
      "3  4/1/2014 0:28  40.7588 -73.9776  B02512\n",
      "4  4/1/2014 0:33  40.7594 -73.9722  B02512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The next step is to iterate through this list of filenames, \\nload it into a DataFrame, and add it to a list of DataFrames you can \\nthen concatenate together.\\n'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import glob \n",
    "import pandas as pd\n",
    "\n",
    "# Write the pattern: pattern\n",
    "#pattern = '*.csv'\n",
    "pattern = './datasets/uber_*'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Print the file names\n",
    "print(csv_files)\n",
    "\n",
    "# Load the second file into a DataFrame: csv2\n",
    "csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# Print the head of csv2\n",
    "print(csv2.head())\n",
    "\n",
    "''' The next step is to iterate through this list of filenames, \n",
    "load it into a DataFrame, and add it to a list of DataFrames you can \n",
    "then concatenate together.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating and concatenating all matches\n",
    "Now that you have a list of filenames to load, you can load all the files into a list of DataFrames that can then be concatenated.\n",
    "\n",
    "You'll start with an empty list called frames. Your job is to use a for loop to:\n",
    "\n",
    "iterate through each of the filenames\n",
    "read each filename into a DataFrame, and then\n",
    "append it to the frames list.\n",
    "You can then concatenate this list of DataFrames using pd.concat(). Go for it!\n",
    "\n",
    "* Write a for loop to iterate through csv_files:\n",
    "    * In each iteration of the loop, read csv into a DataFrame called df.\n",
    "    * After creating df, append it to the list frames using the .append() method.\n",
    "* Concatenate frames into a single DataFrame called uber.\n",
    "* Hit 'Submit Answer' to see the head and shape of the concatenated DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 4)\n",
      "       Date/Time      Lat      Lon    Base\n",
      "0  6/1/2014 0:01  40.7131 -74.0097  B02512\n",
      "1  6/1/2014 0:04  40.3461 -74.6610  B02512\n",
      "2  6/1/2014 0:04  40.7555 -73.9833  B02512\n",
      "3  6/1/2014 0:07  40.6880 -74.1831  B02512\n",
      "4  6/1/2014 0:08  40.7152 -73.9917  B02512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" You can now programmatically combine datasets that are broken up into many smaller parts. You'll find many datasets in the wild will be stored this way, particularly data that is collected incrementally.\""
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list: frames\n",
    "frames = []\n",
    "\n",
    "#  Iterate over csv_files\n",
    "for csv in csv_files:\n",
    "\n",
    "    #  Read csv into a DataFrame: df\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Append df to frames\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate frames into a single DataFrame: uber\n",
    "uber = pd.concat(frames)\n",
    "\n",
    "# Print the shape of uber\n",
    "print(uber.shape)\n",
    "\n",
    "# Print the head of uber\n",
    "print(uber.head())\n",
    "\n",
    "''' You can now programmatically combine datasets that are broken up into many smaller parts. You'll find many datasets in the wild will be stored this way, particularly data that is collected incrementally.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining data\n",
    "* Concatenation is not the only way data can be combined\n",
    "\n",
    "### Merging data\n",
    "* Similar to joining tables in SQL\n",
    "* Combine disparate datasets based on common columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population_2016</th>\n",
       "      <th>name</th>\n",
       "      <th>ANSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>39250017</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>27862596</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>20612439</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>19745289</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  population_2016        name ANSI\n",
       "0  California         39250017  California   CA\n",
       "1       Texas         27862596       Texas   TX\n",
       "2     Florida         20612439     Florida   FL\n",
       "3    New York         19745289    New York   NY"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging data with pd.merge\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "state_populations = pd.read_csv('./datasets/states_1.csv')\n",
    "state_codes = pd.read_csv('./datasets/states_2.csv')\n",
    "\n",
    "pd.merge(left=state_populations, right=state_codes,\n",
    "         on=None, left_on='state', right_on='name')\n",
    "    # only need to specify 'on' or \"left_on,right_on\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of merges\n",
    "* One to One\n",
    "* Many to One / One to Many\n",
    "* Many to Many\n",
    "* All use the same function\n",
    "* Only difference is the DataFrames you are merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-to-1 data merge\n",
    "Merging data allows you to combine disparate datasets into a single dataset to do more complex analysis.\n",
    "\n",
    "Here, you'll be using survey data that contains readings that William Dyer, Frank Pabodie, and Valentina Roerich took in the late 1920 and 1930 while they were on an expedition towards Antarctica. The dataset was taken from a sqlite database from the [Software Carpentry SQL lesson](http://swcarpentry.github.io/sql-novice-survey/).\n",
    "\n",
    "Two DataFrames have been pre-loaded: site and visited. Explore them in the IPython Shell and take note of their structure and column names. Your task is to perform a 1-to-1 merge of these two DataFrames using the 'name' column of site and the 'site' column of visited.\n",
    "\n",
    "* Merge the site and visited DataFrames on the 'name' column of site and 'site' column of visited.\n",
    "* Print the merged DataFrame o2o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "   ident   site      dated\n",
      "0    619   DR-1   2/8/1927\n",
      "1    734   DR-3   1/7/1939\n",
      "2    837  MSK-4  1/14/1932\n",
      "    name    lat    long  ident   site      dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1   2/8/1927\n",
      "1   DR-3 -47.15 -126.72    734   DR-3   1/7/1939\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1/14/1932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Notice the 1-to-1 correspondence between the name column of the site DataFrame and the site column of the visited DataFrame. This is what made the 1-to-1 merge possible.'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "site = pd.read_csv('./datasets/site.csv')\n",
    "visited = pd.read_csv('./datasets/visited.csv')\n",
    "\n",
    "print(site.head())\n",
    "print(visited.head())\n",
    "\n",
    "# Merge the DataFrames: o2o\n",
    "#o2o = pd.merge(left=visited, right=site, left_on='site', right_on='name')\n",
    "o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print o2o\n",
    "print(o2o)\n",
    "\n",
    "'''Notice the 1-to-1 correspondence between the name column of the site DataFrame and the site column of the visited DataFrame. This is what made the 1-to-1 merge possible.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "   ident  site      dated\n",
      "0    619  DR-1   2/8/1927\n",
      "1    622  DR-1  2/10/1927\n",
      "2    734  DR-3   1/7/1939\n",
      "3    735  DR-3  1/12/1930\n",
      "4    751  DR-3  2/26/1930\n",
      "    name    lat    long  ident   site      dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1   2/8/1927\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  2/10/1927\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  3/22/1932\n",
      "3   DR-3 -47.15 -126.72    734   DR-3   1/7/1939\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1/12/1930\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  2/26/1930\n",
      "6   DR-3 -47.15 -126.72    752   DR-3        NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1/14/1932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Notice how the site data is duplicated during this many-to-1 merge!'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "site = pd.read_csv('./datasets/site.csv')\n",
    "visited = pd.read_csv('./datasets/visited2.csv')\n",
    "\n",
    "print(site.head())\n",
    "print(visited.head())\n",
    "\n",
    "# Merge the DataFrames: m2o\n",
    "m2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print m2o\n",
    "print(m2o)\n",
    "\n",
    "'''Notice how the site data is duplicated during this many-to-1 merge!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-many data merge\n",
    "The final merging scenario occurs when both DataFrames do not have unique keys for a merge. What happens here is that for each duplicated key, every pairwise combination will be created.\n",
    "\n",
    "Two example DataFrames that share common key values have been pre-loaded: df1 and df2. Another DataFrame df3, which is the result of df1 merged with df2, has been pre-loaded. All three DataFrames have been printed - look at the output and notice how pairwise combinations have been created. This example is to help you develop your intuition for many-to-many merges.\n",
    "\n",
    "Here, you'll work with the site and visited DataFrames from before, and a new survey DataFrame. Your task is to merge site and visited as you did in the earlier exercises. You will then merge this merged DataFrame with survey.\n",
    "\n",
    "Begin by exploring the site, visited, and survey DataFrames in the IPython Shell.\n",
    "\n",
    "* Merge the site and visited DataFrames on the 'name' column of site and 'site' column of visited, exactly as you did in the previous two exercises. Save the result as m2m.\n",
    "* Merge the m2m and survey DataFrames on the 'ident' column of m2m and 'taken' column of survey.\n",
    "* Hit 'Submit Answer' to print the first 20 lines of the merged DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "   ident  site      dated\n",
      "0    619  DR-1   2/8/1927\n",
      "1    622  DR-1  2/10/1927\n",
      "2    734  DR-3   1/7/1939\n",
      "3    735  DR-3  1/12/1930\n",
      "4    751  DR-3  2/26/1930\n",
      "   taken person quant  reading\n",
      "0    619   dyer   rad     9.82\n",
      "1    619   dyer   sal     0.13\n",
      "2    622   dyer   rad     7.80\n",
      "3    622   dyer   sal     0.09\n",
      "4    734     pb   rad     8.41\n",
      "     name    lat    long  ident   site      dated  taken person quant  reading\n",
      "0    DR-1 -49.85 -128.57    619   DR-1   2/8/1927    619   dyer   rad     9.82\n",
      "1    DR-1 -49.85 -128.57    619   DR-1   2/8/1927    619   dyer   sal     0.13\n",
      "2    DR-1 -49.85 -128.57    622   DR-1  2/10/1927    622   dyer   rad     7.80\n",
      "3    DR-1 -49.85 -128.57    622   DR-1  2/10/1927    622   dyer   sal     0.09\n",
      "4    DR-1 -49.85 -128.57    844   DR-1  3/22/1932    844    roe   rad    11.25\n",
      "5    DR-3 -47.15 -126.72    734   DR-3   1/7/1939    734     pb   rad     8.41\n",
      "6    DR-3 -47.15 -126.72    734   DR-3   1/7/1939    734   lake   sal     0.05\n",
      "7    DR-3 -47.15 -126.72    734   DR-3   1/7/1939    734     pb  temp   -21.50\n",
      "8    DR-3 -47.15 -126.72    735   DR-3  1/12/1930    735     pb   rad     7.22\n",
      "9    DR-3 -47.15 -126.72    735   DR-3  1/12/1930    735    NaN   sal     0.06\n",
      "10   DR-3 -47.15 -126.72    735   DR-3  1/12/1930    735    NaN  temp   -26.00\n",
      "11   DR-3 -47.15 -126.72    751   DR-3  2/26/1930    751     pb   rad     4.35\n",
      "12   DR-3 -47.15 -126.72    751   DR-3  2/26/1930    751     pb  temp   -18.50\n",
      "13   DR-3 -47.15 -126.72    751   DR-3  2/26/1930    751   lake   sal     0.10\n",
      "14   DR-3 -47.15 -126.72    752   DR-3        NaN    752   lake   rad     2.19\n",
      "15   DR-3 -47.15 -126.72    752   DR-3        NaN    752   lake   sal     0.09\n",
      "16   DR-3 -47.15 -126.72    752   DR-3        NaN    752   lake  temp   -16.00\n",
      "17   DR-3 -47.15 -126.72    752   DR-3        NaN    752    roe   sal    41.60\n",
      "18  MSK-4 -48.87 -123.40    837  MSK-4  1/14/1932    837   lake   rad     1.46\n",
      "19  MSK-4 -48.87 -123.40    837  MSK-4  1/14/1932    837   lake   sal     0.21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Notice how the keys are duplicated in this many-to-many merge!'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "site = pd.read_csv('./datasets/site.csv')\n",
    "visited = pd.read_csv('./datasets/visited2.csv')\n",
    "survey = pd.read_csv('./datasets/survey.csv')\n",
    "\n",
    "print(site.head())\n",
    "print(visited.head())\n",
    "print(survey.head())\n",
    "\n",
    "# Merge site and visited: m2m\n",
    "m2m = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Merge m2m and survey: m2m\n",
    "m2m = pd.merge(left=m2m, right=survey, left_on='ident', right_on='taken')\n",
    "\n",
    "# Print the first 20 lines of m2m\n",
    "print(m2m.head(20))\n",
    "\n",
    "'''Notice how the keys are duplicated in this many-to-many merge!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and clean data\n",
    "`print(df.dtypes)`\n",
    "* There may be times we want to convert from one type to another\n",
    "    * Numeric columns can be strings, or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name           object\n",
      "sex            object\n",
      "treatment a    object\n",
      "treatment b     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv('./datasets/treatment.csv')\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name             object\n",
       "sex            category\n",
       "treatment a      object\n",
       "treatment b      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting data types\n",
    "df['treatment b'] = df['treatment b'].astype(str)\n",
    "\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data\n",
    "* Converting categorical data to 'category' dtype:\n",
    "    * Can make the DataFrame smaller in memory\n",
    "    * Can make them be utilized by other Python libraries for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning data\n",
    "* Numerica data loaded as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name             object\n",
       "sex            category\n",
       "treatment a     float64\n",
       "treatment b      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning bad data\n",
    "df['treatment a'] = pd.to_numeric(df['treatment a'], errors='coerce')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data types\n",
    "In this exercise, you'll see how ensuring all categorical variables in a DataFrame are of type category reduces memory usage.\n",
    "\n",
    "The [tips dataset](https://github.com/mwaskom/seaborn-data/blob/master/tips.csv) has been loaded into a DataFrame called tips. This data contains information about how much a customer tipped, whether the customer was male or female, a smoker or not, etc.\n",
    "\n",
    "Look at the output of tips.info() in the IPython Shell. You'll note that two columns that should be categorical - sex and smoker - are instead of type object, which is pandas' way of storing arbitrary strings. Your job is to convert these two columns to type category and note the reduced memory usage.\n",
    "\n",
    "* Convert the sex column of the tips DataFrame to type 'category' using the .astype() method.\n",
    "* Convert the smoker column of the tips DataFrame.\n",
    "* Print the memory usage of tips after converting the data types of the columns. Use the .info() method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      "total_bill    244 non-null float64\n",
      "tip           244 non-null float64\n",
      "sex           244 non-null object\n",
      "smoker        244 non-null object\n",
      "day           244 non-null object\n",
      "time          244 non-null object\n",
      "size          244 non-null int64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 9.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 7 columns):\n",
      "total_bill    244 non-null float64\n",
      "tip           244 non-null float64\n",
      "sex           244 non-null category\n",
      "smoker        244 non-null category\n",
      "day           244 non-null object\n",
      "time          244 non-null object\n",
      "size          244 non-null int64\n",
      "dtypes: category(2), float64(2), int64(1), object(2)\n",
      "memory usage: 8.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"By converting sex and smoker to categorical variables, the memory usage of the DataFrame went down from 13.4 KB to 10.1KB. This may seem like a small difference here, but when you're dealing with large datasets, the reduction in memory usage can be very significant!\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tips = pd.read_csv('./datasets/tips.csv')\n",
    "\n",
    "print(tips.info())\n",
    "\n",
    "# Convert the sex column to type 'category'\n",
    "tips.sex = tips.sex.astype('category')\n",
    "\n",
    "# Convert the smoker column to type 'category'\n",
    "tips.smoker = tips.smoker.astype('category')\n",
    "\n",
    "# Print the info of tips\n",
    "print(tips.info())\n",
    "\n",
    "'''By converting sex and smoker to categorical variables, the memory usage of the DataFrame went down from 13.4 KB to 10.1KB. This may seem like a small difference here, but when you're dealing with large datasets, the reduction in memory usage can be very significant!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with numeric data\n",
    "If you expect the data type of a column to be numeric (int or float), but instead it is of type object, this typically means that there is a non numeric value in the column, which also signifies bad data.\n",
    "\n",
    "You can use the pd.to_numeric() function to convert a column into a numeric data type. If the function raises an error, you can be sure that there is a bad value within the column. You can either use the techniques you learned in Chapter 1 to do some exploratory data analysis and find the bad value, or you can choose to ignore or coerce the value into a missing value, NaN.\n",
    "\n",
    "A modified version of the tips dataset has been pre-loaded into a DataFrame called tips. For instructional purposes, it has been pre-processed to introduce some 'bad' data for you to clean. Use the .info() method to explore this. You'll note that the total_bill and tip columns, which should be numeric, are instead of type object. Your job is to fix this.\n",
    "\n",
    "* Use pd.to_numeric() to convert the 'total_bill' column of tips to a numeric data type. Coerce the errors to NaN by specifying the keyword argument errors='coerce'.\n",
    "* Convert the 'tip' column of 'tips' to a numeric data type exactly as you did for the 'total_bill' column.\n",
    "* Print the info of tips to confirm that the data types of 'total_bill' and 'tips' are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304 entries, 0 to 303\n",
      "Data columns (total 7 columns):\n",
      "total_bill    304 non-null object\n",
      "tip           304 non-null object\n",
      "sex           304 non-null object\n",
      "smoker        302 non-null object\n",
      "day           303 non-null object\n",
      "time          300 non-null object\n",
      "size          301 non-null float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304 entries, 0 to 303\n",
      "Data columns (total 7 columns):\n",
      "total_bill    294 non-null float64\n",
      "tip           300 non-null float64\n",
      "sex           304 non-null object\n",
      "smoker        302 non-null object\n",
      "day           303 non-null object\n",
      "time          300 non-null object\n",
      "size          301 non-null float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 11.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The 'total_bill' and 'tip' columns in this DataFrame are stored as object types because the string 'missing' is used in these columns to encode missing values. By coercing the values into a numeric type, they become proper NaN values.\""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tips = pd.read_csv('./datasets/tips2.csv')\n",
    "\n",
    "print(tips.info())\n",
    "\n",
    "# Convert 'total_bill' to a numeric dtype\n",
    "tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')\n",
    "\n",
    "# Convert 'tip' to a numeric dtype\n",
    "tips['tip'] = pd.to_numeric(tips['tip'], errors='coerce')\n",
    "\n",
    "# Print the info of tips\n",
    "print(tips.info())\n",
    "\n",
    "'''The 'total_bill' and 'tip' columns in this DataFrame are stored as object types because the string 'missing' is used in these columns to encode missing values. By coercing the values into a numeric type, they become proper NaN values.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regular expressions to clean strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String manipulation\n",
    "* Much of data cleaning involves string manipulation\n",
    "    * Most of the world's data is unstructured text\n",
    "* Also have to do string manipulation to make datasets consistent with one another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate values\n",
    "* 17\n",
    "* \\$17\n",
    "* \\$17.89\n",
    "* \\$17.895\n",
    "\n",
    "### String manipulation\n",
    "* Many built-in and external libraries\n",
    "* `re` library for regular expressions\n",
    "    * A formal way of specifying a pattern\n",
    "    * Sequence of characters\n",
    "* Pattern matching\n",
    "    * Similar to globbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regex match\n",
    "* 17        1234567890          \\d*              match all numbers\n",
    "* $17       $1234567890         \\$\\d*            match $ and all numbers\n",
    "* $17.00    $1234567890.42      \\$\\d* \\.\\d*      match $ all numbers '.' all numbers\n",
    "* $17.895   $1234567890.42      \\$\\d* \\.\\d{2}    limits to 2 characets after the '.'\n",
    "* $17.895   $1234567890.999     ^\\$\\d* \\.\\d{2}$  limits to only the characters starting \n",
    "                                                  with $ and dending with 2 charaters \n",
    "                                                  after the '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regular expressions\n",
    "* Compile the pattern\n",
    "* Use the compiled pattern to match values\n",
    "* This lets us use the pattern over and over again\n",
    "* Useful since we want to match values down a column of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using regular expressions (regex)\n",
    "import re\n",
    "\n",
    "pattern = re.compile('\\d*\\.\\d{2}')\n",
    "\n",
    "result = pattern.match('17.89')\n",
    "\n",
    "bool(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String parsing with regular expressions\n",
    "In the video, Dan introduced you to the basics of regular expressions, which are powerful ways of defining patterns to match strings. This exercise will get you started with writing them.\n",
    "\n",
    "When working with data, it is sometimes necessary to write a regular expression to look for properly entered values. Phone numbers in a dataset is a common field that needs to be checked for validity. Your job in this exercise is to define a regular expression to match US phone numbers that fit the pattern of xxx-xxx-xxxx.\n",
    "\n",
    "The [regular expression module](https://docs.python.org/3/library/re.html) in python is re. When performing pattern matching on data, since the pattern will be used for a match across multiple rows, it's better to compile the pattern first using re.compile(), and then use the compiled pattern to match values.\n",
    "\n",
    "* Import re.\n",
    "* Compile a pattern that matches a phone number of the format xxx-xxx-xxxx.\n",
    "* Use \\d{x} to match x digits. Here you'll need to use it three times: twice to match 3 digits, and once to match 4 digits.\n",
    "* Place the regular expression inside re.compile().\n",
    "* Using the .match() method on prog, check whether the pattern matches the string '123-456-7890'.\n",
    "* Using the same approach, now check whether the pattern matches the string '1123-456-7890'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Regular expressions can seem challenging at first, but with practice, you'll get better and better at writing them! Here, as expected, the pattern matches the first string, but not the second.\""
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Compile the pattern: prog\n",
    "prog = re.compile('\\d{3}-\\d{3}-\\d{4}')\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('123-456-7890')\n",
    "print(bool(result))\n",
    "\n",
    "# See if the pattern matches\n",
    "result2 = prog.match('1123-456-7890')\n",
    "print(bool(result2))\n",
    "\n",
    "'''Regular expressions can seem challenging at first, but with practice, you'll get better and better at writing them! Here, as expected, the pattern matches the first string, but not the second.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting numerical values from strings\n",
    "Extracting numbers from strings is a common task, particularly when working with unstructured data or log files.\n",
    "\n",
    "Say you have the following string: 'the recipe calls for 6 strawberries and 2 bananas'.\n",
    "\n",
    "It would be useful to extract the 6 and the 2 from this string to be saved for later use when comparing strawberry to banana ratios.\n",
    "\n",
    "When using a regular expression to extract multiple numbers (or multiple pattern matches, to be exact), you can use the re.findall() function. Dan did not discuss this in the video, but it is straightforward to use: You pass in a pattern and a string to re.findall(), and it will return a list of the matches.\n",
    "\n",
    "* Import re.\n",
    "* Write a pattern that will find all the numbers in the following string: 'the recipe calls for 10 strawberries and 1 banana'. To do this:\n",
    "    * Use the re.findall() function and pass it two arguments: the pattern, followed by the string.\n",
    "    * \\d is the pattern required to find digits. This should be followed with a + so that the previous element is matched one or more times. This ensures that 10 is viewed as one number and not as 1 and 0.\n",
    "* Print the matches to confirm that your regular expression found the values 10 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '1']\n"
     ]
    }
   ],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Find the numeric values: matches\n",
    "matches = re.findall('\\d+', 'the recipe calls for 10 strawberries and 1 banana')\n",
    "\n",
    "# Print the matches\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern matching\n",
    "In this exercise, you'll continue practicing your regular expression skills. For each provided string, your job is to write the appropriate pattern to match it.\n",
    "\n",
    "* Write patterns to match:\n",
    "    * A telephone number of the format xxx-xxx-xxxx. You already did this in a previous exercise.\n",
    "    * A string of the format: A dollar sign, an arbitrary number of digits, a decimal point, 2 digits.\n",
    "        * Use \\$ to match the dollar sign, \\d* to match an arbitrary number of digits, \\. to match the decimal point, and \\d{x} to match x number of digits.\n",
    "    * A capital letter, followed by an arbitrary number of alphanumeric characters.\n",
    "        * Use [A-Z] to match any capital letter followed by \\w* to match an arbitrary number of alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Write the first pattern\n",
    "pattern1 = bool(re.match(pattern='\\d{3}-\\d{3}-\\d{4}', string='123-456-7890'))\n",
    "print(pattern1)\n",
    "\n",
    "# Write the second pattern\n",
    "pattern2 = bool(re.match(pattern='\\$\\d*\\.\\d{2}', string='$123.45'))\n",
    "print(pattern2)\n",
    "\n",
    "# Write the third pattern\n",
    "pattern3 = bool(re.match(pattern='[A-Z]\\w*', string='Australia'))\n",
    "print(pattern3)\n",
    "\n",
    "# Write the fourth pattern\n",
    "pattern4 = bool(re.match(pattern='^A*\\D{8}', string='Australia'))\n",
    "print(pattern4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using functions to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name     sex treatment a  treatment b\n",
      "0  Daniel    male           -           42\n",
      "1    John    male          12           31\n",
      "2    Jane  female          24           27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "treatment a    18.000000\n",
       "treatment b    33.333333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using functions to clean data\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv('./datasets/treatment.csv')\n",
    "df2 = pd.read_csv('./datasets/treatment2.csv')\n",
    "\n",
    "print(df)\n",
    "\n",
    "df2.apply(np.mean, axis = 0) # per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    30.0\n",
       "1    21.5\n",
       "2    25.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.apply(np.mean, axis = 1) # per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Job #  Doc #        Borough Initial Cost  initial_cost Total Est. Fee  \\\n",
      "0  121577873      2      MANHATTAN    $75000.00         75000        $986.00   \n",
      "1  520129502      1  STATEN ISLAND        $0.00             0       $1144.00   \n",
      "2  121601560      1      MANHATTAN    $30000.00         30000        $522.50   \n",
      "3  121601203      1      MANHATTAN     $1500.00          1500        $225.00   \n",
      "4  121601338      1      MANHATTAN    $19500.00         19500        $389.50   \n",
      "\n",
      "   total_est_fee  Existing Zoning Sqft  Proposed Zoning Sqft  \\\n",
      "0          986.0                     0                     0   \n",
      "1         1144.0                     0                     0   \n",
      "2          522.5                     0                     0   \n",
      "3          225.0                     0                     0   \n",
      "4          389.5                     0                     0   \n",
      "\n",
      "   Enlargement SQ Footage  Street Frontage  ExistingNo. of Stories  \\\n",
      "0                       0                0                       0   \n",
      "1                       0              143                       0   \n",
      "2                       0                0                       5   \n",
      "3                       0                0                      12   \n",
      "4                       0                0                       6   \n",
      "\n",
      "   Proposed No. of Stories  Existing Height  Proposed Height     diff  \n",
      "0                        0                0                0  74014.0  \n",
      "1                        0                0                0  -1144.0  \n",
      "2                        5               54               54  29477.5  \n",
      "3                       12              120              120   1275.0  \n",
      "4                        6               64               64  19110.5  \n"
     ]
    }
   ],
   "source": [
    "# Using functions to clean data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from numpy import NaN\n",
    "\n",
    "df_subset = pd.read_csv('./datasets/df_dob_job_application_filings_subset2.csv')\n",
    "\n",
    "pattern = re.compile('^\\$\\d*\\.\\d{2}$') #make sure source data doesn't have \",\" separators\n",
    "\n",
    "def diff_money(row, pattern):\n",
    "    \n",
    "    icost = row['Initial Cost']\n",
    "    tef = row['Total Est. Fee']\n",
    "\n",
    "    if bool(pattern.match(icost)) and bool(pattern.match(tef)):\n",
    "        icost = icost.replace(\"$\", \"\")\n",
    "        tef = tef.replace(\"$\", \"\")\n",
    "\n",
    "        icost = float(icost)\n",
    "        tef = float(tef)\n",
    "\n",
    "        return icost - tef\n",
    "    else:\n",
    "        return(NaN)\n",
    "\n",
    "df_subset['diff'] = df_subset.apply(diff_money,\n",
    "                                    axis = 1,\n",
    "                                    pattern = pattern)\n",
    "print(df_subset.head())\n",
    "#print(df_subset.columns)\n",
    "#df_subset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions to clean data\n",
    "You'll now practice writing functions to clean data.\n",
    "\n",
    "The tips dataset has been pre-loaded into a DataFrame called tips. It has a 'sex' column that contains the values 'Male' or 'Female'. Your job is to write a function that will recode 'Female' to 0, 'Male' to 1, and return np.nan for all entries of 'sex' that are neither 'Female' nor 'Male'.\n",
    "\n",
    "Recoding variables like this is a common data cleaning task. Functions provide a mechanism for you to abstract away complex bits of code as well as reuse code. This makes your code more readable and less error prone.\n",
    "\n",
    "As Dan showed you in the videos, you can use the .apply() method to apply a function across entire rows or columns of DataFrames. However, note that each column of a DataFrame is a pandas Series. Functions can also be applied across Series. Here, you will apply your function over the 'sex' column.\n",
    "\n",
    "* Define a function named recode_gender() that has one parameter: gender.\n",
    "    * If gender equals 'Male', return 1.\n",
    "    * Else, if gender equals 'Female', return 0.\n",
    "    * If gender does not equal 'Male' or 'Female', return np.nan. NumPy has been pre-imported for you.\n",
    "* Apply your recode_gender() function over tips.sex using the .apply() method to create a new column: 'recode'. Note that when passing in a function inside the .apply() method, you don't need to specify the parentheses after the function name.\n",
    "* Hit 'Submit Answer' and take note of the new 'gender_recode' column in the tips DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  total_bill   tip     sex smoker  day    time  size  recode\n",
      "0      16.99  1.01  Female     No  Sun  Dinner   2.0     0.0\n",
      "1      10.34  1.66    Male     No  Sun  Dinner   3.0     1.0\n",
      "2      21.01   3.5    Male     No  Sun  Dinner   3.0     1.0\n",
      "3      23.68  3.31    Male     No  Sun  Dinner   2.0     1.0\n",
      "4      24.59  3.61  Female     No  Sun  Dinner   4.0     0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'For simple recodes, you can also use the replace method. You can also convert the column into a categorical type.'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tips = pd.read_csv('./datasets/tips2.csv')\n",
    "\n",
    "#print(tips.info())\n",
    "\n",
    "# Define recode_gender()\n",
    "def recode_gender(gender):\n",
    "\n",
    "    # Return 0 if gender is 'Female'\n",
    "    if gender == 'Female':\n",
    "        return 0\n",
    "    \n",
    "    # Return 1 if gender is 'Male'    \n",
    "    elif gender == 'Male':\n",
    "        return 1\n",
    "    \n",
    "    # Return np.nan    \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the sex column\n",
    "tips['recode'] = tips.sex.apply(recode_gender)\n",
    "\n",
    "# Print the first five rows of tips\n",
    "print(tips.head())\n",
    "\n",
    "'''For simple recodes, you can also use the replace method. You can also convert the column into a categorical type.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda functions\n",
    "You'll now be introduced to a powerful Python feature that will help you clean your data more effectively: lambda functions. Instead of using the def syntax that you used in the previous exercise, lambda functions let you make simple, one-line functions.\n",
    "\n",
    "For example, here's a function that squares a variable used in an .apply() method:\n",
    "```python\n",
    "def my_square(x):\n",
    "    return x ** 2\n",
    "\n",
    "df.apply(my_square)\n",
    "```\n",
    "The equivalent code using a lambda function is:\n",
    "```python\n",
    "df.apply(lambda x: x ** 2)\n",
    "```\n",
    "The lambda function takes one parameter - the variable x. The function itself just squares x and returns the result, which is whatever the one line of code evaluates to. In this way, lambda functions can make your code concise and Pythonic.\n",
    "\n",
    "The tips dataset has been pre-loaded into a DataFrame called tips. Your job is to clean its 'total_dollar' column by removing the dollar sign. You'll do this using two different methods: With the .replace() method, and with regular expressions. The regular expression module re has been pre-imported.\n",
    "\n",
    "* Use the .replace() method inside a lambda function to remove the dollar sign from the 'total_dollar' column of tips.\n",
    "    * You need to specify two arguments to the .replace() method: The string to be replaced ('$'), and the string to replace it by ('').\n",
    "    * Apply the lambda function over the 'total_dollar' column of tips.\n",
    "* Use a regular expression to remove the dollar sign from the 'total_dollar' column of tips.\n",
    "    * The pattern has been provided for you: It is the first argument of the re.findall() function.\n",
    "    * Complete the rest of the lambda function and apply it over the 'total_dollar' column of tips. Notice that because re.findall() returns a list, you have to slice it in order to access the actual value.\n",
    "* Hit 'Submit Answer' to verify that you have removed the dollar sign from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size total_dollar  \\\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2       $16.99   \n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3       $10.34   \n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3       $21.01   \n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2       $23.68   \n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4       $24.59   \n",
      "\n",
      "  total_dollar_replace total_dollar_re  \n",
      "0                16.99           16.99  \n",
      "1                10.34           10.34  \n",
      "2                21.01           21.01  \n",
      "3                23.68           23.68  \n",
      "4                24.59           24.59  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Notice how the 'total_dollar_re' and 'total_dollar_replace' columns are identical.\""
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tips = pd.read_csv('./datasets/tips.csv')\n",
    "\n",
    "#print(tips.info())\n",
    "\n",
    "# Write the lambda function using replace\n",
    "tips['total_dollar_replace'] = tips.total_dollar.apply(lambda x: x.replace('$', ''))\n",
    "\n",
    "# Write the lambda function using regular expressions\n",
    "tips['total_dollar_re'] = tips.total_dollar.apply(lambda x: re.findall('\\d+\\.\\d+', x)[0])\n",
    "\n",
    "# Print the head of tips\n",
    "print(tips.head())\n",
    "\n",
    "'''Notice how the 'total_dollar_re' and 'total_dollar_replace' columns are identical.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate and missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name     sex treatment a  treatment b\n",
      "0  Daniel    male           -           42\n",
      "1    John    male          12           31\n",
      "2    Jane  female          24           27\n",
      "3  Daniel    male           -           42 \n",
      "\n",
      "     name     sex treatment a  treatment b\n",
      "0  Daniel    male           -           42\n",
      "1    John    male          12           31\n",
      "2    Jane  female          24           27\n"
     ]
    }
   ],
   "source": [
    "# Duplicate data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv('./datasets/treatment3.csv')\n",
    "\n",
    "print(df,'\\n')\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304 entries, 0 to 303\n",
      "Data columns (total 7 columns):\n",
      "total_bill    294 non-null float64\n",
      "tip           300 non-null float64\n",
      "sex           304 non-null object\n",
      "smoker        302 non-null object\n",
      "day           303 non-null object\n",
      "time          300 non-null object\n",
      "size          300 non-null object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 10.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304 entries, 0 to 303\n",
      "Data columns (total 7 columns):\n",
      "total_bill    294 non-null float64\n",
      "tip           300 non-null float64\n",
      "sex           304 non-null object\n",
      "smoker        302 non-null object\n",
      "day           303 non-null object\n",
      "time          300 non-null object\n",
      "size          300 non-null object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 10.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Missing data\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tips_nan = pd.read_csv('./datasets/tips2.csv')\n",
    "\n",
    "tips_nan.info()\n",
    "\n",
    "# Drop missing values\n",
    "tips_dropped = tips_nan.dropna()\n",
    "\n",
    "tips_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304 entries, 0 to 303\n",
      "Data columns (total 7 columns):\n",
      "total_bill    304 non-null object\n",
      "tip           301 non-null object\n",
      "sex           304 non-null object\n",
      "smoker        302 non-null object\n",
      "day           303 non-null object\n",
      "time          300 non-null object\n",
      "size          304 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values \n",
    "tips_nan['sex'] = tips_nan['sex'].fillna('missing')\n",
    "\n",
    "tips_nan[['total_bill', 'size']] = tips_nan[['total_bill',\n",
    "                                             'size']].fillna(0)\n",
    "tips_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.214666666666667\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 304 entries, 0 to 303\n",
      "Data columns (total 7 columns):\n",
      "total_bill    294 non-null float64\n",
      "tip           304 non-null float64\n",
      "sex           304 non-null object\n",
      "smoker        302 non-null object\n",
      "day           303 non-null object\n",
      "time          300 non-null object\n",
      "size          300 non-null object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 10.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with a test statistic\n",
    "#tips_nan['tip'] = pd.to_numeric(tips_nan['tip'])\n",
    "mean_value = tips_nan['tip'].mean() #median better when outliers\n",
    "print(mean_value)\n",
    "\n",
    "tips_nan['tip'] = tips_nan['tip'].fillna(mean_value)\n",
    "\n",
    "tips_nan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicate data\n",
    "Duplicate data causes a variety of problems. From the point of view of performance, they use up unnecessary amounts of memory and cause unneeded calculations to be performed when processing data. In addition, they can also bias any analysis results.\n",
    "\n",
    "A dataset consisting of the performance of songs on the Billboard charts has been pre-loaded into a DataFrame called billboard. Check out its columns in the IPython Shell. Your job in this exercise is to subset this DataFrame and then drop all duplicate rows.\n",
    "\n",
    "* Create a new DataFrame called tracks that contains the following columns from billboard: 'year', 'artist', 'track', and 'time'.\n",
    "* Print the info of tracks. This has been done for you.\n",
    "* Drop duplicate rows from tracks using the .drop_duplicates() method. Save the result to tracks_no_duplicates.\n",
    "* Print the info of tracks_no_duplicates. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 951 entries, 0 to 950\n",
      "Data columns (total 4 columns):\n",
      "year      951 non-null int64\n",
      "artist    951 non-null object\n",
      "track     951 non-null object\n",
      "time      951 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 18.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 317 entries, 0 to 316\n",
      "Data columns (total 4 columns):\n",
      "year      317 non-null int64\n",
      "artist    317 non-null object\n",
      "track     317 non-null object\n",
      "time      317 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 8.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "billboard = pd.read_csv('./datasets/billboard.csv')\n",
    "\n",
    "#billboard.info()\n",
    "\n",
    "# Create the new DataFrame: tracks\n",
    "tracks = billboard[['year', 'artist', 'track', 'time']]\n",
    "\n",
    "# Print info of tracks\n",
    "print(tracks.info())\n",
    "\n",
    "# Drop the duplicates: tracks_no_duplicates\n",
    "tracks_no_duplicates = tracks.drop_duplicates()\n",
    "\n",
    "# Print info of tracks\n",
    "print(tracks_no_duplicates.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing data\n",
    "Here, you'll return to the airquality dataset from Chapter 2. It has been pre-loaded into the DataFrame airquality, and it has missing values for you to practice filling in. Explore airquality in the IPython Shell to checkout which columns have missing values.\n",
    "\n",
    "It's rare to have a (real-world) dataset without any missing values, and it's important to deal with them because certain calculations cannot handle missing values while some calculations will, by default, skip over any missing values.\n",
    "\n",
    "Also, understanding how much missing data you have, and thinking about where it comes from is crucial to making unbiased interpretations of data.\n",
    "\n",
    "* Calculate the mean of the Ozone column of airquality using the .mean() method on airquality.Ozone.\n",
    "* Use the .fillna() method to replace all the missing values in the Ozone column of airquality with the mean, oz_mean.\n",
    "* Hit 'Submit Answer' to see the result of filling in the missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      116 non-null float64\n",
      "Solar.R    146 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n",
      "None\n",
      "\n",
      " Ozone       42.129310\n",
      "Solar.R    185.931507\n",
      "dtype: float64 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      153 non-null float64\n",
      "Solar.R    153 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "airquality = pd.read_csv('./datasets/airquality3.csv')\n",
    "\n",
    "print(airquality.info())\n",
    "\n",
    "# Calculate the mean of the Ozone column: oz_mean\n",
    "#oz_mean = airquality['Ozone'].mean()\n",
    "oz_mean = airquality[['Ozone','Solar.R']].mean()\n",
    "print('\\n',oz_mean,'\\n')\n",
    "\n",
    "# Replace all the missing values in the Ozone column with the mean\n",
    "#airquality['Ozone'] = airquality['Ozone'].fillna(oz_mean)\n",
    "airquality[['Ozone','Solar.R']] = airquality[['Ozone','Solar.R']].fillna(oz_mean)\n",
    "\n",
    "# Print the info of airquality\n",
    "print(airquality.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with asserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assert statements\n",
    "* Programmatically vs visually checking\n",
    "* If drop or fill NaNs, expect 0 missing values\n",
    "* Write assert statemnt to verify\n",
    "* Detect early warnings and errors\n",
    "* Gives confidence that code is running correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a58c3ac11155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Asserts\n",
    "assert 1 == 1 # gives no output\n",
    "\n",
    "assert 1 == 2 # gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63 entries, 0 to 62\n",
      "Data columns (total 6 columns):\n",
      "date      63 non-null object\n",
      "close     60 non-null object\n",
      "volume    62 non-null object\n",
      "open      63 non-null object\n",
      "high      62 non-null object\n",
      "low       62 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.5+ KB\n",
      "None\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d169a7cf6bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Google stock data 201702\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "google = pd.read_csv('./datasets/GoogleHistoricalQuotes2.csv')\n",
    "\n",
    "print(google.info())\n",
    "\n",
    "assert google.close.notnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test column\n",
    "#google_0 = google.fillna(value = 0)\n",
    "google_0 = google.close.fillna(value = 0)\n",
    "\n",
    "assert google_0.notnull().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing your data with asserts\n",
    "Here, you'll practice writing assert statements using the Ebola dataset from previous chapters to programmatically check for missing values and to confirm that all values are positive. The dataset has been pre-loaded into a DataFrame called ebola.\n",
    "\n",
    "In the video, you saw Dan use the .all() method together with the .notnull() DataFrame method to check for missing values in a column. The .all() method returns True if all values are True. When used on a DataFrame, it returns a Series of Booleans - one for each column in the DataFrame. So if you are using it on a DataFrame, like in this exercise, you need to chain another .all() method so that you return only one True or False value. When using these within an assert statement, nothing will be returned if the assert statement is true: This is how you can confirm that the data you are checking are valid.\n",
    "\n",
    "Note: You can use pd.notnull(df) as an alternative to df.notnull().\n",
    "\n",
    "* Write an assert statement to confirm that there are no missing values in ebola.\n",
    "    * Use the pd.notnull() function on ebola (or the .notnull() method of ebola) and chain two .all() methods (that is, .all().all()). The first .all() method will return a True or False for each column, while the second .all() method will return a single True or False.\n",
    "* Write an assert statement to confirm that all values in ebola are greater than or equal to 0.\n",
    "    * Chain two all() methods to the Boolean condition (ebola >= 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If the assert statements did not throw any errors, you can be sure that there are no missing values in the data and that all values are >= 0!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "ebola = pd.read_csv('./datasets/ebola2.csv')\n",
    "\n",
    "# Assert that there are no missing values\n",
    "assert ebola.notnull().all().all()\n",
    "\n",
    "# Assert that all values are >= 0\n",
    "assert (ebola >= 0).all().all()\n",
    "\n",
    "'''If the assert statements did not throw any errors, you can be sure that there are no missing values in the data and that all values are >= 0!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "##### Useful methods\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('file.csv')\n",
    "df.head()\n",
    "df.info()\n",
    "df.columns\n",
    "df.describe()\n",
    "df.column.value_counts()\n",
    "df.column.plot('hist')\n",
    "```\n",
    "##### Data quality\n",
    "```python\n",
    "def cleaning_function(row_data):\n",
    "    data cleaning steps\n",
    "    return ...\n",
    "\n",
    "df.apply(cleaning_function, axis = 1) # by row, default is column\n",
    "\n",
    "assert (df.column_data > 0).all()\n",
    "```\n",
    "##### Combining data\n",
    "```python\n",
    "pd.merge(df1,df2,...)\n",
    "pd.concat([df1,df2,df3,...])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis\n",
    "Whenever you obtain a new dataset, your first task should always be to do some exploratory analysis to get a better understanding of the data and diagnose it for any potential issues.\n",
    "\n",
    "The Gapminder data for the 19th century has been loaded into a DataFrame called g1800s. In the IPython Shell, use pandas methods such as .head(), .info(), and .describe(), and DataFrame attributes like .columns and .shape to explore it.\n",
    "\n",
    "Use the information that you acquire from your exploratory analysis to choose the true statement from the options provided below.\n",
    "\n",
    "* The DataFrame has 259 rows and 100 columns.\n",
    "* The DataFrame has no missing values encoded as NaN.\n",
    "* 100 of the columns are of type float64 and 1 column is of type object.\n",
    "* The DataFrame takes up 203.2+ KB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 461 entries, 0 to 460\n",
      "Columns: 101 entries, Life expectancy to 1899\n",
      "dtypes: float64(100), object(1)\n",
      "memory usage: 362.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "g1800s = pd.read_csv('./datasets/g1800s.csv')\n",
    "#g1800s = pd.read_csv('./datasets/gapminder.csv')\n",
    "\n",
    "g1800s.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing your data\n",
    "Since 1800, life expectancy around the globe has been steadily going up. You would expect the Gapminder data to confirm this.\n",
    "\n",
    "The DataFrame g1800s has been pre-loaded. Your job in this exercise is to create a scatter plot with life expectancy in '1800' on the x-axis and life expectancy in '1899' on the y-axis.\n",
    "\n",
    "Here, the goal is to visually check the data for insights as well as errors. When looking at the plot, pay attention to whether the scatter plot takes the form of a diagonal line, and which points fall below or above the diagonal line. This will inform how life expectancy in 1899 changed (or did not change) compared to 1800 for different countries. If points fall on a diagonal line, it means that life expectancy remained the same!\n",
    "\n",
    "* Import matplotlib.pyplot as plt.\n",
    "* Use the .plot() method on g1800s with kind='scatter' to create a scatter plot with '1800' on the x-axis and '1899' on the y-axis.\n",
    "* Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmclXX5//HXe4ZhQEBBxBVRXAlNUMct0Awz09Q00Sy3rEQzUb8qkJZft6xQc+n3LRW31FBTDHFfEUtzG3BYBBdcAQ2VABnUgZm5fn/c9xkOw1nuM3P2cz0fj/PgnPvcy3Vu4P7c92e5PjIznHPOOYCqQgfgnHOueHih4Jxzro0XCs4559p4oeCcc66NFwrOOefaeKHgnHOuTU4LBUnvS5otqUFSfbjsYkmLwmUNkg7JZQzOOeei65KHY3zLzD5rt+waM7sqD8d2zjmXAa8+cs451ybXTwoGPCnJgBvNbEK4/AxJJwL1wLlmtrT9hpJGAaMAevTosfugQYNyHKpzzpWX6dOnf2Zm/TLZRrlMcyFpczP7SNLGwFPAaOBN4DOCAuMyYDMz+2mq/dTV1Vl9fX3O4nTOuXIkabqZ1WWyTU6rj8zso/DPT4DJwJ5mttjMWsysFbgJ2DOXMTjnnIsuZ4WCpB6SesXeA98B5kjaLG61I4E5uYrBOedcZnLZprAJMFlS7Dh3mdnjku6UNJSg+uh94NQcxuCccy4DOSsUzOxdYEiC5Sfk6pjOOec6x7ukOueca+OFgnPOuTZeKDjnnGvjhYJzzrk2Xig455xr44WCc865Nl4oOOeca+OFgnPOuTZeKDjnnGvjhYJzzrk2Xig455xr44WCc865Nl4oOJclSxqbmLlgGUsamwodinMdluvpOJ2rCFMaFjHu/lnUVFWxurWVK47ahcOHblHosJzLmD8pONdJSxqbGHf/LL5a3cqKpma+Wt3K2Ptn+RODK0leKDjXSQuXfklN1dr/lWqqqli49MsCReRcx3mh4Fwn9e/TndWtrWstW93aSv8+3QsUkXMdl7RQkNRT0qWSXpe0XNKnkl6S9JM8xufKTDk2xvbtWcsVR+1Ct5oqetV2oVtNFVcctQt9e9YWOjTnMpaqoXkiMBk4CDgG6AHcA/xG0g5mdkEe4nNlpJwaY5c0NrFw6Zf079Odvj1rOXzoFgzbbqO1ljlXimRmib+QZprZkLjPr5rZHpKqgLlmNihfQdbV1Vl9fX2+DudyYEljE8PGT+Wr1WuqWbrVVPHCuBEldwEtp8LNlTdJ082sLpNtUrUprJQ0PNzxYcB/AcysFVCHo3QVqVwaY72nkSt3qaqPTgNulrQjMBv4GYCkfsCf8xCbKyPl0hgbK9y+Ys1viRVupfbE41wiSZ8UzGyWme1pZhuY2XAzezNc/qmZ/SnKziW9L2m2pAZJ9eGyDSU9Jent8M8+2fkprpiVS2NsuRRuziWTckSzpG2BI4EtgWbgbeBuM1uewTG+ZWafxX3+FfCMmf1B0q/Cz+MyC9uVonJojI0VbmPbtSmU4m9xLpGkhYKkM4HDgOeAPYAGgsLhRUmnm9m0Dh7z+8D+4fvbgWl4oVAx+vasLfkLaDkUbom071HlKlOq3kezgaFm1iJpPeBRM9tf0gBgipntmnbn0nvAUsCAG81sgqRlZtY7bp2lZrZOFZKkUcAogAEDBuz+wQcfdOT3Oeci8B5V5SnbvY9gzZNELdALwMw+BGoi7n+Yme0GHAz8UtJ+UQMzswlmVmdmdf369Yu6masQ5TgILl4+f5/3qHLxUrUp3Ay8KuklYD9gPLT1PvpvlJ2b2Ufhn59ImgzsCSyWtJmZfSxpM+CTzvwAV3mK+a42G1Uw+f593qPKxUvV++g64EfAk8ARZnZbuPxTM0t7xy+ph6ResffAd4A5wIPASeFqJwFTOvULXEUp5rvaKQ2LGDZ+Ksff/DLDxk/lwYZFGe+jEL/Pe1S5eOmqj1YAT5vZG5K2ljRS0s4R970J8LykmcArwCNm9jjwB+BASW8DB4afnYukWAfBJbqYj5k0i3++9WlGF/RC/L5y6S7ssiNV76NfAacCTZKuAs4DXgAukXSLmV2dasdm9i4wJMHyJcABnYraVaxivatNVAXT1NzKaXdOpxWLXAVUqN9Xrj2qXOZSPSmcAAwGhgHXAPua2c8I2gV+mofYnFtHsd7VJrqYA3yxuiVSFVCsYRko2O/r27OWIVv2Lvi5dIWVqqG5xcy+lLQK+BJYAmBmKyVPfeQKpxjvauMHtVVJfLGqZa3vUzXcJmpYfmHciKL6fa5ypBqn8FegK0HK7C8IRjQ/DowAepnZMXmK0bOkupKxpLGJ1z9azil31NPUvOb/VrKMsOWUPdYVn2yPU/g58BBwN0FV0vXAPsCbwMkdDdK5cta3Zy377bAxV44cEqkKqFgbzl3lSlp9ZGbNBAVCzL/Dl3MujXRVXLHxDD26Vhdlw7mrXCkT4iUj6TEzOzjbwThXTpLleWrfhnBMXX/urV/oCfZcUUjVJXW3ZF8BQ3MTjnPlLX48Q6z76r31C3n4jOGsXNXiDcuu4FI9KbxKkCE1UVej3gmWOefSSJZSYuWqFoZs6f+tXOGlKhTmAaea2dvtv5C0IHchOVe+inXwnXMxqXofXZzi+9HZD8W58lesg++ci0nV+2hSiu8eyE04zkWT7wlhsnm8Yhx851xMh3ofOVdI+U4tnYvjlcMMdK48pcuS6lxRyXdq6WJO1e1cLnih4EpKvkcAF3LEcbnPLueKU6TqI0nfALaOX9/M7shRTM4lle/eO4XqLVTMs8u58pb2SUHSncBVwHBgj/CVUYIl57Il3713snW8TO76vcrKFVKUJ4U6YLAlS6fqXJ7lu/dOZ4+X6V2/z5nsCilKoTAH2BT4OMexOBe562e+e+909HiJ0lqMvX8Ww7bbKOn+fICbK6QohcJGwFxJrwBtz69mdnjOonIVqRzr0Tty1x8/YY8nyXP5FqVQuDjXQTjXkTvqUtDRu34f4OYKJW2hYGbP5SMQV9nKtR69M3f9PsDNFUKq1NnPm9lwSSuA+EZmAWZm6+c8OlcxMr2jzneai87wu35XSlLlPhoe/tmrMweQVA3UA4vM7NBw7udvAsvDVX5iZg2dOYYrfZncUZdi24Pf9btSkY/cR2cRpOGOf7IYkyrhnqtMUe6oy7XtwblikdM0F5L6A98Dbs7lcVz56NuzliFb9k56gfeJ7p3LrVznProWGAu0tlt+uaRZkq6RlPB/v6RRkuol1X/66ac5DtOVikL24fdcRK4SRElzcYakPpnuWNKhwCdmNr3dV+cDgwjSZWwIjEu0vZlNMLM6M6vr169fpod3ZSpfaS7aFwBTGhYxbPxUjr/5ZYaNn8qDDYuyejznikWUNoVNgVclzQBuBZ6ImPJiGHC4pEOAbsD6kv5mZseH3zdJug04ryOBu8qV69487RuyL/zeYC57ZK63Y7iKkPZJwcx+A2wP3AL8BHhb0u8kbZtmu/PNrL+ZbQ0cC0w1s+MlbQYgScARBGk0nMtIuraHjkqUjO6Sh16nS5XWWs/bMVy5itSmED4Z/Cd8NQN9gEmSrujAMSdKmg3MJkih8dsO7MO5nEjYkF1dxaqWtR+OPReRK1dpq48knQmcBHxG0ItojJmtllQFvE3QkJySmU0DpoXvR3QiXudyKlFDdosZFx02mMsenuu5iFzZi9Km0Bf4gZl9EL/QzFrDxmRXZkpptHC2JRtEd/jQLfjuTptmfF4q+Vy60qRUbcbh08BcMxuUv5DWVVdXZ/X19YUMoWKU4mjhXMjGxdzPpSs0SdPNLKNJ0VK2KZhZK/CmpAGdisyVBJ/xa43ONmT7uXSlKkr1UR/g9XA+hZWxhT6fQvkp10ylUWS7mqeSz6UrbVEKhQtzHoUrCpU641cuqnkq9Vy60helS+ohZvZc/As4JNeBufzL12jhYpKrap5KPJeuPER5UjiQdVNRHJxgmSsDlZb7P5fVPJV2Ll15SDXJzi+A04FtJM2K+6oX8O9cB+YKp5Jy/+e6mqeSzqUrD6mqj+4CDgMeDP+MvXY3s+PyEJtzOefVPM6tLdXMa8sJZkf7UTh72ibh+j0l9TSzD/MUo3M55dU8zq0RJc3FGcDFwGLWzItgwC65C8u5/PJqHucCURqazwZ2NLMluQ7GOedcYUXpkrqAoBrJOedcmYvypPAuME3SI0Bb520zuzpnUbmc8ORszrl0ohQKH4avruHLlSBPzuaciyJtoWBml+QjEJc78aN2Y4O0zps0i8Gbrc92m/QqcHTOuWKStk1B0rOSprZ/5SM4lx2JZhNb1dzKIX/6V9lMQL+ksYmZC5YVZRbSYo7NufaiVB+dF/e+G3AUwZScrkQkGrULsKrFymIC+mKuGivm2JxLJO2TgplNj3u9YGbnAPvnPjSXLbFRu127rPvXXeoT0BfzvAXFHJtzyUSpPtow7rWRpIOADfIQm8uiw4duwaOjh9O1WmstL/V0zomqxoqloCvm2JxLJkr10XSCEcwiqDZ6D/hZLoNyubHdJr246ugh68w/XMpVR8U8b0Exx+ZcMlF6Hw3MRyAuP8otz0+saqwYC7pijs25ZGRmqVeQaoBfAPuFi6YBN5rZ6kgHCJLp1QOLzOxQSQOBe4ANgRnACWa2KtU+6urqrL6+PsrhXIXqyMC8JY1NvP7R54Cx0+Yb5Oxi7YMGXaFImm5mdZlsE6X66HqgBvhL+PmEcNnPIx7jLGAesH74eTxwjZndI+kGgqqo6yNH7FwCmSa0m9KwiHPvbaA5rN2pqRZ/PHpITnoGebI9V0qi5D7aw8xOMrOp4etkYI8oO5fUH/gecHP4WcAIYFK4yu3AEZmH7VzHLWlsYuykmW0FAsDqFmPMpLV7Bvn4AleJojwptEja1szeAZC0DdAScf/XAmMJZmsD6AssM7PYOIeFgHfadnm1cOmXVKuK9v+Mq6vUNg2njy9wlSrKk8IY4FlJ0yQ9B0wFzk23kaRDgU/MbHr84gSrJmzUkDRKUr2k+k8//TRCmM6tLdmdfv8+3WmxdQfztbQa/ft09/EFrqJF6X30jKTtgR0JLupvmFmU/x3DgMMlHUIwEnp9gieH3pK6hE8L/YGPkhx3AjABgobmKD/GuZhUd/p9e9Zy5cghnNOuTeHKkUHPoJkLllFTVdWWJwrWjC/wtgFX7pIWCpKOJ+iddGdYCMwKl58gqcXM7kq1YzM7Hzg/3GZ/4DwzO07SfcBIgh5IJwFTsvJLnAslSgDYPp1HrGtuot5HPr7AVbJU1UejgckJlv+DCNVHKYwDzpE0n6CN4ZZO7Mu5dUQdSdy3Zy377dCP/XbYeK0ngNj4gm41VfSq7UK3miofX+AqRqrqoxoza2y/0MxWhmMXIjOzaQTjGzCzd4E9M9neVYZs9efPxp1+uQ3ycy6qVIVCd0k9zGxl/EJJvfDJdlyWZbO3T7ZGEvv4AleJUhUKtwCTJP3CzN4HkLQ18Ge8ysdlUZQ2gEx15k7fRyC7Spa0UDCzqyQ1As9J6knQdXQl8Acz8xHILmtibQDZ7u3TkTt9H5/gKl3KLqlmdgNwQ1goyMxW5CcsV0mKpbdPLp5YnCs1UQavYWaNXiC4XCmW3j4+/4Fz0dJcOJdzxdDbp1ieWJwrpEhPCs7lQ9+etQzZsnfGjcLZSloXe2Kp7SLWq6mmtot8fIKrOGmfFCTVA7cBd5nZ0tyH5Fw0uWgUDvKpKEjoYolSdTlX3qI8KRwLbA68KukeSQeFKbCdSygfKadzkbQuts+m5la+WNVCU7MnwnOVJ0pCvPnAryVdCBwK3Aq0SroVuM7M/pvjGF0JyVeXzmx2Y42NS1j+5SpPhOcqXqSGZkm7ACcDhwD3AxOB4QRptIfmLDpXUvLZpTNbjcLxhdiqlhZa2+Xj9YZmV2nSVh9Jmg5cA7wK7GJmZ5rZy2b2R+DdXAfoSkc+u3Rmoxtr+yqopmbDzKjt4onwXOWK8qRwdJjEbh1m9oMsx+NKWL67dHa2G2uiKqjuNV3483G7sUH3Gk9z4SpSlIbm5ZL+JGmGpOmSrpPUN+eRuZJTiEFoHenGGpOsENtp8/UZsmVvlq5cxaT6Bcxf7OM2XeWI8qRwD/BP4Kjw83HA34Fv5yooV7qKYRBaVKmyqf7vA7O546UP29Y9cZ8BXPr9rxcwWufyQ2apZ7qUNMfMdm63bLaZ5e1/SF1dndXX1+frcK7CxHof9ehazcpVLaxubmHkjS+ts97T/7Mf223SqwAROtcxkqabWV0m20R5UnhS0rHAveHnkcATmQbnXCbSpa/OZnrrvj1ruX/6Qq544g26VlexqqU14XoNC5Z5oeDKXqo5mlcQDPAUcDZwZ/hVNdAInJfz6FxFSjfWYeJLH3DJQ69TU11Fi1mnx0KMnTSTe+sXAtDcmrhAABi6Ze8OH8O5UpFqPgW/JXJ5l26sw8SXPuDXD8wBYFVLyzrfRzV/8QoaFiyjz3o1bQVCvCogvng4cZ8B/pTgKoJnSXVFJdVIZYBLHp67zjbVUkajjuOfDJKpqoJ7T9mb95d8wdAte3uB4CqGFwquqKQa67Bw6Zd0rRarmtfeZnVLtLEQ8xev4NKH5/LPtz9Lu+7YgwZRN7AvdQO997WrLF4ouKKSqpsoQHP7PBTARYftlPIpYUljE795YA6PzflPpBiOqevPqG9u27Ef4FyJi5I6+yrgNjN7PZMdS+pGML6hNjzOJDO7SNJfgW8Cy8NVf2JmDRlF7cpasrEO8QVGdZVY3WJcdNhgjttrq6T7mvjSB1z04Byak7cfA3DLibuz9IvVXlXkKl6UJ4U3gAmSuhDMq3C3mS1Psw1AEzDCzBol1QDPS3os/G6MmU3qWMiuEvTtWZvw7j/q4LgljU1c+fgb3JOm7QCCJ4MDBm/a6ZidKwdRUmffDNwsaUeCTKmzJL0A3GRmz6bYzgi6rgLUhK/UI+WciyBZgREz4bl3+N1jb0Ta1ynDB/LrQwdnKzTnSl6k6TglVQODwtdnwEzgHEn3pNtOUgPwCfCUmb0cfnW5pFmSrpFUvHkQXMkZO2lm5ALhmLr+XiA4106UNoWrgcOBZ4Dfmdkr4VfjJb2ZalszawGGSuoNTJa0M3A+8B+gKzABGAdcmuC4o4BRAAMGDIj8g1zHZXOUcL7NX7yCJ17/T9qupgcO6sfQAX04aKdNve3AuQSitCnMAX5jZl8k+G7PKAcxs2WSpgHfNbOrwsVNkm4jychoM5tAUGhQV1fn1U45lm4UcTEXGO2T1yVz1gHb8T8H7piHiJwrXVGqj5YStAcAIKm3pCMAUjU4S+oXPiEgqTtBVtU3JG0WLhNwBEGh4woo3XzHUxoWMWz8VI6/+WWGjZ/Kgw2LChzxGvMXr4hUIBxT198LBOciiPKkcJGZTY59CO/6LwIeSLPdZsDtYXtEFXCvmT0saaqkfgQ5lRqA0zoYu+ukKHMTA52eYjPbTxnx+2tYsCzluntu1Zvf/WAXrypyLqIohUKip4kovZZmAbsmWD4iwjFdjkWdmzhV2okoF/h01VKZmvjSB1zy8Fy6VovmVuOcA3dIuN6Y7+zg7QbOdUCUQqE+bGz+M0GX0tHA9JxG5XIqUdK5LlVQ26WKrtXrjiLu6BSb6ZLbZRrzn555m9tf/ACgLdXF1U+9xTF1/ddqYD5xnwH8csT2Ge3fOReIUiiMBi4kmG1NwJPAL3MZlMutTOYmTpd2ItPjZPKUETPhuXf4/WNvJBzkUl0ljttrK0btuw0NC5b5iGTnOilKNdBK4Fd5iMXlSaq5iTszijjqcaI8ZcScefcMHpz5cdLvV7dYW0xeGDjXeVHGKexA0G106/j1vW2gdHXk7j/dKOJsHQeCHkXPz/+M1xYsTVkgAFx02OCi6yLrXCmLMkfzTOAGgnaElthyM8tbu4LP0Zwb+Rp7kMlxTr3zVZ54/ZNI+73g4EGezdS5FHI1R3OzmV3fwZhcEevI3X+ujjN/8QqOnfAin61cnXZ/1VXi0u/vlDI7qnOuY6IUCg9JOh2YTJD5FAAz+2/OonIV5ay7ZzAlTTVRzL7b9+XaH+7qVUbO5UiUQuGk8M8xccsM2Cb74bhKc9xNL/LCO+nvL7pUibEH7ejVRc7lWJTeRwPzEYirLPMXr+Ant73MwmVNadc998Ad+PFeA/zpwLk8iDQdZ5jddDDQLbbMzO7IVVCueGWjcfrMu6bz4Kz0U2NuvkEtD43e1wsD5/IoSpfUi4D9CQqFR4GDgecBLxQqTGdTVlzzxDyuf+5dVqWZGhNgyz61/GvctzsRrXOuI6I8KYwEhgCvmdnJkjYB/pbbsFyx6UzKiiWNTezx26eJUBawcc8afv+DXXx6TOcKJEqh8KWZtUpqlrQ+wSxqW+Y4LldkOpqyYuJLH/CbB+ZEmod1ly3W58HR+2YhWudcR0VNiNcbuIlgAFsj8GJOo3IFkaq9INOUFfMXr+Dap9/i4dnp2w7AJ8BxrlhE6X10evj2BkmPA+uHabFdGUnXXpBJyoqx9zVw7/RoE/HstGlP7vj53t6Y7FyRiNLQ/IyZHQBgZu+3X+ZK25LGJl7/6HPGTppFU3Pq9oJ0ifHmL17BHx6fx9PzPo107K37dueRs7+ZvR/jnOu0pIWCpG7AesBGkvoQpM0GWB/YPA+xuRyLPR1UIZqa164aStZekChlxfzFKzj7nteY8/GKSMfdfP2uXHbE170x2bkilOpJ4VTgbIICYDprCoXPCSbccSUsvjdRIlFTXGeSouIn39iK0SO296oi54pY0kLBzK4DrpM02sz+Xx5jcnmQqDcRwHpdq2k1S5viekljEyff+iqzPloe6XiXH7Ezx+3tCeycK3ZReh+1SuptZssAwqqkH5nZX3IbmsulRL2JulbD2IN2YPh2/VJOWHPjc+/whyQzobV37B5bMOagr/nTgXMloirCOqfECgQAM1sKnJK7kFw+xHoTdaupoldtF7pUgSH++OTbHPp/z/Ngw7q9h+YvXsGhf/pn0qkx41UJLj9yZ/5w1FAvEJwrIVGeFKokycLZeCRVA11zG5bLh1hvotc/+pxT7qinqbmV1S3NwLq9j06+9WWefeuzSPsdtEkPJp6yjxcGzpWgKIXCE8C9km4gSJl9GvB4TqNyedO3Zy0bdK+ha3XVWj2Q4nsf7Tv+GRYs/Srtvvr3ruXaH+5K3cC+uQzZOZdDUQqFcQQ9kX5B0APpSeDmdBuFXVr/CdSGx5lkZhdJGgjcA2wIzABOMLNVHQvfZUOy0cqrm1sYef3zkQqE3QZswD9OH56rEJ1zeZJ2jmYASd2BAWb2ZuQdSwJ6mFmjpBqCzKpnAecA/zCze8Knj5nppvv0OZpz78GGRWuNVh66xQa89P7StNtt0289rvjBLv504FwRyskczZIOB64kaEcYKGkocKmZHZ5qu7ANojH8WBO+DBgB/DhcfjtwMeBzQBdY/Gjl++oX8LeXP0y/zZDN+NOPdstDdM65fIlSfXQRsCcwDcDMGiRtHWXnYaP0dGA7ggFv7wDLzKw5XGUhkDAhv6RRwCiAAQMGRDmc64RYMrxbnn+XB9MMRuuzXjX3nTosZbdV51xpilIoNJvZ8qA2KDNm1gIMDbOsTga+lmi1JNtOACZAUH2U8cFdZLF0F9USK1e1pFz36N0358qjd81TZM65fItSKMyR9GOgWtL2wJnAvzM5iJktkzQN2BvoLalL+LTQH/gow5hdFtW/t4Tz7pvJ6pb05e4xdVtwxciheYjKOVcoUQavjQZ2ApqAuwlyH52dbiNJ/cInhFhD9beBecCzBLO5AZwETMk87MqzpLGJmQuWsaQx/UT3UcxfvIIfT3iRkTe+lLZA+Ob2G/H0/+znBYJzFSDKfApfAL+WND74aNFSYcJmwO1hu0IVcK+ZPSxpLnCPpN8CrwG3dDD2itHZuZHjPTBjAVc9+SYLl0UrXI6p688VI4d06FjOudITpffRHsCtQK/w83Lgp2Y2PdV24UQ861Q+m9m7BA3XLoLOzI3c3p6XP8knK1anXKemWoz5zo5s2KMrQ7fs7Y3JzlWYKG0KtwCnm9m/ACQNB24DdsllYC7Q0bmR2/vN5NlpCwSAu3++l485cK6CRSkUWmIFAoCZPS+pOdUGrmMSzZGc6dzIifbXo2s1d0UYd3DiPgO8QHCuwkUpFJ6TdCNBI7MBPwSmSdoNwMxm5DC+ipGs3SCTuZHjTXzpAy556HVqqqtY3WpUAYmn04FvbLMhl35/Z68qcs6lT3Mh6dkUX5uZjchuSOsq9zQXSxqbGDZ+6lqzoHWrqeKFcSPaLv6JniKS7ev/PfM2f33xg7TH7VVbxeTTh3th4FyZykmaCzP7VsdDclFEaTdINDdye1MaFnHO3xtI1MO0toswCzIarm4xjttrAJcd+fVs/gznXBmI0vvoTuAMM1seft4KuNXMDsh1cJWiM+0GEDwdvP7Rcsbcl7hAADCDR8/cl5WrWtI+bTjnKleUNoXngZclnUOQp2gMcG5Oo6owHW03gDVtB9VVIlWGiosO28mriZxzaUWpPrpR0usEI5E/A3Y1s//kPLIKE5+lNOqd/MSXPuDXD8wJPqQYlXzBwYM4bu+tshWqc66MRak+OgG4EDiRYGzCo5JONrOZuQ6u0kRpN4hZ0tjEJQ/PTblOtWDcwYMYtd+2bdtkUug45ypPlOqjo4DhZvYJcLekyQTzIHginDyLv6gvXPolXavFqnYjRmqqxY/3HMBdr3xA1+pqrn7qLTZdvxsGWUuV4ZwrX1Gqj45o9/kVSZ6mIs/aj2O48HuDaW5dt8pozEE7cvVTb7G6BVa3BI0MYybNBERTc+dTZTjnylvSLKmS7o17P77d1w/nLCK3lvmLV/DXF95lzH0NfLW6lRVNzXy1upXLHpnLhYcOpltNFT1qq+napYrLj9yZvQb2paZq7b/WalVRXbX2fBixLq/OORcv1ZPC9nHvDwTGxX3ul5twXMySxiZ+88AcHpuTuE2/pqqKnTffgBfGjVirnWBJY9M63VtbrBVs7UIhky6vzrnKkapQSDXU2WdCy6GJL33ARVPm0JziLMcu6u0bp5N1bwU61OXVOVdZUhUK60lflXaZAAAQlUlEQVTalaCKqXv4XuHLbzHjZLNXz1rdTBOora5CVaS8qCfr3pppl1fnXOVJVSh8DFwdvv9P3PvY54oWKwjmLFrOZY/M7XSvnmBU8udc8lDqbqZ/PGYI+2zbN+1FPVH31ky6vDrnKlPSQsFzHiWXaKL7zvTqufzhudzy/HtUC1anqDI6cZ8BHDpk807FXgg+PsK50hFlnIKLEz8TWiKZTIAzf/EKfjThRT5dGUx+k6CHKQBH7bo5v9h/u5JMU5HNqUSdc7nnhUKGEmU0jRe1V89Zd89gysyPk37fvaaKFoOLDhvMcXuVZoqKbE4l6pzLDy8UMpQooylAj9pqWlotba+e+YtXcPbfX2PORyuSriPgxhN2Z6fNNyjpi2e2phJ1zuVPlNxHAo4DtjGzSyUNADY1s1dyHl0RStTl88LvDWbnLTZIWWe+pLGJsZNm8swbn6Y9xs+HD2S/HTbOduh519mU4M65/IvypPAXgpkcRwCXAiuA+4E9chhXUcs0o+mE597h94+9EWlwx3b91uPXhw7OTqAF1pmU4M65wohSKOxlZrtJeg3AzJZK6ppuI0lbAncAmxIUKhPM7DpJFwOnALFb5gvM7NEORV9AUbp3ZvJ0MKBPNy46bCcOGLxp0n2VYg+ejqQEd84VTpRCYbWkasJRzJL6kXwO+HjNwLlmNkNSL2C6pKfC764xs6s6FHGJmNKwiDH3NaSc+CbmoJ025sYTkj94lXoPHh8f4VzpSJoQL86fgMnAxpIuJ5iJ7XfpNjKzj81sRvh+BTCPYOa2shfrdROlQLjg4EEpC4T4HjyxZHhj75/FksamLEbsnHOBpE8Kkgaa2XtmNlHSdOAAgo4xR5jZvEwOImlrYFfgZWAYcIakE4F6gqeJpQm2GQWMAhgwYEAmh8uLVNU56bqtVglO3GcrRo/YPu0dtPfgcc7lU6rqo0nA7pKeMbMDgDc6cgBJPQkaps82s88lXQ9cRlAddRnwR+Cn7bczswnABIC6urqiSsCXaG6D+N5HybqtAnz7axszPoPGVu/B45zLp1SFQpWkC4AdJJ3T/kszuzrBNmuRVENQIEw0s3+E2y2O+/4mSmxuhkQDsn79wBx61lbTHI5TOHzoFmv1umlqbubo3Qdw8rCtMx6V7D14nHP5lKpQOBY4Ilwn4/wK4fiGW4B58QWIpM3MLDaU90ggeUrQIpSsaqixKWhAiI3YzWavG+/B45zLl1QJ8d4ExkuaZWaPdWDfw4ATgNmSGsJlFwA/kjSUoProfeDUDuy7YFJVDcHa9f3Z7HXjPXicc/mQqqH5eDP7GzBY0tfaf5+u+sjMnidomG6v5MYkxIuvzonPkhrj9f3OuVKWqvqoR/hnzwTfFVXDb77FV+fM+Wg5lz081+v7nXNlIVX10Y3hn5e0/07S2bkMqpgk63oaq84ZsmVvvrvTppHr+0t1ZLJzrjJ0NEvqOcC12QykGEUdSRy1vr/URyY758pflBHNiSRqKygr2R5J7COTnXOloKOFQtm3KcS6nsaL9Swqhv0551wupOp9tILEF38BZd+9JtsjiX1ksnOuFCR9UjCzXma2foJXLzMr+xnbYl1Pu9VU0au2C91qqjrVsyjR/i783mAWLv3Sq5Ccc0VDZsVfE1RXV2f19fUFOXa2ewvF9jdn0XIue2SuNzo753JG0nQzq8tkm7K/4++sbI8kju3rhxNe9AntnXNFp6MNza4TvNHZOVesvFAogB5dq2lq8UZn51zx8eqjPIsNYFPYltOtJiiXPT2Gc64YeKGQR/ED2GJaW41Hz9w343kWnHMuF7z6KI8StSXUdqleJ9Oqc84VihcKeeQD2Jxzxc4LhTzK9oA455zLNm9TyDOfWtM5V8y8UCgAn1rTOVesvPrIOedcGy8UnHPOtfFCwTnnXBsvFJxzzrXJWaEgaUtJz0qaJ+l1SWeFyzeU9JSkt8M/++QqBuecc5nJ5ZNCM3CumX0N2Bv4paTBwK+AZ8xse+CZ8LNzzrkikLNCwcw+NrMZ4fsVwDxgC+D7wO3harcDR+QqBuecc5nJyzgFSVsDuwIvA5uY2ccQFBySNk6yzShgVPixSdKcPISaKxsBnxU6iE4o5fhLOXbw+Aut1OPfMdMNcj4dp6SewHPA5Wb2D0nLzKx33PdLzSxlu4Kk+kynlCsmHn/hlHLs4PEXWiXGn9PeR5JqgPuBiWb2j3DxYkmbhd9vBnySyxicc85Fl8veRwJuAeaZ2dVxXz0InBS+PwmYkqsYnHPOZSaXbQrDgBOA2ZIawmUXAH8A7pX0M+BD4OgI+5qQmxDzxuMvnFKOHTz+Qqu4+HPepuCcc650+Ihm55xzbbxQcM4516aoCoVST42RIv6LJS2S1BC+Dil0rIlI6ibpFUkzw/gvCZcPlPRyeP7/LqlroWNNJEX8f5X0Xtz5H1roWJORVC3pNUkPh59L4tzHJIi/lM79+5Jmh3HWh8tK4toDSePP+NpTVIUCpZ8aI1n8ANeY2dDw9WjhQkypCRhhZkOAocB3Je0NjCeIf3tgKfCzAsaYSrL4AcbEnf+G5LsouLMIRv/HlMq5j2kfP5TOuQf4VhhnrG9/qVx7YtrHDxlee4qqUCj11Bgp4i8JFmgMP9aELwNGAJPC5cV8/pPFXxIk9Qe+B9wcfhYlcu5h3fjLRElce7KpqAqFeKlSYwAJU2MUk3bxA5whaZakW4v8EbQ67EL8CfAU8A6wzMyaw1UWUsQFXfv4zSx2/i8Pz/81kop1LtRrgbFAa/i5LyV07lk3/phSOPcQ3EA8KWl6mGYHSuvakyh+yPDaU5SFQpga437gbDP7vNDxZCpB/NcD2xJUaXwM/LGA4aVkZi1mNhToD+wJfC3RavmNKrr28UvaGTgfGATsAWwIjCtgiAlJOhT4xMymxy9OsGpRnvsk8UMJnPs4w8xsN+Bggqrf/QodUIYSxZ/xtafoCoVST42RKH4zWxxerFqBmwgutkXNzJYB0wjaRnpLig107A98VKi4ooqL/7thtZ6ZWRNwG8V5/ocBh0t6H7iHoNroWkrn3K8Tv6S/lci5B8DMPgr//ASYTBBryVx7EsXfkWtPURUKpZ4aI1n8sX9UoSOBosz4KqmfpN7h++7AtwnaRZ4FRoarFfP5TxT/G3H/qUVQJ1x059/Mzjez/ma2NXAsMNXMjqNEzn2S+I8vhXMPIKmHpF6x98B3CGItlWtPwvg7cu3JS+rsDGQzNUYhJIv/R2FXPAPeB04tTHhpbQbcLqma4IbhXjN7WNJc4B5JvwVeIyj4ilGy+KdK6kdQHdMAnFbIIDM0jtI498lMLJFzvwkwOSi76ALcZWaPS3qV0rj2JIv/zkyvPZ7mwjnnXJuiqj5yzjlXWF4oOOeca+OFgnPOuTZeKDjnnGvjhYJzzrk2XihUAEmNCZadJunE8P2gMIPia5K2jbjPaZLejMu+OCn9Vp0n6WxJ6+XjWAmOvc55zHD78yS9EZ6vV2PnP1sk9ZZ0ehb28+8M1z9aQVbaVkl1cctrJN2uIHPnPEnnx3333fDfz3xJv4pbPlAllBW2HHmhUKHM7AYzuyP8eAQwycx2NbN3MtjNcXHZF0emXz0rzgYKUih0hqTTgAMJRpkOBQ4gcRqLzugNJCwUwrEbkZjZNzI87hzgB8A/2y0/Gqg1s68DuwOnSto6jOXPBOkYBhOM44llEy61rLBlxwuFCqUgz/p5CvKrnw38QtKz4XfHK5iXoEHSjZlcUCRNiXsCOVXSxPD9NEnXhfucI2nPcHkPBYm6Xg2fVL4fLq+WdFV4lzlL0mhJZwKbA8/GxXq9pHrFzZ8QLn9f0iWSZoT7GBQu7ynptrj9HiXpZ5Kuidv2FEnxI+rjf9814bGeUTCCeltJM+K+315S+/w/EAxiPD2Wy8vMPjez28NtDgh/++zwXNTG/YaNwvd1kqbF/d3dGp7Td8PzAsEgz23Dc3ylpP0l/UvSg8A8SZcpnOMj3M/lcdvG/8bG8M/9w2NMCp9wJkpapyAzs3lm9maC32xADwVpOroDq4DPCVItzDezd81sFUFajO+H+y6ZrLBly8z8VeYvoDHBsouB8xK8/xrwEFATfv4LcGKC7acBbxKMUm0ArgyXbwLMB/YF3gI2jFv/pvD9fsCc8P3vgOPD973DbXoAvyDIIdUl/C62n/eBjeLiiC2vDo+xS9x6o8P3pwM3h+/HA9fGbd8nPN47cb/538DXE/xmI3g6Avhf4P/C988CQ+N+z+h22/UClib5u+kGLAB2CD/fQZBIca3fCtQB0+L+vv4N1AIbAUsI0oRvHTuv4Xr7AyuBgeHnrYEZ4fuq8Df3TfbvJdx+OUHOpSrgRWB4in9n04C6uM81BBf8T8M4RoXLR8b+PsLPJwD/F/6W+XHLt4z/Pf7Kz6vY0ly4wjuA4FH/1fCmsDvJk4AdZ2b18QvMbLGk/yW4UB5pZv+N+/rucJ1/SlpfQZ6i7xAkUjsvXKcbMIAgb9ENFqaNbrefeMcoSBPchSDNxWBgVvhdLKHidILqDcL9HhsX71IASVOBQyXNIygcZic4Vivw9/D93+L2fzNwsqRzgB+ybtIxkTy76Y7Ae2b2Vvj5duCXBMnwUnnEgiRzTZI+ISiME3nFzN4DMLP3JS2RtGu4/mtmtiTNcV4xs4UAClK3bA08n2abmD2BFoKnuz7AvyQ9TfLsryWTFbaceaHg2hNwu5mdn3bN5L5OcPe6ebvl7f+Dxy4ER1m76oewKiHlBUHSQOA8YA8zWyrprwSFSkxT+GcLa/6tJ9vvzQRVPG8QZPOMIraf+4GLgKnA9PYXWjP7XNJKSduY2bvtf0aK/Tezpoq3W7vvmuLex/++9la2+3wz8BNgU+DWFMfO9DiJ/Bh43MxWA59IeoHgiWcBwVNATCz762eEWWHDm4FizgpbtrxNwbX3DDBS0sbQNkftVlE3DtsKDiaYYOi88MId88NwneHAcjNbDjwBjI7VVYd3sQBPAqeF9dFI2jBcvoKgOgZgfYKL3nJJm4THTedJ4Iy4ePsAWDAZz5YEF7K7k2xbxZqMpT8mvGM2s6/C33E9yQuU3wN/lrR+eNyeYdvLG8DWkrYL1zsBeC58/z7BUxvAURF+W/y5SWYy8F2C+Q2eiLDPzviQIIW2FGTu3Jvg974KbK+gp1FXgie3By2oMyqJrLDlzAuFyrCepIVxr3OSrWhmc4HfEMzgNItg9rXNkqw+UWu6pD4dNpDeBPzUgtzu5wK3xjVOfiXpNeAG1vQquYyg7nmWpDnhZwjuaD8Ml88kuAgDTAAek/Ssmc0kyBz6BnAX8EKEc/FboI+Cxu6ZwLfivrsXeCFWpZTASoKJe+YQNIheGn8uCGe+SrLt9QQXvFfD7f8FtIYFysnAfZJmE1RR3RBucwlwnYJJ2FvS/bDwCeWF8LddmWSdVWEc95pZ2n1GIelISQuBfYBHJMUKmz8DPQl6J70K3GZms8KngDMICqV5YSyvh9uMA86RNJ9g5rlSywpb8jxLqsuLsOfMee3bIIqJpIcJukM+04FtzwM2MLMLsx9Z9kiqAmYAR5vZ24WOxxUff1JwFU/BoK+3gC87WCBMBk4Erst6cFmkYCzAfOAZLxBcMv6k4Jxzro0/KTjnnGvjhYJzzrk2Xig455xr44WCc865Nl4oOOeca/P/Ae8VGiFNqzP2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'As you can see, there are a surprising number of countries that fall on the diagonal line. In fact, examining the DataFrame reveals that the life expectancy for 140 of the 260 countries did not change at all in the 19th century! This is possibly a result of not having access to the data for all the years back then. In this way, visualizing your data can help you uncover insights as well as diagnose it for errors.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the scatter plot\n",
    "g1800s.plot(kind='scatter', x='1800', y='1899')\n",
    "\n",
    "# Specify axis labels\n",
    "plt.xlabel('Life Expectancy by Country in 1800')\n",
    "plt.ylabel('Life Expectancy by Country in 1899')\n",
    "\n",
    "# Specify axis limits\n",
    "plt.xlim(20, 55)\n",
    "plt.ylim(20, 55)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "'''As you can see, there are a surprising number of countries that fall on the diagonal line. In fact, examining the DataFrame reveals that the life expectancy for 140 of the 260 countries did not change at all in the 19th century! This is possibly a result of not having access to the data for all the years back then. In this way, visualizing your data can help you uncover insights as well as diagnose it for errors.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about the question at hand\n",
    "Since you are given life expectancy level data by country and year, you could ask questions about how much the average life expectancy changes over each year.\n",
    "\n",
    "Before continuing, however, it's important to make sure that the following assumptions about the data are true:\n",
    "\n",
    "* 'Life expectancy' is the first column (index 0) of the DataFrame.\n",
    "* The other columns contain either null or numeric values.\n",
    "* The numeric values are all greater than or equal to 0.\n",
    "* There is only one instance of each country.\n",
    "\n",
    "You can write a function that you can apply over the entire DataFrame to verify some of these assumptions. Note that spending the time to write such a script will help you when working with other datasets as well.\n",
    "\n",
    "* Define a function called check_null_or_valid() that takes in one argument: row_data.\n",
    "* Inside the function, convert no_na to a numeric data type using pd.to_numeric().\n",
    "* Write an assert statement to make sure the first column (index 0) of the g1800s DataFrame is 'Life expectancy'.\n",
    "* Write an assert statement to test that all the values are valid for the g1800s DataFrame. Use the check_null_or_valid() function placed inside the .apply() method for this. Note that because you're applying it over the entire DataFrame, and not just one column, you'll have to chain the .all() method twice, and remember that you don't have to use () for functions placed inside .apply().\n",
    "* Write an assert statement to make sure that each country occurs only once in the data. Use the .value_counts() method on the 'Life expectancy' column for this. Specifically, index 0 of .value_counts() will contain the most frequently occuring value. If this is equal to 1 for the 'Life expectancy' column, then you can be certain that no country appears more than once in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Getting into the habit of testing your code like this is an important skill.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "g1800s = pd.read_csv('./datasets/g1800s.csv')\n",
    "#g1800s = pd.read_csv('./datasets/gapminder.csv')\n",
    "\n",
    "#g1800s.info()\n",
    "\n",
    "def check_null_or_valid(row_data):\n",
    "    \"\"\"Function that takes a row of data,\n",
    "    drops all missing values,\n",
    "    and checks if all remaining values are greater than or equal to 0\n",
    "    \"\"\"\n",
    "    no_na = row_data.dropna()\n",
    "    numeric = pd.to_numeric(no_na)\n",
    "    ge0 = numeric >= 0\n",
    "    return ge0\n",
    "\n",
    "# Check whether the first column is 'Life expectancy'\n",
    "assert g1800s.columns[0] == 'Life expectancy' \n",
    "\n",
    "# Check whether the values in the row are valid\n",
    "assert g1800s.iloc[:, 1:].apply(check_null_or_valid, axis=1).all().all()\n",
    "\n",
    "# Check that there is only one instance of each country\n",
    "assert g1800s['Life expectancy'].value_counts()[0] == 1\n",
    "\n",
    "'''Getting into the habit of testing your code like this is an important skill.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling your data\n",
    "Here, three DataFrames have been pre-loaded: g1800s, g1900s, and g2000s. These contain the Gapminder life expectancy data for, respectively, the 19th century, the 20th century, and the 21st century.\n",
    "\n",
    "Your task in this exercise is to concatenate them into a single DataFrame called gapminder. This is a row-wise concatenation, similar to how you concatenated the monthly Uber datasets in Chapter 3.\n",
    "\n",
    "* Use pd.concat() to concatenate g1800s, g1900s, and g2000s into one DataFrame called gapminder. Make sure you pass DataFrames to pd.concat() in the form of a list.\n",
    "* Print the shape and the head of the concatenated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 302)\n",
      "    1800   1801   1802   1803   1804   1805   1806   1807   1808   1809  \\\n",
      "0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "1  28.21  28.20  28.19  28.18  28.17  28.16  28.15  28.14  28.13  28.12   \n",
      "2    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "3  35.40  35.40  35.40  35.40  35.40  35.40  35.40  35.40  35.40  35.40   \n",
      "4  28.82  28.82  28.82  28.82  28.82  28.82  28.82  28.82  28.82  28.82   \n",
      "\n",
      "           ...            2092  2093  2094  2095  2096  2097  2098  2099  \\\n",
      "0          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   2100        Life expectancy  \n",
      "0   NaN               Abkhazia  \n",
      "1   NaN            Afghanistan  \n",
      "2   NaN  Akrotiri and Dhekelia  \n",
      "3   NaN                Albania  \n",
      "4   NaN                Algeria  \n",
      "\n",
      "[5 rows x 302 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All the Gapminder data, from 1800 to 2016, is now contained in one DataFrame.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "g1800s = pd.read_csv('./datasets/g1800s.csv')\n",
    "g1900s = pd.read_csv('./datasets/g1900s.csv')\n",
    "g2000s = pd.read_csv('./datasets/g2000s.csv')\n",
    "\n",
    "# Concatenate the DataFrames row-wise\n",
    "gapminder = pd.concat([g1800s,g1900s,g2000s])\n",
    "\n",
    "# Print the shape of gapminder\n",
    "print(gapminder.shape)\n",
    "\n",
    "# Print the head of gapminder\n",
    "print(gapminder.head())\n",
    "\n",
    "'''All the Gapminder data, from 1800 to 2016, is now contained in one DataFrame.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial impressions of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Principles of tidy data\n",
    "* Rows form observations\n",
    "* Columns form variables\n",
    "* Tidying data will make data cleaning easier\n",
    "* Melting turns columns into rows\n",
    "* Pivot will take unique values from a column and create new columns\n",
    "\n",
    "##### Checking data types\n",
    "```python\n",
    "df.dtypes\n",
    "df['column'] = df['column'].to_numeric()\n",
    "df['column'] = df['column'].astype(str)\n",
    "df['column'] = df['column'].astype(int)\n",
    "df['column'] = df['column'].astype(float)\n",
    "```\n",
    "\n",
    "##### Additional calculations and saving your data\n",
    "```python\n",
    "df['new_column'] = df['column_1'] + df['column_2']\n",
    "df['new_column'] = df.apply(my_function, axis=1) #works on rows\n",
    "df.to_csv['my_data.csv']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping your data\n",
    "Now that you have all the data combined into a single DataFrame, the next step is to reshape it into a tidy data format.\n",
    "\n",
    "Currently, the gapminder DataFrame has a separate column for each year. What you want instead is a single column that contains the year, and a single column that represents the average life expectancy for each year and country. By having year in its own column, you can use it as a predictor variable in a later analysis.\n",
    "\n",
    "You can convert the DataFrame into the desired tidy format by melting it.\n",
    "\n",
    "* Reshape gapminder by melting it. Keep 'Life expectancy' fixed by specifying it as an argument to the id_vars parameter.\n",
    "* Rename the three columns of the melted DataFrame to 'country', 'year', and 'life_expectancy' by passing them in as a list to gapminder_melt.columns.\n",
    "* Print the head of the melted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 country  year  life_expectancy\n",
      "0               Abkhazia  1800              NaN\n",
      "1            Afghanistan  1800            28.21\n",
      "2  Akrotiri and Dhekelia  1800              NaN\n",
      "3                Albania  1800            35.40\n",
      "4                Algeria  1800            28.82\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Melt gapminder: gapminder_melt\n",
    "gapminder_melt = pd.melt(frame=gapminder, id_vars='Life expectancy')\n",
    "\n",
    "# Rename the columns\n",
    "gapminder_melt.columns = ['country','year','life_expectancy']\n",
    "\n",
    "# Print the head of gapminder_melt\n",
    "print(gapminder_melt.head())\n",
    "\n",
    "'''Having the data in this tidy format will make subsequent analysis far easier.'''\n",
    "#gapminder_melt.to_csv('./datasets/gapminder2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data types\n",
    "Now that your data are in the proper shape, you need to ensure that the columns are of the proper data type. That is, you need to ensure that country is of type object, year is of type int64, and life_expectancy is of type float64.\n",
    "\n",
    "The tidy DataFrame has been pre-loaded as gapminder. Explore it in the IPython Shell using the .info() method. Notice that the column 'year' is of type object. This is incorrect, so you'll need to use the pd.to_numeric() function to convert it to a numeric data type.\n",
    "\n",
    "NumPy and pandas have been pre-imported as np and pd.\n",
    "\n",
    "* Convert the year column of gapminder using pd.to_numeric().\n",
    "* Assert that the country column is of type np.object. This has been done for you.\n",
    "* Assert that the year column is of type np.int64.\n",
    "* Assert that the life_expectancy column is of type np.float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since the assert statements did not throw any errors, you can be sure that your columns have the correct data types!'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "gapminder = pd.read_csv('./datasets/gapminder2.csv')\n",
    "\n",
    "# Convert the year column to numeric\n",
    "gapminder.year = pd.to_numeric(gapminder.year)\n",
    "\n",
    "# Test if country is of type object\n",
    "assert gapminder.country.dtypes == np.object\n",
    "\n",
    "# Test if year is of type int64\n",
    "assert gapminder.year.dtypes == np.int64\n",
    "\n",
    "# Test if life_expectancy is of type float64\n",
    "assert gapminder.life_expectancy.dtypes == np.float64\n",
    "#print(gapminder.info())\n",
    "\n",
    "'''Since the assert statements did not throw any errors, you can be sure that your columns have the correct data types!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at country spellings\n",
    "Having tidied your DataFrame and checked the data types, your next task in the data cleaning process is to look at the 'country' column to see if there are any special or invalid characters you may need to deal with.\n",
    "\n",
    "It is reasonable to assume that country names will contain:\n",
    "\n",
    "The set of lower and upper case letters.\n",
    "Whitespace between words.\n",
    "Periods for any abbreviations.\n",
    "To confirm that this is the case, you can leverage the power of regular expressions again. For common operations like this, Pandas has a built-in string method - str.contains() - which takes a regular expression pattern, and applies it to the Series, returning True if there is a match, and False otherwise.\n",
    "\n",
    "Since here you want to find the values that do not match, you have to invert the boolean, which can be done using ~. This Boolean series can then be used to get the Series of countries that have invalid names.\n",
    "\n",
    "* Create a Series called countries consisting of the 'country' column of gapminder.\n",
    "* Drop all duplicates from countries using the .drop_duplicates() method.\n",
    "* Write a regular expression that tests your assumptions of what characters belong in countries:\n",
    "    * Anchor the pattern to match exactly what you want by placing a ^ in the beginning and $ in the end.\n",
    "    * Use A-Za-z to match the set of lower and upper case letters, \\. to match periods, and \\s to match whitespace between words.\n",
    "* Use str.contains() to create a Boolean vector representing values that match the pattern.\n",
    "* Invert the mask by placing a ~ before it.\n",
    "* Subset the countries series using the .loc[] accessor and mask_inverse. Then hit 'Submit Answer' to see the invalid country names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49              Congo, Dem. Rep.\n",
      "50                   Congo, Rep.\n",
      "53                 Cote d'Ivoire\n",
      "73        Falkland Is (Malvinas)\n",
      "93                 Guinea-Bissau\n",
      "98              Hong Kong, China\n",
      "118      United Korea (former)\\n\n",
      "131                 Macao, China\n",
      "132               Macedonia, FYR\n",
      "145        Micronesia, Fed. Sts.\n",
      "161              Ngorno-Karabakh\n",
      "187               St. Barthélemy\n",
      "193       St.-Pierre-et-Miquelon\n",
      "225                  Timor-Leste\n",
      "251        Virgin Islands (U.S.)\n",
      "252         North Yemen (former)\n",
      "253         South Yemen (former)\n",
      "258                        Åland\n",
      "260                      Curaçao\n",
      "261    Sint Maarten (Dutch part)\n",
      "262     St. Martin (French part)\n",
      "Name: country, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As you can see, not all these country names are actually invalid so maybe the assumptions need to be tweaked a little. However, there certainly are a few cases worth further investigation, such as St. Barth?lemy. Whenever you are dealing with columns of raw data consisting of strings, it is important to check them for consistency like this.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the series of countries: countries\n",
    "countries = gapminder.country\n",
    "\n",
    "# Drop all the duplicates from countries\n",
    "countries = countries.drop_duplicates()\n",
    "\n",
    "# Write the regular expression: pattern\n",
    "pattern = '^[A-Za-z\\.\\s]*$'\n",
    "\n",
    "# Create the Boolean vector: mask\n",
    "mask = countries.str.contains(pattern)\n",
    "\n",
    "# Invert the mask: mask_inverse\n",
    "mask_inverse = ~mask\n",
    "\n",
    "# Subset countries using mask_inverse: invalid_countries\n",
    "invalid_countries = countries.loc[mask_inverse]\n",
    "\n",
    "# Print invalid_countries\n",
    "print(invalid_countries)\n",
    "\n",
    "'''As you can see, not all these country names are actually invalid so maybe the assumptions need to be tweaked a little. However, there certainly are a few cases worth further investigation, such as St. Barth?lemy. Whenever you are dealing with columns of raw data consisting of strings, it is important to check them for consistency like this.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data cleaning and processing\n",
    "It's now time to deal with the missing data. There are several strategies for this: You can drop them, fill them in using the mean of the column or row that the missing value is in (also known as [imputation](https://en.wikipedia.org/wiki/Imputation_(statistics))), or, if you are dealing with time series data, use a forward fill or backward fill, in which you replace missing values in a column with the most recent known value in the column. See [pandas Foundations](https://www.datacamp.com/courses/pandas-foundations) for more on forward fill and backward fill.\n",
    "\n",
    "In general, it is not the best idea to drop missing values, because in doing so you may end up throwing away useful information. In this data, the missing values refer to years where no estimate for life expectancy is available for a given country. You could fill in, or guess what these life expectancies could be by looking at the average life expectancies for other countries in that year, for example. Whichever strategy you go with, it is important to carefully consider all options and understand how they will affect your data.\n",
    "\n",
    "In this exercise, you'll practice dropping missing values. Your job is to drop all the rows that have NaN in the life_expectancy column. Before doing so, it would be valuable to use assert statements to confirm that year and country do not have any missing values.\n",
    "\n",
    "Begin by printing the shape of gapminder in the IPython Shell prior to dropping the missing values. Complete the exercise to find out what its shape will be after dropping the missing values!\n",
    "\n",
    "* Assert that country and year do not contain any missing values. The first assert statement has been written for you. Note the chaining of the .all() method to pd.notnull() to confirm that all values in the column are not null.\n",
    "* Drop the rows in the data where any observation in life_expectancy is missing. As you confirmed that country and year don't have missing values, you can use the .dropna() method on the entire gapminder DataFrame, because any missing values would have to be in the life_expectancy column. The .dropna() method has the default keyword arguments axis=0 and how='any', which specify that rows with any missing values should be dropped.\n",
    "* Print the shape of gapminder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248325, 3)\n",
      "(60688, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"After dropping the missing values from 'life_expectancy', the number of rows in the DataFrame has gone down from 169260 to 43857. In general, you should avoid dropping too much of your data, but if there is no reasonable way to fill in or impute missing values, then dropping the missing data may be the best solution.\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "gapminder = pd.read_csv('./datasets/gapminder2.csv')\n",
    "\n",
    "print(gapminder.shape)\n",
    "\n",
    "# Assert that country does not contain any missing values\n",
    "assert pd.notnull(gapminder.country).all()\n",
    "\n",
    "# Assert that year does not contain any missing values\n",
    "assert pd.notnull(gapminder.year).all()\n",
    "\n",
    "# Drop the missing values\n",
    "gapminder = gapminder.dropna()\n",
    "\n",
    "# Print the shape of gapminder\n",
    "print(gapminder.shape)\n",
    "\n",
    "'''After dropping the missing values from 'life_expectancy', the number of rows in the DataFrame has gone down from 169260 to 43857. In general, you should avoid dropping too much of your data, but if there is no reasonable way to fill in or impute missing values, then dropping the missing data may be the best solution.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up\n",
    "Now that you have a clean and tidy dataset, you can do a bit of visualization and aggregation. In this exercise, you'll begin by creating a histogram of the life_expectancy column. You should not get any values under 0 and you should see something reasonable on the higher end of the life_expectancy age range.\n",
    "\n",
    "Your next task is to investigate how average life expectancy changed over the years. To do this, you need to subset the data by each year, get the life_expectancy column from each subset, and take an average of the values. You can achieve this using the [.groupby() method](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html). This .groupby() method is covered in greater depth in [Manipulating DataFrames](https://www.datacamp.com/courses/manipulating-dataframes-with-pandas) with pandas.\n",
    "\n",
    "Finally, you can save your tidy and summarized DataFrame to a file using the .to_csv() method.\n",
    "\n",
    "matplotlib.pyplot and pandas have been pre-imported as plt and pd. Go for it!\n",
    "\n",
    "* Create a histogram of the life_expectancy column using the .plot() method of gapminder. Specify kind='hist'.\n",
    "* Group gapminder by 'year' and aggregate 'life_expectancy' by the mean. To do this:\n",
    "    * Use the .groupby() method on gapminder with 'year' as the argument. Then select 'life_expectancy' and chain the .mean() method to it.\n",
    "* Print the head and tail of gapminder_agg. This has been done for you.\n",
    "* Create a line plot of average life expectancy per year by using the .plot() method (without any arguments in plot) on gapminder_agg.\n",
    "* Save gapminder and gapminder_agg to csv files called 'gapminder.csv' and 'gapminder_agg.csv', respectively, using the .to_csv() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1800    31.486020\n",
      "1801    31.448905\n",
      "1802    31.463483\n",
      "1803    31.377413\n",
      "1804    31.446318\n",
      "Name: life_expectancy, dtype: float64\n",
      "year\n",
      "2096    85.294724\n",
      "2097    85.416181\n",
      "2098    85.537337\n",
      "2099    85.658141\n",
      "2100    85.778995\n",
      "Name: life_expectancy, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"You've stepped through each stage of the data cleaning process and your data is now ready for serious analysis! Looking at the line plot, it seems like life expectancy has, as expected, increased over the years. There is a surprising dip around 1920 that may be worth further investigation!\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gapminder = pd.read_csv('./datasets/gapminder2.csv')\n",
    "\n",
    "# Add first subplot\n",
    "plt.subplot(2, 1, 1) \n",
    "\n",
    "# Create a histogram of life_expectancy\n",
    "gapminder.life_expectancy.plot(kind='hist')\n",
    "\n",
    "# Group gapminder: gapminder_agg\n",
    "gapminder_agg = gapminder.groupby('year')['life_expectancy'].mean()\n",
    "\n",
    "# Print the head of gapminder_agg\n",
    "print(gapminder_agg.head())\n",
    "\n",
    "# Print the tail of gapminder_agg\n",
    "print(gapminder_agg.tail())\n",
    "\n",
    "# Add second subplot\n",
    "plt.subplot(2, 1, 2)\n",
    "\n",
    "# Create a line plot of life expectancy per year\n",
    "gapminder_agg.plot()\n",
    "\n",
    "# Add title and specify axis labels\n",
    "plt.title('Life expectancy over the years')\n",
    "plt.ylabel('Life expectancy')\n",
    "plt.xlabel('Year')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save both DataFrames to csv files\n",
    "gapminder.to_csv('gapminder.csv')\n",
    "gapminder_agg.to_csv('gapminder_agg.csv')\n",
    "\n",
    "'''You've stepped through each stage of the data cleaning process and your data is now ready for serious analysis! Looking at the line plot, it seems like life expectancy has, as expected, increased over the years. There is a surprising dip around 1920 that may be worth further investigation!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
